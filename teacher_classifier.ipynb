{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32c4ea0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, magic, shutil\n",
    "from glob import glob\n",
    "import time, datetime\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import joblib\n",
    "import datetime as dt\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torch, gc\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "\n",
    "#from skimage import io\n",
    "import sklearn\n",
    "from sklearn.model_selection import GroupKFold, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, log_loss, f1_score, confusion_matrix, classification_report\n",
    "from sklearn import metrics, preprocessing\n",
    "from scipy.ndimage import zoom\n",
    "import timm\n",
    "from timm.data import resolve_data_config\n",
    "from timm.data.transforms_factory import create_transform\n",
    "import albumentations as A\n",
    "import albumentations.pytorch\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29d0796-1f1d-40df-ad4a-21f57ed7fe35",
   "metadata": {},
   "source": [
    "#### Hyper Param Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57c0283c",
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'fold_num': 5,\n",
    "    'seed': 42,\n",
    "    'model': 'resnet152',\n",
    "    'img_size': 260,\n",
    "    'epochs': 200,\n",
    "    'train_bs':64,\n",
    "    'valid_bs':64,\n",
    "    'lr': 1e-4, ## learning rate\n",
    "    'num_workers': 8,\n",
    "    'verbose_step': 1,\n",
    "    'patience' : 5,\n",
    "    'label_encoder':False,\n",
    "    'device': 'cuda:0',\n",
    "    'freezing': False,\n",
    "    'trainable_layer': 12,\n",
    "    'model_path': './models'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7066a8a1-7060-4b6d-bf0c-d4164820a414",
   "metadata": {},
   "source": [
    "#### wandb init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "127461e4-c16d-47fd-b983-556c12ad0daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "category = 'dishes'\n",
    "time_now = dt.datetime.now()\n",
    "run_id = time_now.strftime(\"%Y%m%d%H%M\")\n",
    "project_name = 'KD_'+ CFG['model'] + '_' + category\n",
    "user = 'hojunking'\n",
    "run_name = project_name + '_' + run_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b6c4553-4301-4ba8-801e-e7130ac0b3cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: wrap 1266\n",
      "label: leftover 1483\n",
      "label: green dish 1261\n",
      "Train_Images:  4010\n",
      "Train_Images_labels: 4010\n"
     ]
    }
   ],
   "source": [
    "# TRAIN DATASET DATAFRAME\n",
    "train_path = '../Data/carbon_reduction_data/train/'\n",
    "label_list = ['wrap','leftover','green dish']\n",
    "\n",
    "train_img_paths = []\n",
    "train_img_labels = []\n",
    "\n",
    "for label in label_list: ## 각 레이블 돌기\n",
    "    print(f'label: {label}',end=' ')\n",
    "    img_paths = [] \n",
    "    img_labels = []\n",
    "\n",
    "    dir_path = train_path + label ## 레이블 폴더 경로\n",
    "    \n",
    "    for folder, subfolders, filenames in os.walk(dir_path): ## 폴더 내 모든 파일 탐색\n",
    "        for img in filenames: ## 각 파일 경로, 레이블 저장\n",
    "            img_paths.append(folder+'/'+img)\n",
    "            img_labels.append(label)\n",
    "        \n",
    "    print(len(img_paths))\n",
    "\n",
    "    train_img_paths.extend(img_paths)\n",
    "    train_img_labels.extend(img_labels)\n",
    "\n",
    "print('Train_Images: ',len(train_img_paths))\n",
    "print(\"Train_Images_labels:\", len(train_img_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6aef7874-aa53-4c21-b0ff-f8985c3dc8d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: wrap 423\n",
      "label: leftover 495\n",
      "label: green dish 421\n",
      "Test_Images:  1339\n",
      "Test_Images_labels: 1339\n"
     ]
    }
   ],
   "source": [
    "# TEST DATASET DATAFRAME\n",
    "test_path = '../Data/carbon_reduction_data/test/'\n",
    "test_img_paths = []\n",
    "test_img_labels = []\n",
    "\n",
    "for label in label_list: ## 각 레이블 돌기\n",
    "    print(f'label: {label}',end=' ')\n",
    "    img_paths = [] \n",
    "    img_labels = []\n",
    "    dir_path = test_path + label ## 레이블 폴더 경로\n",
    "    \n",
    "    for folder, subfolders, filenames in os.walk(dir_path): ## 폴더 내 모든 파일 탐색\n",
    "        for img in filenames: ## 각 파일 경로, 레이블 저장\n",
    "            img_paths.append(folder+'/'+img)\n",
    "            img_labels.append(label)\n",
    "        \n",
    "    print(len(img_paths))\n",
    "\n",
    "    test_img_paths.extend(img_paths)\n",
    "    test_img_labels.extend(img_labels)\n",
    "\n",
    "print('Test_Images: ',len(test_img_paths))\n",
    "print(\"Test_Images_labels:\", len(test_img_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2716dd8b-84db-4707-80e2-19b29eae9c23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>dir</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0720.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/train/wrap</td>\n",
       "      <td>wrap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0282.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/train/wrap</td>\n",
       "      <td>wrap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1028.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/train/wrap</td>\n",
       "      <td>wrap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0540.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/train/wrap</td>\n",
       "      <td>wrap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0466.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/train/wrap</td>\n",
       "      <td>wrap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4005</th>\n",
       "      <td>0011.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/train/green dish</td>\n",
       "      <td>green dish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4006</th>\n",
       "      <td>0868.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/train/green dish</td>\n",
       "      <td>green dish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4007</th>\n",
       "      <td>0611.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/train/green dish</td>\n",
       "      <td>green dish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4008</th>\n",
       "      <td>0692.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/train/green dish</td>\n",
       "      <td>green dish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4009</th>\n",
       "      <td>1059.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/train/green dish</td>\n",
       "      <td>green dish</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4010 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      image_id                                             dir       label\n",
       "0     0720.jpg        ../Data/carbon_reduction_data/train/wrap        wrap\n",
       "1     0282.jpg        ../Data/carbon_reduction_data/train/wrap        wrap\n",
       "2     1028.jpg        ../Data/carbon_reduction_data/train/wrap        wrap\n",
       "3     0540.jpg        ../Data/carbon_reduction_data/train/wrap        wrap\n",
       "4     0466.jpg        ../Data/carbon_reduction_data/train/wrap        wrap\n",
       "...        ...                                             ...         ...\n",
       "4005  0011.jpg  ../Data/carbon_reduction_data/train/green dish  green dish\n",
       "4006  0868.jpg  ../Data/carbon_reduction_data/train/green dish  green dish\n",
       "4007  0611.jpg  ../Data/carbon_reduction_data/train/green dish  green dish\n",
       "4008  0692.jpg  ../Data/carbon_reduction_data/train/green dish  green dish\n",
       "4009  1059.jpg  ../Data/carbon_reduction_data/train/green dish  green dish\n",
       "\n",
       "[4010 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Pandas 데이터프레임 만들기\n",
    "trn_df = pd.DataFrame(train_img_paths, columns=['image_id'])\n",
    "trn_df['dir'] = trn_df['image_id'].apply(lambda x: os.path.dirname(x))\n",
    "trn_df['image_id'] = trn_df['image_id'].apply(lambda x: os.path.basename(x))\n",
    "trn_df['label'] = train_img_labels\n",
    "train = trn_df\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "105ae88a-4d4f-49a9-bffc-8689e2db0826",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>dir</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0282.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/test/wrap</td>\n",
       "      <td>wrap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0190.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/test/wrap</td>\n",
       "      <td>wrap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0234.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/test/wrap</td>\n",
       "      <td>wrap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0392.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/test/wrap</td>\n",
       "      <td>wrap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0375.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/test/wrap</td>\n",
       "      <td>wrap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1334</th>\n",
       "      <td>0381.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/test/green dish</td>\n",
       "      <td>green dish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1335</th>\n",
       "      <td>0236.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/test/green dish</td>\n",
       "      <td>green dish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336</th>\n",
       "      <td>0384.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/test/green dish</td>\n",
       "      <td>green dish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1337</th>\n",
       "      <td>0074.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/test/green dish</td>\n",
       "      <td>green dish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1338</th>\n",
       "      <td>0011.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/test/green dish</td>\n",
       "      <td>green dish</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1339 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      image_id                                            dir       label\n",
       "0     0282.jpg        ../Data/carbon_reduction_data/test/wrap        wrap\n",
       "1     0190.jpg        ../Data/carbon_reduction_data/test/wrap        wrap\n",
       "2     0234.jpg        ../Data/carbon_reduction_data/test/wrap        wrap\n",
       "3     0392.jpg        ../Data/carbon_reduction_data/test/wrap        wrap\n",
       "4     0375.jpg        ../Data/carbon_reduction_data/test/wrap        wrap\n",
       "...        ...                                            ...         ...\n",
       "1334  0381.jpg  ../Data/carbon_reduction_data/test/green dish  green dish\n",
       "1335  0236.jpg  ../Data/carbon_reduction_data/test/green dish  green dish\n",
       "1336  0384.jpg  ../Data/carbon_reduction_data/test/green dish  green dish\n",
       "1337  0074.jpg  ../Data/carbon_reduction_data/test/green dish  green dish\n",
       "1338  0011.jpg  ../Data/carbon_reduction_data/test/green dish  green dish\n",
       "\n",
       "[1339 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Pandas 데이터프레임 만들기\n",
    "tst_df = pd.DataFrame(test_img_paths, columns=['image_id'])\n",
    "tst_df['dir'] = tst_df['image_id'].apply(lambda x: os.path.dirname(x))\n",
    "tst_df['image_id'] = tst_df['image_id'].apply(lambda x: os.path.basename(x))\n",
    "tst_df['label'] = test_img_labels\n",
    "test = tst_df\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf387b57-bb5d-4564-96db-d764e547a93a",
   "metadata": {},
   "source": [
    "##### Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03c67d39-7933-4f98-b998-54a6036ff4a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>dir</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0720.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/train/wrap</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0282.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/train/wrap</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1028.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/train/wrap</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0540.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/train/wrap</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0466.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/train/wrap</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4005</th>\n",
       "      <td>0011.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/train/green dish</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4006</th>\n",
       "      <td>0868.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/train/green dish</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4007</th>\n",
       "      <td>0611.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/train/green dish</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4008</th>\n",
       "      <td>0692.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/train/green dish</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4009</th>\n",
       "      <td>1059.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/train/green dish</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4010 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      image_id                                             dir  label\n",
       "0     0720.jpg        ../Data/carbon_reduction_data/train/wrap      2\n",
       "1     0282.jpg        ../Data/carbon_reduction_data/train/wrap      2\n",
       "2     1028.jpg        ../Data/carbon_reduction_data/train/wrap      2\n",
       "3     0540.jpg        ../Data/carbon_reduction_data/train/wrap      2\n",
       "4     0466.jpg        ../Data/carbon_reduction_data/train/wrap      2\n",
       "...        ...                                             ...    ...\n",
       "4005  0011.jpg  ../Data/carbon_reduction_data/train/green dish      0\n",
       "4006  0868.jpg  ../Data/carbon_reduction_data/train/green dish      0\n",
       "4007  0611.jpg  ../Data/carbon_reduction_data/train/green dish      0\n",
       "4008  0692.jpg  ../Data/carbon_reduction_data/train/green dish      0\n",
       "4009  1059.jpg  ../Data/carbon_reduction_data/train/green dish      0\n",
       "\n",
       "[4010 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "train['label'] = le.fit_transform(train['label'].values)\n",
    "test['label'] = le.transform(test['label'].values)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29be149b-1ea0-4e34-846e-7395d4e94f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_encoding_classes():\n",
    "    # define certain classes to transform differently\n",
    "    capture_image_classes = ['10Kwalk', 'battery','receipt']\n",
    "    return le.transform(capture_image_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c454bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d97a3c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img(path, sub_path=None):\n",
    "    try:\n",
    "        im_bgr = cv2.imread(path)\n",
    "        im_rgb = im_bgr[:, :, ::-1]\n",
    "        past_path = path\n",
    "    except: ## 이미지 에러 발생 시 백지로 대체\n",
    "        im_bgr = cv2.imread('../Data/carbon_reduction/temp_img.jpg')\n",
    "        im_rgb = im_bgr[:, :, ::-1]\n",
    "    return im_rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "884eb987-4341-4fe7-8094-6e61cb051af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = A.Compose([\n",
    "    A.OneOf([\n",
    "        A.Compose([\n",
    "            A.RandomResizedCrop(p=1, height=CFG['img_size'] ,width=CFG['img_size'], scale=(0.65, 0.75),ratio=(0.90, 1.10)),\n",
    "        ], p=0.8),\n",
    "        A.Compose([\n",
    "            A.Resize(p=1, height = CFG['img_size'], width = CFG['img_size']),\n",
    "        ], p=0.2),\n",
    "    ], p=1.0),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.SafeRotate(p=0.5, limit=(-20, 20), interpolation=2, border_mode=0, value=(0, 0, 0), mask_value=None),\n",
    "    A.ColorJitter(always_apply=True, p=0.5, contrast=0.2, saturation=0.3, hue=0.2),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, always_apply=True, p=1.0),\n",
    "    A.pytorch.transforms.ToTensorV2()\n",
    "        ])\n",
    "\n",
    "transform_train_cap = A.Compose([\n",
    "    A.OneOf([\n",
    "        A.Compose([\n",
    "            A.RandomResizedCrop(p=1, height=CFG['img_size'] ,width=CFG['img_size'], scale=(0.65, 0.85),ratio=(0.90, 1.10)),\n",
    "        ], p=0.6),\n",
    "        A.Compose([\n",
    "            A.Resize(p=1, height = CFG['img_size'], width = CFG['img_size']),\n",
    "        ], p=0.4),\n",
    "    ], p=1.0),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, always_apply=True, p=1.0),\n",
    "    A.pytorch.transforms.ToTensorV2()\n",
    "])\n",
    "\n",
    "transform_test = A.Compose([\n",
    "    A.Resize(height = CFG['img_size'], width = CFG['img_size']),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, p=1.0),\n",
    "    A.pytorch.transforms.ToTensorV2()\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f1561be",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, df, data_root, transform=None, transform2=None, output_label=True, encoded_class=False):\n",
    "        super(CustomDataset,self).__init__()\n",
    "        self.df = df.reset_index(drop=True).copy()\n",
    "        self.transform = transform\n",
    "        self.transform2 = transform2\n",
    "        self.data_root = data_root\n",
    "        self.output_label = output_label\n",
    "         \n",
    "        if encoded_class == True:\n",
    "            self.encoded_class = label_encoding_classes()\n",
    "        else:\n",
    "            self.encoded_class = encoded_class\n",
    "            \n",
    "        if output_label == True:\n",
    "            self.labels = self.df['label'].values\n",
    "        \n",
    "    # AUGMENTATION DIFFERENTLY DEPENDING ON THE TARGET\n",
    "    def custom_augmentation(self, img, target):\n",
    "        if self.encoded_class is not False and target in self.encoded_class:\n",
    "            return self.transform2(image=img)\n",
    "        else:\n",
    "            return self.transform(image=img)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index: int):\n",
    "        \n",
    "        # GET IMAGES\n",
    "        path = \"{}/{}\".format(self.data_root[index], self.df.iloc[index]['image_id'])\n",
    "        img  = get_img(path)\n",
    "        \n",
    "        # GET LABELS\n",
    "        if self.output_label:\n",
    "            target = self.labels[index]\n",
    "            \n",
    "            # CUSTOM AUGMENTATION\n",
    "            transformed = self.custom_augmentation(img, target) \n",
    "            img = transformed['image']\n",
    "            return img, target\n",
    "        else:\n",
    "            transformed =self.transform(image=img)\n",
    "            img = transformed['image']\n",
    "            return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7acf9a37-cf66-431c-85c2-d559515afe2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD PRE-TRAINED MODEL\n",
    "class Teacher(nn.Module):\n",
    "    def __init__(self, model_arch_str, num_classes= 2,pretrained=True):\n",
    "        super(Teacher, self).__init__()\n",
    "        model_arch = getattr(models, model_arch_str)\n",
    "        self.backbone = model_arch(pretrained=pretrained) ## 모델 선언 여기 models.##(pretrained =pretrained)\n",
    "        self.backbone.fc = nn.Linear(self.backbone.fc.in_features, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "240e5531",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataloader(df, trn_idx, val_idx, data_root=train.dir.values):\n",
    "    \n",
    "    train_ = df.loc[trn_idx,:].reset_index(drop=True)\n",
    "    valid_ = df.loc[val_idx,:].reset_index(drop=True)\n",
    "    train_data_root = data_root[trn_idx]\n",
    "    valid_data_root = data_root[val_idx]\n",
    "    \n",
    "        \n",
    "    train_ds = CustomDataset(train_, train_data_root, transform=transform_train,\n",
    "                            transform2=transform_train_cap, output_label=True, encoded_class=CFG['label_encoder'])\n",
    "    valid_ds = CustomDataset(valid_, valid_data_root, transform=transform_test,\n",
    "                            output_label=True)\n",
    "    # WEIGHTEDRANDOMSAMPLER\n",
    "    class_counts = train_.label.value_counts(sort=False).to_dict()\n",
    "    num_samples = sum(class_counts.values())\n",
    "    print(f'cls_cnts: {len(class_counts)}\\nnum_samples:{num_samples}')\n",
    "    \n",
    "    # weight 제작, 전체 학습 데이터 수를 해당 클래스의 데이터 수로 나누어 줌\n",
    "    class_weights = {l:round(num_samples/class_counts[l], 2) for l in class_counts.keys()}\n",
    "    t_labels = train_.label.to_list()\n",
    "    \n",
    "    # class 별 weight를 전체 trainset에 대응시켜 sampler에 넣어줌\n",
    "    weights = [class_weights[t_labels[i]] for i in range(int(num_samples))]\n",
    "\n",
    "\n",
    "    # weight 제작, 전체 학습 데이터 수를 해당 클래스의 데이터 수로 나누어 줌\n",
    "    class_weights = {l:round(num_samples/class_counts[l], 2) for l in class_counts.keys()}\n",
    "\n",
    "    # class 별 weight를 전체 trainset에 대응시켜 sampler에 넣어줌\n",
    "    weights = [class_weights[t_labels[i]] for i in range(int(num_samples))] \n",
    "    sampler = torch.utils.data.WeightedRandomSampler(torch.DoubleTensor(weights), int(num_samples))\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_ds,\n",
    "        batch_size=CFG['train_bs'],\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "        shuffle=False,\n",
    "        sampler=sampler, \n",
    "        num_workers=CFG['num_workers']\n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        valid_ds, \n",
    "        batch_size=CFG['valid_bs'],\n",
    "        num_workers=CFG['num_workers'],\n",
    "        shuffle=False,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "08ffa2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(epoch, model, loss_fn, optimizer, train_loader, device, scheduler=None):\n",
    "    t = time.time()\n",
    "    \n",
    "    # SET MODEL TRAINING MODE\n",
    "    model.train()\n",
    "    \n",
    "    running_loss = None\n",
    "    loss_sum = 0\n",
    "    image_preds_all = []\n",
    "    image_targets_all = []\n",
    "    acc_list = []\n",
    "    \n",
    "    pbar = tqdm(enumerate(train_loader), total=len(train_loader))\n",
    "    for step, (imgs, image_labels) in pbar:\n",
    "        imgs = imgs.to(device).float()\n",
    "        image_labels = image_labels.to(device).long()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # TEACHER MODEL PREDICTION\n",
    "        with torch.cuda.amp.autocast():\n",
    "            image_preds = model(imgs)   #output = model(input)\n",
    "\n",
    "            loss = loss_fn(image_preds, image_labels)\n",
    "            loss_sum+=loss.detach()\n",
    "            \n",
    "            # BACKPROPAGATION\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        \n",
    "            if running_loss is None:\n",
    "                running_loss = loss.item()\n",
    "            else:\n",
    "                running_loss = running_loss * .99 + loss.item() * .01    \n",
    "        \n",
    "            # TQDM VERBOSE_STEP TRACKING\n",
    "            if ((step + 1) % CFG['verbose_step'] == 0) or ((step + 1) == len(train_loader)):\n",
    "                description = f'epoch {epoch} loss: {running_loss:.4f}'\n",
    "                pbar.set_description(description)\n",
    "        \n",
    "        image_preds_all += [torch.argmax(image_preds, 1).detach().cpu().numpy()]\n",
    "        image_targets_all += [image_labels.detach().cpu().numpy()]\n",
    "        \n",
    "    if scheduler is not None:\n",
    "        scheduler.step()\n",
    "    \n",
    "    image_preds_all = np.concatenate(image_preds_all)\n",
    "    image_targets_all = np.concatenate(image_targets_all)\n",
    "    \n",
    "    matrix = confusion_matrix(image_targets_all,image_preds_all)\n",
    "    epoch_f1 = f1_score(image_targets_all, image_preds_all, average='macro')\n",
    "    \n",
    "    accuracy = (image_preds_all==image_targets_all).mean()\n",
    "    trn_loss = loss_sum/len(train_loader)\n",
    "    \n",
    "    return image_preds_all, accuracy, trn_loss, matrix, epoch_f1\n",
    "\n",
    "def valid_one_epoch(epoch, model, loss_fn, val_loader, device, scheduler=None, schd_loss_update=False):\n",
    "    t = time.time()\n",
    "    \n",
    "    # SET MODEL VALID MODE\n",
    "    model.eval()\n",
    "    \n",
    "    loss_sum = 0\n",
    "    sample_num = 0\n",
    "    avg_loss = 0\n",
    "    image_preds_all = []\n",
    "    image_targets_all = []\n",
    "    acc_list = []\n",
    "    \n",
    "    pbar = tqdm(enumerate(val_loader), total=len(val_loader))\n",
    "    for step, (imgs, image_labels) in pbar:\n",
    "        imgs = imgs.to(device).float()\n",
    "        image_labels = image_labels.to(device).long()\n",
    "        \n",
    "        # TEACHER MODEL PREDICTION\n",
    "        image_preds = model(imgs)\n",
    "        image_preds_all += [torch.argmax(image_preds, 1).detach().cpu().numpy()]\n",
    "        image_targets_all += [image_labels.detach().cpu().numpy()]\n",
    "        \n",
    "        loss = loss_fn(image_preds, image_labels)\n",
    "        \n",
    "        avg_loss += loss.item()\n",
    "        loss_sum += loss.item()*image_labels.shape[0]\n",
    "        sample_num += image_labels.shape[0]\n",
    "        \n",
    "        # TQDM\n",
    "        description = f'epoch {epoch} loss: {loss_sum/sample_num:.4f}'\n",
    "        pbar.set_description(description)\n",
    "    \n",
    "    image_preds_all = np.concatenate(image_preds_all)\n",
    "    image_targets_all = np.concatenate(image_targets_all)\n",
    "    matrix = confusion_matrix(image_targets_all,image_preds_all)\n",
    "    \n",
    "    epoch_f1 = f1_score(image_targets_all, image_preds_all, average='macro')\n",
    "    acc = (image_preds_all==image_targets_all).mean()\n",
    "    val_loss = avg_loss/len(val_loader)\n",
    "    \n",
    "    return image_preds_all, acc, val_loss, matrix, epoch_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "77e9950b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10, verbose=False, delta=0):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "\n",
    "    def __call__(self, score):\n",
    "        print(f' present score: {score}')\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "        elif score <= self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            print(f'Best F1 score from now: {self.best_score}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.counter = 0\n",
    "        \n",
    "        return self.early_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37102a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb26e8e89374427a90e1d5994548a024",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016669219016330318, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/hojun/git/KD_models/wandb/run-20230520_003608-sj9r2y4u</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/hojunking/KD_resnet152_dishes/runs/sj9r2y4u' target=\"_blank\">glad-waterfall-1</a></strong> to <a href='https://wandb.ai/hojunking/KD_resnet152_dishes' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/hojunking/KD_resnet152_dishes' target=\"_blank\">https://wandb.ai/hojunking/KD_resnet152_dishes</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/hojunking/KD_resnet152_dishes/runs/sj9r2y4u' target=\"_blank\">https://wandb.ai/hojunking/KD_resnet152_dishes/runs/sj9r2y4u</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: resnet152\n",
      "Training start with fold: 0 epoch: 200 \n",
      "\n",
      "cls_cnts: 3\n",
      "num_samples:3208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hojun/miniconda3/envs/torch/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/hojun/miniconda3/envs/torch/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet152_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet152_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 0\n",
      "Epoch 0/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 0 loss: 0.7822: 100%|████████████████████████████████████████████████████████████████████████| 51/51 [01:26<00:00,  1.69s/it]\n",
      "epoch 0 loss: 0.1303: 100%|████████████████████████████████████████████████████████████████████████| 13/13 [00:26<00:00,  2.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], Train Loss : [0.26559] Val Loss : [0.15026] Val F1 Score : [0.96485]\n",
      " present score: 0.9648492300931326\n",
      "Epoch 1/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 loss: 0.1206: 100%|████████████████████████████████████████████████████████████████████████| 51/51 [01:21<00:00,  1.60s/it]\n",
      "epoch 1 loss: 0.1013: 100%|████████████████████████████████████████████████████████████████████████| 13/13 [00:26<00:00,  2.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1], Train Loss : [0.13844] Val Loss : [0.11775] Val F1 Score : [0.97231]\n",
      " present score: 0.9723106082111399\n",
      "Epoch 2/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 2 loss: 0.0806: 100%|████████████████████████████████████████████████████████████████████████| 51/51 [01:27<00:00,  1.71s/it]\n",
      "epoch 2 loss: 0.1336: 100%|████████████████████████████████████████████████████████████████████████| 13/13 [00:26<00:00,  2.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2], Train Loss : [0.10645] Val Loss : [0.15526] Val F1 Score : [0.96097]\n",
      " present score: 0.9609740375426014\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Best F1 score from now: 0.9723106082111399\n",
      "Epoch 3/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 3 loss: 0.0885: 100%|████████████████████████████████████████████████████████████████████████| 51/51 [01:26<00:00,  1.70s/it]\n",
      "epoch 3 loss: 0.1269: 100%|████████████████████████████████████████████████████████████████████████| 13/13 [00:28<00:00,  2.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3], Train Loss : [0.09739] Val Loss : [0.14595] Val F1 Score : [0.95856]\n",
      " present score: 0.9585634344456239\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Best F1 score from now: 0.9723106082111399\n",
      "Epoch 4/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 4 loss: 0.0679: 100%|████████████████████████████████████████████████████████████████████████| 51/51 [01:27<00:00,  1.72s/it]\n",
      "epoch 4 loss: 0.1069: 100%|████████████████████████████████████████████████████████████████████████| 13/13 [00:29<00:00,  2.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4], Train Loss : [0.05884] Val Loss : [0.12064] Val F1 Score : [0.96502]\n",
      " present score: 0.9650187566535035\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Best F1 score from now: 0.9723106082111399\n",
      "Epoch 5/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 5 loss: 0.0438: 100%|████████████████████████████████████████████████████████████████████████| 51/51 [01:28<00:00,  1.74s/it]\n",
      "epoch 5 loss: 0.0815: 100%|████████████████████████████████████████████████████████████████████████| 13/13 [00:26<00:00,  2.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5], Train Loss : [0.04181] Val Loss : [0.09720] Val F1 Score : [0.97874]\n",
      " present score: 0.9787355187482346\n",
      "Epoch 6/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 6 loss: 0.0426: 100%|████████████████████████████████████████████████████████████████████████| 51/51 [01:30<00:00,  1.77s/it]\n",
      "epoch 6 loss: 0.0956: 100%|████████████████████████████████████████████████████████████████████████| 13/13 [00:30<00:00,  2.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6], Train Loss : [0.03713] Val Loss : [0.11426] Val F1 Score : [0.97386]\n",
      " present score: 0.973857770958824\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Best F1 score from now: 0.9787355187482346\n",
      "Epoch 7/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 7 loss: 0.0317: 100%|████████████████████████████████████████████████████████████████████████| 51/51 [01:37<00:00,  1.91s/it]\n",
      "epoch 7 loss: 0.1041: 100%|████████████████████████████████████████████████████████████████████████| 13/13 [00:27<00:00,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7], Train Loss : [0.02752] Val Loss : [0.12796] Val F1 Score : [0.97600]\n",
      " present score: 0.9760038845797608\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Best F1 score from now: 0.9787355187482346\n",
      "Epoch 8/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 8 loss: 0.0349: 100%|████████████████████████████████████████████████████████████████████████| 51/51 [01:30<00:00,  1.78s/it]\n",
      "epoch 8 loss: 0.0916: 100%|████████████████████████████████████████████████████████████████████████| 13/13 [00:29<00:00,  2.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8], Train Loss : [0.04216] Val Loss : [0.11726] Val F1 Score : [0.97600]\n",
      " present score: 0.976002781414687\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Best F1 score from now: 0.9787355187482346\n",
      "Epoch 9/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 9 loss: 0.0193: 100%|████████████████████████████████████████████████████████████████████████| 51/51 [01:28<00:00,  1.73s/it]\n",
      "epoch 9 loss: 0.1030: 100%|████████████████████████████████████████████████████████████████████████| 13/13 [00:26<00:00,  2.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9], Train Loss : [0.03908] Val Loss : [0.12774] Val F1 Score : [0.97358]\n",
      " present score: 0.9735751838752105\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Best F1 score from now: 0.9787355187482346\n",
      "Epoch 10/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 10 loss: 0.0096: 100%|███████████████████████████████████████████████████████████████████████| 51/51 [01:25<00:00,  1.67s/it]\n",
      "epoch 10 loss: 0.1043: 100%|███████████████████████████████████████████████████████████████████████| 13/13 [00:28<00:00,  2.22s/it]\n",
      "/home/hojun/miniconda3/envs/torch/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/hojun/miniconda3/envs/torch/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet152_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet152_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10], Train Loss : [0.01829] Val Loss : [0.13002] Val F1 Score : [0.97722]\n",
      " present score: 0.9772198794852516\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Best F1 score from now: 0.9787355187482346\n",
      "stop called\n",
      "time : 0:21:25\n",
      "fold: 0, Best Epoch : 5/ 11\n",
      "Best Train Marco F1 : 0.98565\n",
      "[[1072    7    7]\n",
      " [   7 1046   12]\n",
      " [   7    6 1044]]\n",
      "Best Valid Marco F1 : 0.97874\n",
      "[[243   6   3]\n",
      " [  0 292   4]\n",
      " [  2   2 250]]\n",
      "-----------------------------------------------------------------------\n",
      "Training start with fold: 1 epoch: 200 \n",
      "\n",
      "cls_cnts: 3\n",
      "num_samples:3208\n",
      "Fold: 1\n",
      "Epoch 0/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 0 loss: 0.7821: 100%|████████████████████████████████████████████████████████████████████████| 51/51 [01:26<00:00,  1.69s/it]\n",
      "epoch 0 loss: 0.1531: 100%|████████████████████████████████████████████████████████████████████████| 13/13 [00:25<00:00,  1.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], Train Loss : [0.24928] Val Loss : [0.15226] Val F1 Score : [0.94807]\n",
      " present score: 0.9480699767029304\n",
      "Epoch 1/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 1 loss: 0.0746: 100%|████████████████████████████████████████████████████████████████████████| 51/51 [01:20<00:00,  1.59s/it]\n",
      "epoch 1 loss: 0.1185: 100%|████████████████████████████████████████████████████████████████████████| 13/13 [00:25<00:00,  1.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1], Train Loss : [0.12527] Val Loss : [0.11875] Val F1 Score : [0.96012]\n",
      " present score: 0.9601225966023909\n",
      "Epoch 2/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 2 loss: 0.1440: 100%|████████████████████████████████████████████████████████████████████████| 51/51 [01:19<00:00,  1.55s/it]\n",
      "epoch 2 loss: 0.1059: 100%|████████████████████████████████████████████████████████████████████████| 13/13 [00:25<00:00,  1.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2], Train Loss : [0.10553] Val Loss : [0.10522] Val F1 Score : [0.96533]\n",
      " present score: 0.9653295045777582\n",
      "Epoch 3/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 3 loss: 0.1314: 100%|████████████████████████████████████████████████████████████████████████| 51/51 [01:21<00:00,  1.60s/it]\n",
      "epoch 3 loss: 0.1228: 100%|████████████████████████████████████████████████████████████████████████| 13/13 [00:26<00:00,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3], Train Loss : [0.10906] Val Loss : [0.12113] Val F1 Score : [0.95674]\n",
      " present score: 0.9567414876181184\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Best F1 score from now: 0.9653295045777582\n",
      "Epoch 4/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 4 loss: 0.0810: 100%|████████████████████████████████████████████████████████████████████████| 51/51 [01:28<00:00,  1.73s/it]\n",
      "epoch 4 loss: 0.0972: 100%|████████████████████████████████████████████████████████████████████████| 13/13 [00:26<00:00,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4], Train Loss : [0.10266] Val Loss : [0.09947] Val F1 Score : [0.96667]\n",
      " present score: 0.9666686128538403\n",
      "Epoch 5/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 5 loss: 0.0692: 100%|████████████████████████████████████████████████████████████████████████| 51/51 [01:29<00:00,  1.75s/it]\n",
      "epoch 5 loss: 0.0927: 100%|████████████████████████████████████████████████████████████████████████| 13/13 [00:29<00:00,  2.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5], Train Loss : [0.06938] Val Loss : [0.09538] Val F1 Score : [0.97164]\n",
      " present score: 0.9716386253536845\n",
      "Epoch 6/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 6 loss: 0.1548: 100%|████████████████████████████████████████████████████████████████████████| 51/51 [01:35<00:00,  1.88s/it]\n",
      "epoch 6 loss: 0.0797: 100%|████████████████████████████████████████████████████████████████████████| 13/13 [00:29<00:00,  2.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6], Train Loss : [0.05803] Val Loss : [0.08064] Val F1 Score : [0.97529]\n",
      " present score: 0.9752935032843134\n",
      "Epoch 7/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 7 loss: 0.0397: 100%|████████████████████████████████████████████████████████████████████████| 51/51 [01:30<00:00,  1.77s/it]\n",
      "epoch 7 loss: 0.0712: 100%|████████████████████████████████████████████████████████████████████████| 13/13 [00:29<00:00,  2.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7], Train Loss : [0.04455] Val Loss : [0.07062] Val F1 Score : [0.97641]\n",
      " present score: 0.9764095238667537\n",
      "Epoch 8/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 8 loss: 0.0494:  27%|███████████████████▊                                                    | 14/51 [00:32<00:50,  1.35s/it]"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    seed_everything(CFG['seed'])\n",
    "    \n",
    "    # WANDB TRACKER INIT\n",
    "    wandb.init(project=project_name, entity=user)\n",
    "    wandb.config.update(CFG)\n",
    "    wandb.run.name = run_name\n",
    "    wandb.define_metric(\"Train Accuracy\", step_metric=\"epoch\")\n",
    "    wandb.define_metric(\"Valid Accuracy\", step_metric=\"epoch\")\n",
    "    wandb.define_metric(\"Train Loss\", step_metric=\"epoch\")\n",
    "    wandb.define_metric(\"Valid Loss\", step_metric=\"epoch\")\n",
    "    wandb.define_metric(\"Train Macro F1 Score\", step_metric=\"epoch\")\n",
    "    wandb.define_metric(\"Valid Macro F1 Score\", step_metric=\"epoch\")\n",
    "    wandb.define_metric(\"Train-Valid Accuracy\", step_metric=\"epoch\")\n",
    "    \n",
    "    model_dir = CFG['model_path'] + '/{}'.format(run_name)\n",
    "    train_dir = train.dir.values\n",
    "    best_fold = 0\n",
    "    best_f1 =0.0\n",
    "    print('Model: {}'.format(CFG['model']))\n",
    "    # MAKE MODEL DIR\n",
    "    if not os.path.isdir(model_dir):\n",
    "        os.makedirs(model_dir)\n",
    "    \n",
    "    # STRATIFIED K-FOLD DEFINITION\n",
    "    folds = StratifiedKFold(n_splits=CFG['fold_num'], shuffle=True, random_state=CFG['seed']).split(np.arange(train.shape[0]), train.label.values)\n",
    "    \n",
    "    # TEST PROCESS FOLD BREAK\n",
    "    for fold, (trn_idx, val_idx) in enumerate(folds):\n",
    "        print(f'Training start with fold: {fold} epoch: {CFG[\"epochs\"]} \\n')\n",
    "\n",
    "        # EARLY STOPPING DEFINITION\n",
    "        early_stopping = EarlyStopping(patience=CFG[\"patience\"], verbose=True)\n",
    "\n",
    "        # DATALOADER DEFINITION\n",
    "        train_loader, val_loader = prepare_dataloader(train, trn_idx, val_idx, data_root=train_dir)\n",
    "\n",
    "        # MODEL & DEVICE DEFINITION \n",
    "        device = torch.device(CFG['device'])\n",
    "        model =Teacher(CFG['model'], train.label.nunique(), pretrained=True)\n",
    "        \n",
    "        # MODEL FREEZING\n",
    "        #model.freezing(freeze = CFG['freezing'], trainable_layer = CFG['trainable_layer'])\n",
    "        if CFG['freezing'] ==True:\n",
    "            for name, param in model.named_parameters():\n",
    "                if param.requires_grad == True:\n",
    "                    print(f\"{name}: {param.requires_grad}\")\n",
    "\n",
    "        model.to(device)\n",
    "        # MODEL DATA PARALLEL\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            model = nn.DataParallel(model)\n",
    "\n",
    "        scaler = torch.cuda.amp.GradScaler()   \n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=CFG['lr'])\n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, gamma=0.5, step_size=5)\n",
    "\n",
    "        # CRITERION (LOSS FUNCTION)\n",
    "        loss_tr = nn.CrossEntropyLoss().to(device) #MyCrossEntropyLoss().to(device)\n",
    "        loss_fn = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "        wandb.watch(model, loss_tr, log='all')\n",
    "        train_acc_list = []\n",
    "        train_matrix_list = []\n",
    "        train_f1_list = []\n",
    "        valid_acc_list = []\n",
    "        valid_matrix_list = []\n",
    "        valid_f1_list = []\n",
    "        \n",
    "\n",
    "        start = time.time()\n",
    "        print(f'Fold: {fold}')\n",
    "        for epoch in range(CFG['epochs']):\n",
    "            print('Epoch {}/{}'.format(epoch, CFG['epochs'] - 1))\n",
    "\n",
    "            # TRAINIG\n",
    "            train_preds_all, train_acc, train_loss, train_matrix, train_f1 = train_one_epoch(epoch, model, loss_tr,\n",
    "                                                                        optimizer, train_loader, device, scheduler=scheduler)\n",
    "            wandb.log({'Train Accuracy':train_acc, 'Train Loss' : train_loss, 'Train F1': train_f1, 'epoch' : epoch})\n",
    "\n",
    "            # VALIDATION\n",
    "            with torch.no_grad():\n",
    "                valid_preds_all, valid_acc, valid_loss, valid_matrix, valid_f1= valid_one_epoch(epoch, model, loss_fn,\n",
    "                                                                        val_loader, device, scheduler=None)\n",
    "                wandb.log({'Valid Accuracy':valid_acc, 'Valid Loss' : valid_loss, 'Valid F1': valid_f1 ,'epoch' : epoch})\n",
    "            print(f'Epoch [{epoch}], Train Loss : [{train_loss :.5f}] Val Loss : [{valid_loss :.5f}] Val F1 Score : [{valid_f1:.5f}]')\n",
    "            \n",
    "            # SAVE ALL RESULTS\n",
    "            train_acc_list.append(train_acc)\n",
    "            train_matrix_list.append(train_matrix)\n",
    "            train_f1_list.append(train_f1)\n",
    "\n",
    "            valid_acc_list.append(valid_acc)\n",
    "            valid_matrix_list.append(valid_matrix)\n",
    "            valid_f1_list.append(valid_f1)\n",
    "\n",
    "            # MODEL SAVE (THE BEST MODEL OF ALL OF FOLD PROCESS)\n",
    "            if valid_f1 > best_f1:\n",
    "                best_f1 = valid_f1\n",
    "                best_epoch = epoch\n",
    "                # SAVE WITH DATAPARARELLEL WRAPPER\n",
    "                #torch.save(model.state_dict(), (model_dir+'/{}.pth').format(CFG['model']))\n",
    "                # SAVE WITHOUT DATAPARARELLEL WRAPPER\n",
    "                torch.save(model.module.state_dict(), (model_dir+'/{}.pth').format(CFG['model']))\n",
    "\n",
    "            # EARLY STOPPING\n",
    "            stop = early_stopping(valid_f1)\n",
    "            if stop:\n",
    "                print(\"stop called\")   \n",
    "                break\n",
    "\n",
    "        end = time.time() - start\n",
    "        time_ = str(datetime.timedelta(seconds=end)).split(\".\")[0]\n",
    "        print(\"time :\", time_)\n",
    "\n",
    "        # PRINT BEST F1 SCORE MODEL OF FOLD\n",
    "        best_index = valid_f1_list.index(max(valid_f1_list))\n",
    "        print(f'fold: {fold}, Best Epoch : {best_index}/ {len(valid_f1_list)}')\n",
    "        print(f'Best Train Marco F1 : {train_f1_list[best_index]:.5f}')\n",
    "        print(train_matrix_list[best_index])\n",
    "        print(f'Best Valid Marco F1 : {valid_f1_list[best_index]:.5f}')\n",
    "        print(valid_matrix_list[best_index])\n",
    "        print('-----------------------------------------------------------------------')\n",
    "\n",
    "        # K-FOLD END\n",
    "        if valid_f1_list[best_index] > best_fold:\n",
    "            best_fold = valid_f1_list[best_index]\n",
    "            top_fold = fold\n",
    "    print(f'Best Fold F1 score: {best_fold} Top fold : {top_fold}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "93dba2e1-92a8-4e81-89e8-17005fb81bbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>dir</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0282.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/test/10Kwalk</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0466.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/test/10Kwalk</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0190.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/test/10Kwalk</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0234.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/test/10Kwalk</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0392.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/test/10Kwalk</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13688</th>\n",
       "      <td>0381.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/test/wrap</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13689</th>\n",
       "      <td>0236.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/test/wrap</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13690</th>\n",
       "      <td>0384.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/test/wrap</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13691</th>\n",
       "      <td>0074.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/test/wrap</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13692</th>\n",
       "      <td>0011.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/test/wrap</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13693 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       image_id                                         dir  label\n",
       "0      0282.jpg  ../Data/carbon_reduction_data/test/10Kwalk      0\n",
       "1      0466.jpg  ../Data/carbon_reduction_data/test/10Kwalk      0\n",
       "2      0190.jpg  ../Data/carbon_reduction_data/test/10Kwalk      0\n",
       "3      0234.jpg  ../Data/carbon_reduction_data/test/10Kwalk      0\n",
       "4      0392.jpg  ../Data/carbon_reduction_data/test/10Kwalk      0\n",
       "...         ...                                         ...    ...\n",
       "13688  0381.jpg     ../Data/carbon_reduction_data/test/wrap     18\n",
       "13689  0236.jpg     ../Data/carbon_reduction_data/test/wrap     18\n",
       "13690  0384.jpg     ../Data/carbon_reduction_data/test/wrap     18\n",
       "13691  0074.jpg     ../Data/carbon_reduction_data/test/wrap     18\n",
       "13692  0011.jpg     ../Data/carbon_reduction_data/test/wrap     18\n",
       "\n",
       "[13693 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "681ed966-953b-4533-a9b5-1438c1bb27de",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################## inference #############################\n",
    "def inference(model, data_loader, device):\n",
    "    model.eval()\n",
    "    image_preds_all = []\n",
    "    \n",
    "    pbar = tqdm(enumerate(data_loader), total=len(data_loader))\n",
    "    for step, (imgs) in pbar:\n",
    "        imgs = imgs.to(device).float()\n",
    "\n",
    "        image_preds = model(imgs)   #output = model(input)\n",
    "        image_preds_all += [torch.softmax(image_preds, 1).detach().cpu().numpy()]\n",
    "    \n",
    "    image_preds_all = np.concatenate(image_preds_all, axis=0)\n",
    "    return image_preds_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1f910c08-4857-43b4-b499-b5a7d799e5b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hojun/miniconda3/envs/torch/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/hojun/miniconda3/envs/torch/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet152_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet152_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:43<00:00,  2.05s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>dir</th>\n",
       "      <th>label</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0282.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/test/wrap</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0190.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/test/wrap</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0234.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/test/wrap</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0392.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/test/wrap</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0375.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/test/wrap</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1334</th>\n",
       "      <td>0381.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/test/green dish</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1335</th>\n",
       "      <td>0236.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/test/green dish</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336</th>\n",
       "      <td>0384.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/test/green dish</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1337</th>\n",
       "      <td>0074.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/test/green dish</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1338</th>\n",
       "      <td>0011.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/test/green dish</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1339 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      image_id                                            dir  label  pred\n",
       "0     0282.jpg        ../Data/carbon_reduction_data/test/wrap      2     2\n",
       "1     0190.jpg        ../Data/carbon_reduction_data/test/wrap      2     2\n",
       "2     0234.jpg        ../Data/carbon_reduction_data/test/wrap      2     2\n",
       "3     0392.jpg        ../Data/carbon_reduction_data/test/wrap      2     2\n",
       "4     0375.jpg        ../Data/carbon_reduction_data/test/wrap      2     2\n",
       "...        ...                                            ...    ...   ...\n",
       "1334  0381.jpg  ../Data/carbon_reduction_data/test/green dish      0     0\n",
       "1335  0236.jpg  ../Data/carbon_reduction_data/test/green dish      0     0\n",
       "1336  0384.jpg  ../Data/carbon_reduction_data/test/green dish      0     0\n",
       "1337  0074.jpg  ../Data/carbon_reduction_data/test/green dish      0     0\n",
       "1338  0011.jpg  ../Data/carbon_reduction_data/test/green dish      0     0\n",
       "\n",
       "[1339 rows x 4 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RUN INFERENCE\n",
    "model = Teacher(CFG['model'], test.label.nunique(), pretrained=True)\n",
    "load_model = CFG['model_path'] + '/KD_resnet152_dishes_202305200035/' + CFG['model'] + '.pth'\n",
    "test_dir = test.dir.values\n",
    "\n",
    "tst_ds = CustomDataset(test, test_dir, transform=transform_test, output_label=False)\n",
    "tst_loader = torch.utils.data.DataLoader(\n",
    "    tst_ds, \n",
    "    batch_size=CFG['train_bs'],\n",
    "    num_workers=CFG['num_workers'],\n",
    "    shuffle=False,\n",
    "    pin_memory=True\n",
    ")\n",
    "device = torch.device(CFG['device'])\n",
    "\n",
    "# INFERENCE VIA MULTI-GPU\n",
    "# if torch.cuda.device_count() > 1:\n",
    "#         model = nn.DataParallel(model)\n",
    "model.to(device)\n",
    "\n",
    "# RUN INFERENCE\n",
    "predictions = []\n",
    "model.load_state_dict(torch.load(load_model))\n",
    "with torch.no_grad():\n",
    "    predictions += [inference(model, tst_loader, device)]\n",
    "\n",
    "\n",
    "predictions = np.mean(predictions, axis=0) \n",
    "test['pred'] = np.argmax(predictions, axis=1)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6dc9d547-6d2c-4d13-95c6-f9baf6e0f5da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>dir</th>\n",
       "      <th>label</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0282.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/test/wrap</td>\n",
       "      <td>wrap</td>\n",
       "      <td>wrap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0190.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/test/wrap</td>\n",
       "      <td>wrap</td>\n",
       "      <td>wrap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0234.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/test/wrap</td>\n",
       "      <td>wrap</td>\n",
       "      <td>wrap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0392.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/test/wrap</td>\n",
       "      <td>wrap</td>\n",
       "      <td>wrap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0375.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/test/wrap</td>\n",
       "      <td>wrap</td>\n",
       "      <td>wrap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1334</th>\n",
       "      <td>0381.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/test/green dish</td>\n",
       "      <td>green dish</td>\n",
       "      <td>green dish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1335</th>\n",
       "      <td>0236.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/test/green dish</td>\n",
       "      <td>green dish</td>\n",
       "      <td>green dish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336</th>\n",
       "      <td>0384.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/test/green dish</td>\n",
       "      <td>green dish</td>\n",
       "      <td>green dish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1337</th>\n",
       "      <td>0074.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/test/green dish</td>\n",
       "      <td>green dish</td>\n",
       "      <td>green dish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1338</th>\n",
       "      <td>0011.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/test/green dish</td>\n",
       "      <td>green dish</td>\n",
       "      <td>green dish</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1339 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      image_id                                            dir       label  \\\n",
       "0     0282.jpg        ../Data/carbon_reduction_data/test/wrap        wrap   \n",
       "1     0190.jpg        ../Data/carbon_reduction_data/test/wrap        wrap   \n",
       "2     0234.jpg        ../Data/carbon_reduction_data/test/wrap        wrap   \n",
       "3     0392.jpg        ../Data/carbon_reduction_data/test/wrap        wrap   \n",
       "4     0375.jpg        ../Data/carbon_reduction_data/test/wrap        wrap   \n",
       "...        ...                                            ...         ...   \n",
       "1334  0381.jpg  ../Data/carbon_reduction_data/test/green dish  green dish   \n",
       "1335  0236.jpg  ../Data/carbon_reduction_data/test/green dish  green dish   \n",
       "1336  0384.jpg  ../Data/carbon_reduction_data/test/green dish  green dish   \n",
       "1337  0074.jpg  ../Data/carbon_reduction_data/test/green dish  green dish   \n",
       "1338  0011.jpg  ../Data/carbon_reduction_data/test/green dish  green dish   \n",
       "\n",
       "            pred  \n",
       "0           wrap  \n",
       "1           wrap  \n",
       "2           wrap  \n",
       "3           wrap  \n",
       "4           wrap  \n",
       "...          ...  \n",
       "1334  green dish  \n",
       "1335  green dish  \n",
       "1336  green dish  \n",
       "1337  green dish  \n",
       "1338  green dish  \n",
       "\n",
       "[1339 rows x 4 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['label'] = le.inverse_transform(test['label'].values)\n",
    "test['pred'] = le.inverse_transform(test['pred'].values)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "da647547-7a7b-4690-94df-bb42ca426f3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9746\n",
      "f1_score: 0.9745\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1500x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "test_acc = np.sum(test.label == test.pred) / len(test)\n",
    "test_matrix = confusion_matrix(test['label'], test['pred'])\n",
    "epoch_f1 = f1_score(test['label'], test['pred'], average='macro')\n",
    "print(f'accuracy: {test_acc:.4f}')\n",
    "print(f'f1_score: {epoch_f1:.4f}')\n",
    "\n",
    "test_matrix = confusion_matrix(test['label'], test['pred'], normalize='true')\n",
    "#test_matrix = confusion_matrix(test['label'], test['pred'])\n",
    "\n",
    "plt.figure(figsize = (15,10))\n",
    "sns.heatmap(test_matrix, \n",
    "            annot=True, \n",
    "            xticklabels = sorted(set(test['label'])), \n",
    "            yticklabels = sorted(set(test['label'])),\n",
    "            )\n",
    "plt.title('Normalized Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "#print(f'confusion_matrix \\n-------------------------\\n {test_matrix}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ab89fde5-9498-4a99-8bb8-4af301e4a6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv('test_result/incep_res_0403.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d8cbfb49-98dd-4d2f-a778-21764270d9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import jsonlines\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3d9a4c94-8eb0-49f1-9e94-d412533a498b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bottle            1229\n",
       "dishes            1163\n",
       "stairs             806\n",
       "else               597\n",
       "plug               593\n",
       "battery            501\n",
       "transportation     458\n",
       "handkerchief       443\n",
       "10Kwalk            411\n",
       "pet                410\n",
       "shopping bag       409\n",
       "box                382\n",
       "paper              374\n",
       "milk               371\n",
       "trash picking      325\n",
       "receipt            288\n",
       "Name: pred, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['pred'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fe7bc385-c882-4830-81f9-e6494fab928d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1475945/30508609.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  label.sort_values(by=['image_id'],ascending=True, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>dir</th>\n",
       "      <th>label</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10Kwalk_1047.jpg</td>\n",
       "      <td>../Data/carbon_data/10Kwalk</td>\n",
       "      <td>10Kwalk</td>\n",
       "      <td>else</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10Kwalk_1174.jpg</td>\n",
       "      <td>../Data/carbon_data/10Kwalk</td>\n",
       "      <td>10Kwalk</td>\n",
       "      <td>else</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16583193231991658319380893.jpg</td>\n",
       "      <td>../Data/carbon_data/else/instance_spoon</td>\n",
       "      <td>else</td>\n",
       "      <td>else</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16583311864571658331260534.jpg</td>\n",
       "      <td>../Data/carbon_data/else/instance_spoon</td>\n",
       "      <td>else</td>\n",
       "      <td>else</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20220722_125118_HDR1658461897787.jpg</td>\n",
       "      <td>../Data/carbon_data/else/instance_spoon</td>\n",
       "      <td>else</td>\n",
       "      <td>else</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>wrap_990.jpg</td>\n",
       "      <td>../Data/carbon_data/dishes/wrap</td>\n",
       "      <td>dishes</td>\n",
       "      <td>else</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>wrap_995.jpg</td>\n",
       "      <td>../Data/carbon_data/dishes/wrap</td>\n",
       "      <td>dishes</td>\n",
       "      <td>else</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>양치컵 사용_063.jpg</td>\n",
       "      <td>../Data/carbon_data/bottle/toothcup/toothcup_852</td>\n",
       "      <td>bottle</td>\n",
       "      <td>else</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>양치컵 사용_140.jpg</td>\n",
       "      <td>../Data/carbon_data/bottle/toothcup/toothcup_852</td>\n",
       "      <td>bottle</td>\n",
       "      <td>else</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>양치컵 사용_175.jpg</td>\n",
       "      <td>../Data/carbon_data/bottle/toothcup/toothcup_852</td>\n",
       "      <td>bottle</td>\n",
       "      <td>else</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>597 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 image_id  \\\n",
       "0                        10Kwalk_1047.jpg   \n",
       "1                        10Kwalk_1174.jpg   \n",
       "2          16583193231991658319380893.jpg   \n",
       "3          16583311864571658331260534.jpg   \n",
       "4    20220722_125118_HDR1658461897787.jpg   \n",
       "..                                    ...   \n",
       "592                          wrap_990.jpg   \n",
       "593                          wrap_995.jpg   \n",
       "594                        양치컵 사용_063.jpg   \n",
       "595                        양치컵 사용_140.jpg   \n",
       "596                        양치컵 사용_175.jpg   \n",
       "\n",
       "                                                  dir    label  pred  \n",
       "0                         ../Data/carbon_data/10Kwalk  10Kwalk  else  \n",
       "1                         ../Data/carbon_data/10Kwalk  10Kwalk  else  \n",
       "2             ../Data/carbon_data/else/instance_spoon     else  else  \n",
       "3             ../Data/carbon_data/else/instance_spoon     else  else  \n",
       "4             ../Data/carbon_data/else/instance_spoon     else  else  \n",
       "..                                                ...      ...   ...  \n",
       "592                   ../Data/carbon_data/dishes/wrap   dishes  else  \n",
       "593                   ../Data/carbon_data/dishes/wrap   dishes  else  \n",
       "594  ../Data/carbon_data/bottle/toothcup/toothcup_852   bottle  else  \n",
       "595  ../Data/carbon_data/bottle/toothcup/toothcup_852   bottle  else  \n",
       "596  ../Data/carbon_data/bottle/toothcup/toothcup_852   bottle  else  \n",
       "\n",
       "[597 rows x 4 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_list = []\n",
    "label = test[test.pred == 'else']\n",
    "\n",
    "label.sort_values(by=['image_id'],ascending=True, inplace=True)\n",
    "label.reset_index(inplace=True, drop=True)\n",
    "tmp = label['image_id'].value_counts().index.sort_values()\n",
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ab3b8b-043d-4d3b-b14f-13564a985766",
   "metadata": {},
   "outputs": [],
   "source": [
    "## show img status\n",
    "\n",
    "back = 0\n",
    "plt.figure(figsize=(16,500))\n",
    "for i in range(len(label[200:400])):\n",
    "    plt.subplot(100,4,i+1)\n",
    "    if i % 4 == 0:\n",
    "        plt.title(f\"{(i+1+back)/4}\")\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "        \n",
    "    path = label['dir'][i] + '/' + label['image_id'][i]\n",
    "    try:\n",
    "    # im_bgr = cv2.imread(path)\n",
    "    # im_rgb = im_bgr[:, :, ::-1]\n",
    "        temp = Image.open(path).convert(\"RGB\")\n",
    "        image = np.array(temp).copy()\n",
    "        temp.close()\n",
    "\n",
    "        plt.imshow(image, cmap=plt.cm.binary)\n",
    "        plt.xlabel(label['image_id'][i], loc='left', fontsize=10)\n",
    "    except:\n",
    "        plt.xlabel(path, loc='left', fontsize=10)\n",
    "        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4949b731-608b-43b9-93fa-c4ef70c28a09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-gpu",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
