{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32c4ea0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, magic, shutil\n",
    "from glob import glob\n",
    "import time, datetime\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import joblib\n",
    "import datetime as dt\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torch, gc\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "\n",
    "#from skimage import io\n",
    "import sklearn\n",
    "from sklearn.model_selection import GroupKFold, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, log_loss, f1_score, confusion_matrix, classification_report\n",
    "from sklearn import metrics, preprocessing\n",
    "from scipy.ndimage import zoom\n",
    "\n",
    "import timm\n",
    "from timm.data import resolve_data_config\n",
    "from timm.data.transforms_factory import create_transform\n",
    "import albumentations as A\n",
    "import albumentations.pytorch\n",
    "import wandb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29d0796-1f1d-40df-ad4a-21f57ed7fe35",
   "metadata": {},
   "source": [
    "#### Hyper Param Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57c0283c",
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'fold_num': 5,\n",
    "    'seed': 42,\n",
    "    'model': 'resnet152',\n",
    "    'img_size': 260,\n",
    "    'epochs': 200,\n",
    "    'train_bs':64,\n",
    "    'valid_bs':64,\n",
    "    'lr': 1e-4, ## learning rate\n",
    "    'num_workers': 8,\n",
    "    'verbose_step': 1,\n",
    "    'patience' : 5,\n",
    "    'label_encoder':None,\n",
    "    'device': 'cuda:0',\n",
    "    'freezing': False,\n",
    "    'trainable_layer': 12,\n",
    "    'model_path': './models'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7066a8a1-7060-4b6d-bf0c-d4164820a414",
   "metadata": {},
   "source": [
    "#### wandb init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "127461e4-c16d-47fd-b983-556c12ad0daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "category = 'pet'\n",
    "time_now = dt.datetime.now()\n",
    "run_id = time_now.strftime(\"%Y%m%d%H%M\")\n",
    "project_name = 'KD_'+ CFG['model'] + '_' + category\n",
    "user = 'hojunking'\n",
    "run_name = project_name + '_' + run_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b6c4553-4301-4ba8-801e-e7130ac0b3cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: pet 2404\n",
      "label: labeled 4529\n",
      "Train_Images:  5546\n",
      "Train_Images_labels: 5546\n",
      "Test_Images:  1387\n",
      "Test_Images_labels: 1387\n",
      "All data 6933\n"
     ]
    }
   ],
   "source": [
    "# Data split\n",
    "main_path = '../Data/carbon_data/'\n",
    "label_list = [\"pet\",\"labeled\"]\n",
    "\n",
    "total_train_img_paths = []\n",
    "total_train_img_labels = []\n",
    "total_test_img_paths = []\n",
    "total_test_img_labels = []\n",
    "\n",
    "for label in label_list: ## 각 레이블 돌기\n",
    "    print(f'label: {label}',end=' ')\n",
    "    img_paths = [] \n",
    "    img_labels = []\n",
    "\n",
    "    # default ratio\n",
    "    train_ratio = 1500\n",
    "    test_ratio = 500\n",
    "\n",
    "    dir_path = main_path + label ## 레이블 폴더 경로\n",
    "    count = 0\n",
    "    for folder, subfolders, filenames in os.walk(dir_path): ## 폴더 내 모든 파일 탐색\n",
    "    \n",
    "        for img in filenames: ## 각 파일 경로, 레이블 저장\n",
    "            count +=1\n",
    "            if count > train_ratio + test_ratio + 10000:\n",
    "                break\n",
    "            \n",
    "            img_paths.append(folder+'/'+img)\n",
    "            img_labels.append(label)\n",
    "        \n",
    "    print(len(img_paths))\n",
    "\n",
    "    if label == 'labeled': ##  데이터 비율 설정하기 \n",
    "        train_ratio = 3623\n",
    "        test_ratio = 906\n",
    "    elif label == 'pet': ##  데이터 비율 설정하기 \n",
    "        train_ratio = 1923\n",
    "        test_ratio = 481\n",
    "        \n",
    "    total_train_img_paths.extend(img_paths[:train_ratio])\n",
    "    total_train_img_labels.extend(img_labels[:train_ratio])\n",
    "\n",
    "    total_test_img_paths.extend(img_paths[-test_ratio:])\n",
    "    total_test_img_labels.extend(img_labels[-test_ratio:])\n",
    "\n",
    "print('Train_Images: ',len(total_train_img_paths))\n",
    "print(\"Train_Images_labels:\", len(total_train_img_labels))\n",
    "print('Test_Images: ',len(total_test_img_paths))\n",
    "print(\"Test_Images_labels:\", len(total_test_img_labels))\n",
    "print(\"All data\",len(total_train_img_paths) + len(total_test_img_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2716dd8b-84db-4707-80e2-19b29eae9c23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>dir</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pet_1214.jpg</td>\n",
       "      <td>../Data/carbon_data/pet</td>\n",
       "      <td>pet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pet_663.jpg</td>\n",
       "      <td>../Data/carbon_data/pet</td>\n",
       "      <td>pet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pet_2262.jpg</td>\n",
       "      <td>../Data/carbon_data/pet</td>\n",
       "      <td>pet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pet_780.jpg</td>\n",
       "      <td>../Data/carbon_data/pet</td>\n",
       "      <td>pet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pet_176.jpg</td>\n",
       "      <td>../Data/carbon_data/pet</td>\n",
       "      <td>pet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5541</th>\n",
       "      <td>pte (872).jpg</td>\n",
       "      <td>../Data/carbon_data/labeled</td>\n",
       "      <td>labeled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5542</th>\n",
       "      <td>pet36594.jpg</td>\n",
       "      <td>../Data/carbon_data/labeled</td>\n",
       "      <td>labeled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5543</th>\n",
       "      <td>2634_jpg.rf.c07e985b8263d33898e6a2dcdec88b08.jpg</td>\n",
       "      <td>../Data/carbon_data/labeled</td>\n",
       "      <td>labeled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5544</th>\n",
       "      <td>2969_jpg.rf.5f6f9269090b49fdab83153569e91038.jpg</td>\n",
       "      <td>../Data/carbon_data/labeled</td>\n",
       "      <td>labeled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5545</th>\n",
       "      <td>pet8979.jpg</td>\n",
       "      <td>../Data/carbon_data/labeled</td>\n",
       "      <td>labeled</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5546 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              image_id  \\\n",
       "0                                         pet_1214.jpg   \n",
       "1                                          pet_663.jpg   \n",
       "2                                         pet_2262.jpg   \n",
       "3                                          pet_780.jpg   \n",
       "4                                          pet_176.jpg   \n",
       "...                                                ...   \n",
       "5541                                     pte (872).jpg   \n",
       "5542                                      pet36594.jpg   \n",
       "5543  2634_jpg.rf.c07e985b8263d33898e6a2dcdec88b08.jpg   \n",
       "5544  2969_jpg.rf.5f6f9269090b49fdab83153569e91038.jpg   \n",
       "5545                                       pet8979.jpg   \n",
       "\n",
       "                              dir    label  \n",
       "0         ../Data/carbon_data/pet      pet  \n",
       "1         ../Data/carbon_data/pet      pet  \n",
       "2         ../Data/carbon_data/pet      pet  \n",
       "3         ../Data/carbon_data/pet      pet  \n",
       "4         ../Data/carbon_data/pet      pet  \n",
       "...                           ...      ...  \n",
       "5541  ../Data/carbon_data/labeled  labeled  \n",
       "5542  ../Data/carbon_data/labeled  labeled  \n",
       "5543  ../Data/carbon_data/labeled  labeled  \n",
       "5544  ../Data/carbon_data/labeled  labeled  \n",
       "5545  ../Data/carbon_data/labeled  labeled  \n",
       "\n",
       "[5546 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Pandas 데이터프레임 만들기\n",
    "trn_df = pd.DataFrame(total_train_img_paths, columns=['image_id'])\n",
    "trn_df['dir'] = trn_df['image_id'].apply(lambda x: os.path.dirname(x))\n",
    "trn_df['image_id'] = trn_df['image_id'].apply(lambda x: os.path.basename(x))\n",
    "trn_df['label'] = total_train_img_labels\n",
    "train = trn_df\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf387b57-bb5d-4564-96db-d764e547a93a",
   "metadata": {},
   "source": [
    "##### Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03c67d39-7933-4f98-b998-54a6036ff4a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>dir</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pet_1214.jpg</td>\n",
       "      <td>../Data/carbon_data/pet</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pet_663.jpg</td>\n",
       "      <td>../Data/carbon_data/pet</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pet_2262.jpg</td>\n",
       "      <td>../Data/carbon_data/pet</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pet_780.jpg</td>\n",
       "      <td>../Data/carbon_data/pet</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pet_176.jpg</td>\n",
       "      <td>../Data/carbon_data/pet</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5541</th>\n",
       "      <td>pte (872).jpg</td>\n",
       "      <td>../Data/carbon_data/labeled</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5542</th>\n",
       "      <td>pet36594.jpg</td>\n",
       "      <td>../Data/carbon_data/labeled</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5543</th>\n",
       "      <td>2634_jpg.rf.c07e985b8263d33898e6a2dcdec88b08.jpg</td>\n",
       "      <td>../Data/carbon_data/labeled</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5544</th>\n",
       "      <td>2969_jpg.rf.5f6f9269090b49fdab83153569e91038.jpg</td>\n",
       "      <td>../Data/carbon_data/labeled</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5545</th>\n",
       "      <td>pet8979.jpg</td>\n",
       "      <td>../Data/carbon_data/labeled</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5546 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              image_id  \\\n",
       "0                                         pet_1214.jpg   \n",
       "1                                          pet_663.jpg   \n",
       "2                                         pet_2262.jpg   \n",
       "3                                          pet_780.jpg   \n",
       "4                                          pet_176.jpg   \n",
       "...                                                ...   \n",
       "5541                                     pte (872).jpg   \n",
       "5542                                      pet36594.jpg   \n",
       "5543  2634_jpg.rf.c07e985b8263d33898e6a2dcdec88b08.jpg   \n",
       "5544  2969_jpg.rf.5f6f9269090b49fdab83153569e91038.jpg   \n",
       "5545                                       pet8979.jpg   \n",
       "\n",
       "                              dir  label  \n",
       "0         ../Data/carbon_data/pet      1  \n",
       "1         ../Data/carbon_data/pet      1  \n",
       "2         ../Data/carbon_data/pet      1  \n",
       "3         ../Data/carbon_data/pet      1  \n",
       "4         ../Data/carbon_data/pet      1  \n",
       "...                           ...    ...  \n",
       "5541  ../Data/carbon_data/labeled      0  \n",
       "5542  ../Data/carbon_data/labeled      0  \n",
       "5543  ../Data/carbon_data/labeled      0  \n",
       "5544  ../Data/carbon_data/labeled      0  \n",
       "5545  ../Data/carbon_data/labeled      0  \n",
       "\n",
       "[5546 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "train['label'] = le.fit_transform(train['label'].values)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29be149b-1ea0-4e34-846e-7395d4e94f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_encoding_classes():\n",
    "    # define certain classes to transform differently\n",
    "    capture_image_classes = ['10Kwalk', 'battery','receipt']\n",
    "    return le.transform(capture_image_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c454bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d97a3c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img(path, sub_path=None):\n",
    "    try:\n",
    "        im_bgr = cv2.imread(path)\n",
    "        im_rgb = im_bgr[:, :, ::-1]\n",
    "        past_path = path\n",
    "    except: ## 이미지 에러 발생 시 백지로 대체\n",
    "        im_bgr = cv2.imread('../Data/carbon_reduction/temp_img.jpg')\n",
    "        im_rgb = im_bgr[:, :, ::-1]\n",
    "    return im_rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "884eb987-4341-4fe7-8094-6e61cb051af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = A.Compose(\n",
    "    [\n",
    "        A.RandomResizedCrop(p=1, height=CFG['img_size'] ,width=CFG['img_size'], scale=(0.65, 0.75),ratio=(0.90, 1.10)),\n",
    "        A.SafeRotate(p=0.5, limit=(-20, 20), interpolation=2, border_mode=0, value=(0, 0, 0), mask_value=None),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.ColorJitter(always_apply=True, p=0.5, contrast=0.2, saturation=0.3, hue=0.2),\n",
    "        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, always_apply=False, p=1.0),\n",
    "        A.pytorch.transforms.ToTensorV2()\n",
    "        ])\n",
    "\n",
    "transform_train_cap = A.Compose(\n",
    "    [\n",
    "        A.RandomResizedCrop(p=1, height=CFG['img_size'] ,width=CFG['img_size'], scale=(0.65, 0.85),ratio=(0.90, 1.10)),\n",
    "        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, always_apply=False, p=1.0),\n",
    "        A.pytorch.transforms.ToTensorV2()\n",
    "        ])\n",
    "\n",
    "transform_test = A.Compose(\n",
    "    [\n",
    "        A.Resize(height = CFG['img_size'], width = CFG['img_size']),\n",
    "        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, always_apply=False, p=1.0),\n",
    "        A.pytorch.transforms.ToTensorV2()\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f1561be",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, df, data_root, transform=None, transform2=None, output_label=True, encoded_class=None):\n",
    "        super(CustomDataset,self).__init__()\n",
    "        self.df = df.reset_index(drop=True).copy()\n",
    "        self.transform = transform\n",
    "        self.transform2 = transform2\n",
    "        self.data_root = data_root\n",
    "        self.output_label = output_label\n",
    "         \n",
    "        if encoded_class == True:\n",
    "            self.encoded_class = label_encoding_classes()\n",
    "        else:\n",
    "            self.encoded_class = encoded_class\n",
    "            \n",
    "        if output_label == True:\n",
    "            self.labels = self.df['label'].values\n",
    "        \n",
    "    # AUGMENTATION DIFFERENTLY DEPENDING ON THE TARGET\n",
    "    def custom_augmentation(self, img, target):\n",
    "        if self.encoded_class is not None and target in self.encoded_class:\n",
    "            return self.transform2(image=img)\n",
    "        else:\n",
    "            return self.transform(image=img)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index: int):\n",
    "        \n",
    "        # GET IMAGES\n",
    "        path = \"{}/{}\".format(self.data_root[index], self.df.iloc[index]['image_id'])\n",
    "        img  = get_img(path)\n",
    "        \n",
    "        # GET LABELS\n",
    "        if self.output_label:\n",
    "            target = self.labels[index]\n",
    "            \n",
    "            # CUSTOM AUGMENTATION\n",
    "            transformed = self.custom_augmentation(img, target) \n",
    "            img = transformed['image']\n",
    "            return img, target\n",
    "        else:\n",
    "            transformed =self.transform(image=img)\n",
    "            img = transformed['image']\n",
    "            return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7acf9a37-cf66-431c-85c2-d559515afe2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD PRE-TRAINED MODEL\n",
    "class Teacher(nn.Module):\n",
    "    def __init__(self, model_arch_str, num_classes= 2,pretrained=True):\n",
    "        super(Teacher, self).__init__()\n",
    "        model_arch = getattr(models, model_arch_str)\n",
    "        self.backbone = model_arch(pretrained=pretrained) ## 모델 선언 여기 models.##(pretrained =pretrained)\n",
    "        self.backbone.fc = nn.Linear(self.backbone.fc.in_features, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "240e5531",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataloader(df, trn_idx, val_idx, data_root=train.dir.values):\n",
    "    \n",
    "    train_ = df.loc[trn_idx,:].reset_index(drop=True)\n",
    "    valid_ = df.loc[val_idx,:].reset_index(drop=True)\n",
    "    train_data_root = data_root[trn_idx]\n",
    "    valid_data_root = data_root[val_idx]\n",
    "    \n",
    "        \n",
    "    train_ds = CustomDataset(train_, train_data_root, transform=transform_train,\n",
    "                            transform2=None, output_label=True, encoded_class=CFG['label_encoder'])\n",
    "    valid_ds = CustomDataset(valid_, valid_data_root, transform=transform_test,\n",
    "                            output_label=True)\n",
    "    # WEIGHTEDRANDOMSAMPLER\n",
    "    class_counts = train_.label.value_counts(sort=False).to_dict()\n",
    "    num_samples = sum(class_counts.values())\n",
    "    print(f'cls_cnts: {len(class_counts)}\\nnum_samples:{num_samples}')\n",
    "    \n",
    "    # weight 제작, 전체 학습 데이터 수를 해당 클래스의 데이터 수로 나누어 줌\n",
    "    class_weights = {l:round(num_samples/class_counts[l], 2) for l in class_counts.keys()}\n",
    "    t_labels = train_.label.to_list()\n",
    "    \n",
    "    # class 별 weight를 전체 trainset에 대응시켜 sampler에 넣어줌\n",
    "    weights = [class_weights[t_labels[i]] for i in range(int(num_samples))]\n",
    "\n",
    "\n",
    "    # weight 제작, 전체 학습 데이터 수를 해당 클래스의 데이터 수로 나누어 줌\n",
    "    class_weights = {l:round(num_samples/class_counts[l], 2) for l in class_counts.keys()}\n",
    "\n",
    "    # class 별 weight를 전체 trainset에 대응시켜 sampler에 넣어줌\n",
    "    weights = [class_weights[t_labels[i]] for i in range(int(num_samples))] \n",
    "    sampler = torch.utils.data.WeightedRandomSampler(torch.DoubleTensor(weights), int(num_samples))\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_ds,\n",
    "        batch_size=CFG['train_bs'],\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "        shuffle=True,\n",
    "        #sampler=sampler, \n",
    "        num_workers=CFG['num_workers']\n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        valid_ds, \n",
    "        batch_size=CFG['valid_bs'],\n",
    "        num_workers=CFG['num_workers'],\n",
    "        shuffle=False,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "08ffa2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(epoch, model, loss_fn, optimizer, train_loader, device, scheduler=None):\n",
    "    t = time.time()\n",
    "    \n",
    "    # SET MODEL TRAINING MODE\n",
    "    model.train()\n",
    "    \n",
    "    running_loss = None\n",
    "    loss_sum = 0\n",
    "    image_preds_all = []\n",
    "    image_targets_all = []\n",
    "    acc_list = []\n",
    "    \n",
    "    pbar = tqdm(enumerate(train_loader), total=len(train_loader))\n",
    "    for step, (imgs, image_labels) in pbar:\n",
    "        imgs = imgs.to(device).float()\n",
    "        image_labels = image_labels.to(device).long()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # TEACHER MODEL PREDICTION\n",
    "        with torch.cuda.amp.autocast():\n",
    "            image_preds = model(imgs)   #output = model(input)\n",
    "\n",
    "            loss = loss_fn(image_preds, image_labels)\n",
    "            loss_sum+=loss.detach()\n",
    "            \n",
    "            # BACKPROPAGATION\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        \n",
    "            if running_loss is None:\n",
    "                running_loss = loss.item()\n",
    "            else:\n",
    "                running_loss = running_loss * .99 + loss.item() * .01    \n",
    "        \n",
    "            # TQDM VERBOSE_STEP TRACKING\n",
    "            if ((step + 1) % CFG['verbose_step'] == 0) or ((step + 1) == len(train_loader)):\n",
    "                description = f'epoch {epoch} loss: {running_loss:.4f}'\n",
    "                pbar.set_description(description)\n",
    "        \n",
    "        image_preds_all += [torch.argmax(image_preds, 1).detach().cpu().numpy()]\n",
    "        image_targets_all += [image_labels.detach().cpu().numpy()]\n",
    "        \n",
    "    if scheduler is not None:\n",
    "        scheduler.step()\n",
    "    \n",
    "    image_preds_all = np.concatenate(image_preds_all)\n",
    "    image_targets_all = np.concatenate(image_targets_all)\n",
    "    \n",
    "    matrix = confusion_matrix(image_targets_all,image_preds_all)\n",
    "    epoch_f1 = f1_score(image_targets_all, image_preds_all, average='macro')\n",
    "    \n",
    "    accuracy = (image_preds_all==image_targets_all).mean()\n",
    "    trn_loss = loss_sum/len(train_loader)\n",
    "    \n",
    "    return image_preds_all, accuracy, trn_loss, matrix, epoch_f1\n",
    "\n",
    "def valid_one_epoch(epoch, model, loss_fn, val_loader, device, scheduler=None, schd_loss_update=False):\n",
    "    t = time.time()\n",
    "    \n",
    "    # SET MODEL VALID MODE\n",
    "    model.eval()\n",
    "    \n",
    "    loss_sum = 0\n",
    "    sample_num = 0\n",
    "    avg_loss = 0\n",
    "    image_preds_all = []\n",
    "    image_targets_all = []\n",
    "    acc_list = []\n",
    "    \n",
    "    pbar = tqdm(enumerate(val_loader), total=len(val_loader))\n",
    "    for step, (imgs, image_labels) in pbar:\n",
    "        imgs = imgs.to(device).float()\n",
    "        image_labels = image_labels.to(device).long()\n",
    "        \n",
    "        # TEACHER MODEL PREDICTION\n",
    "        image_preds = model(imgs)\n",
    "        image_preds_all += [torch.argmax(image_preds, 1).detach().cpu().numpy()]\n",
    "        image_targets_all += [image_labels.detach().cpu().numpy()]\n",
    "        \n",
    "        loss = loss_fn(image_preds, image_labels)\n",
    "        \n",
    "        avg_loss += loss.item()\n",
    "        loss_sum += loss.item()*image_labels.shape[0]\n",
    "        sample_num += image_labels.shape[0]\n",
    "        \n",
    "        # TQDM\n",
    "        description = f'epoch {epoch} loss: {loss_sum/sample_num:.4f}'\n",
    "        pbar.set_description(description)\n",
    "    \n",
    "    image_preds_all = np.concatenate(image_preds_all)\n",
    "    image_targets_all = np.concatenate(image_targets_all)\n",
    "    matrix = confusion_matrix(image_targets_all,image_preds_all)\n",
    "    \n",
    "    epoch_f1 = f1_score(image_targets_all, image_preds_all, average='macro')\n",
    "    acc = (image_preds_all==image_targets_all).mean()\n",
    "    val_loss = avg_loss/len(val_loader)\n",
    "    \n",
    "    return image_preds_all, acc, val_loss, matrix, epoch_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "77e9950b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10, verbose=False, delta=0):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "\n",
    "    def __call__(self, score):\n",
    "        print(f' present score: {score}')\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "        elif score <= self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            print(f'Best F1 score from now: {self.best_score}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.counter = 0\n",
    "        \n",
    "        return self.early_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37102a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhojunking\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/hojun/git/KD_models/wandb/run-20230511_105238-h76t11as</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/hojunking/KD_resnet152_pet/runs/h76t11as\" target=\"_blank\">toasty-music-6</a></strong> to <a href=\"https://wandb.ai/hojunking/KD_resnet152_pet\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: resnet152\n",
      "Training start with fold: 0 epoch: 200 \n",
      "\n",
      "cls_cnts: 2\n",
      "num_samples:4436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hojun/miniconda3/envs/torch/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/hojun/miniconda3/envs/torch/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet152_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet152_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 0\n",
      "Epoch 0/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 0 loss: 0.5168:  49%|██████████▏          | 34/70 [00:36<00:26,  1.35it/s]"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    seed_everything(CFG['seed'])\n",
    "    \n",
    "    # WANDB TRACKER INIT\n",
    "    wandb.init(project=project_name, entity=user)\n",
    "    wandb.config.update(CFG)\n",
    "    wandb.run.name = run_name\n",
    "    wandb.define_metric(\"Train Accuracy\", step_metric=\"epoch\")\n",
    "    wandb.define_metric(\"Valid Accuracy\", step_metric=\"epoch\")\n",
    "    wandb.define_metric(\"Train Loss\", step_metric=\"epoch\")\n",
    "    wandb.define_metric(\"Valid Loss\", step_metric=\"epoch\")\n",
    "    wandb.define_metric(\"Train Macro F1 Score\", step_metric=\"epoch\")\n",
    "    wandb.define_metric(\"Valid Macro F1 Score\", step_metric=\"epoch\")\n",
    "    wandb.define_metric(\"Train-Valid Accuracy\", step_metric=\"epoch\")\n",
    "    \n",
    "    model_dir = CFG['model_path'] + '/{}_{}'.format(CFG['model'], run_name)\n",
    "    train_dir = train.dir.values\n",
    "    best_fold = 0\n",
    "    best_f1 =0.0\n",
    "    print('Model: {}'.format(CFG['model']))\n",
    "    # MAKE MODEL DIR\n",
    "    if not os.path.isdir(model_dir):\n",
    "        os.makedirs(model_dir)\n",
    "    \n",
    "    # STRATIFIED K-FOLD DEFINITION\n",
    "    folds = StratifiedKFold(n_splits=CFG['fold_num'], shuffle=True, random_state=CFG['seed']).split(np.arange(train.shape[0]), train.label.values)\n",
    "    \n",
    "    # TEST PROCESS FOLD BREAK\n",
    "    for fold, (trn_idx, val_idx) in enumerate(folds):\n",
    "        print(f'Training start with fold: {fold} epoch: {CFG[\"epochs\"]} \\n')\n",
    "\n",
    "        # EARLY STOPPING DEFINITION\n",
    "        early_stopping = EarlyStopping(patience=CFG[\"patience\"], verbose=True)\n",
    "\n",
    "        # DATALOADER DEFINITION\n",
    "        train_loader, val_loader = prepare_dataloader(train, trn_idx, val_idx, data_root=train_dir)\n",
    "\n",
    "        # MODEL & DEVICE DEFINITION \n",
    "        device = torch.device(CFG['device'])\n",
    "        model =Teacher(CFG['model'], train.label.nunique(), pretrained=True)\n",
    "        \n",
    "        # MODEL FREEZING\n",
    "        #model.freezing(freeze = CFG['freezing'], trainable_layer = CFG['trainable_layer'])\n",
    "        if CFG['freezing'] ==True:\n",
    "            for name, param in model.named_parameters():\n",
    "                if param.requires_grad == True:\n",
    "                    print(f\"{name}: {param.requires_grad}\")\n",
    "\n",
    "        model.to(device)\n",
    "        # MODEL DATA PARALLEL\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            model = nn.DataParallel(model)\n",
    "\n",
    "        scaler = torch.cuda.amp.GradScaler()   \n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=CFG['lr'])\n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, gamma=0.5, step_size=5)\n",
    "\n",
    "        # CRITERION (LOSS FUNCTION)\n",
    "        loss_tr = nn.CrossEntropyLoss().to(device) #MyCrossEntropyLoss().to(device)\n",
    "        loss_fn = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "        wandb.watch(model, loss_tr, log='all')\n",
    "        train_acc_list = []\n",
    "        train_matrix_list = []\n",
    "        train_f1_list = []\n",
    "        valid_acc_list = []\n",
    "        valid_matrix_list = []\n",
    "        valid_f1_list = []\n",
    "        \n",
    "\n",
    "        start = time.time()\n",
    "        print(f'Fold: {fold}')\n",
    "        for epoch in range(CFG['epochs']):\n",
    "            print('Epoch {}/{}'.format(epoch, CFG['epochs'] - 1))\n",
    "\n",
    "            # TRAINIG\n",
    "            train_preds_all, train_acc, train_loss, train_matrix, train_f1 = train_one_epoch(epoch, model, loss_tr,\n",
    "                                                                        optimizer, train_loader, device, scheduler=scheduler)\n",
    "            wandb.log({'Train Accuracy':train_acc, 'Train Loss' : train_loss, 'Train F1': train_f1, 'epoch' : epoch})\n",
    "\n",
    "            # VALIDATION\n",
    "            with torch.no_grad():\n",
    "                valid_preds_all, valid_acc, valid_loss, valid_matrix, valid_f1= valid_one_epoch(epoch, model, loss_fn,\n",
    "                                                                        val_loader, device, scheduler=None)\n",
    "                wandb.log({'Valid Accuracy':valid_acc, 'Valid Loss' : valid_loss, 'Valid F1': valid_f1 ,'epoch' : epoch})\n",
    "            print(f'Epoch [{epoch}], Train Loss : [{train_loss :.5f}] Val Loss : [{valid_loss :.5f}] Val F1 Score : [{valid_f1:.5f}]')\n",
    "            \n",
    "            # SAVE ALL RESULTS\n",
    "            train_acc_list.append(train_acc)\n",
    "            train_matrix_list.append(train_matrix)\n",
    "            train_f1_list.append(train_f1)\n",
    "\n",
    "            valid_acc_list.append(valid_acc)\n",
    "            valid_matrix_list.append(valid_matrix)\n",
    "            valid_f1_list.append(valid_f1)\n",
    "\n",
    "            # MODEL SAVE (THE BEST MODEL OF ALL OF FOLD PROCESS)\n",
    "            if valid_f1 > best_f1:\n",
    "                best_f1 = valid_f1\n",
    "                best_epoch = epoch\n",
    "                torch.save(model.state_dict(), (model_dir+'/{}').format(CFG['model']))\n",
    "\n",
    "            # EARLY STOPPING\n",
    "            stop = early_stopping(valid_f1)\n",
    "            if stop:\n",
    "                print(\"stop called\")   \n",
    "                break\n",
    "\n",
    "        end = time.time() - start\n",
    "        time_ = str(datetime.timedelta(seconds=end)).split(\".\")[0]\n",
    "        print(\"time :\", time_)\n",
    "\n",
    "        # PRINT BEST F1 SCORE MODEL OF FOLD\n",
    "        best_index = valid_f1_list.index(max(valid_f1_list))\n",
    "        print(f'fold: {fold}, Best Epoch : {best_index}/ {len(valid_f1_list)}')\n",
    "        print(f'Best Train Marco F1 : {train_f1_list[best_index]:.5f}')\n",
    "        print(train_matrix_list[best_index])\n",
    "        print(f'Best Valid Marco F1 : {valid_f1_list[best_index]:.5f}')\n",
    "        print(valid_matrix_list[best_index])\n",
    "        print('-----------------------------------------------------------------------')\n",
    "\n",
    "        # K-FOLD END\n",
    "        if valid_f1_list[best_index] > best_fold:\n",
    "            best_fold = valid_f1_list[best_index]\n",
    "            top_fold = fold\n",
    "    print(f'Best Fold F1 score: {best_fold} Top fold : {top_fold}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c9ab9299-b98a-43ef-ad42-51e4aad3ddd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>dir</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pet_2366.jpg</td>\n",
       "      <td>../Data/carbon_data/pet</td>\n",
       "      <td>pet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pet_2065.jpg</td>\n",
       "      <td>../Data/carbon_data/pet</td>\n",
       "      <td>pet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pet_1199.jpg</td>\n",
       "      <td>../Data/carbon_data/pet</td>\n",
       "      <td>pet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pet_932.jpg</td>\n",
       "      <td>../Data/carbon_data/pet</td>\n",
       "      <td>pet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pet_201.jpg</td>\n",
       "      <td>../Data/carbon_data/pet</td>\n",
       "      <td>pet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1382</th>\n",
       "      <td>2294_jpg.rf.ce95ad8540f9b9d5f686614f49224dba.jpg</td>\n",
       "      <td>../Data/carbon_data/labeled</td>\n",
       "      <td>labeled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1383</th>\n",
       "      <td>4460_jpg.rf.a92554d8db8ed19fc370562601f2c33e.jpg</td>\n",
       "      <td>../Data/carbon_data/labeled</td>\n",
       "      <td>labeled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384</th>\n",
       "      <td>pet27463.jpg</td>\n",
       "      <td>../Data/carbon_data/labeled</td>\n",
       "      <td>labeled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1385</th>\n",
       "      <td>pet19028.jpg</td>\n",
       "      <td>../Data/carbon_data/labeled</td>\n",
       "      <td>labeled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1386</th>\n",
       "      <td>pte (1079).jpg</td>\n",
       "      <td>../Data/carbon_data/labeled</td>\n",
       "      <td>labeled</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1387 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              image_id  \\\n",
       "0                                         pet_2366.jpg   \n",
       "1                                         pet_2065.jpg   \n",
       "2                                         pet_1199.jpg   \n",
       "3                                          pet_932.jpg   \n",
       "4                                          pet_201.jpg   \n",
       "...                                                ...   \n",
       "1382  2294_jpg.rf.ce95ad8540f9b9d5f686614f49224dba.jpg   \n",
       "1383  4460_jpg.rf.a92554d8db8ed19fc370562601f2c33e.jpg   \n",
       "1384                                      pet27463.jpg   \n",
       "1385                                      pet19028.jpg   \n",
       "1386                                    pte (1079).jpg   \n",
       "\n",
       "                              dir    label  \n",
       "0         ../Data/carbon_data/pet      pet  \n",
       "1         ../Data/carbon_data/pet      pet  \n",
       "2         ../Data/carbon_data/pet      pet  \n",
       "3         ../Data/carbon_data/pet      pet  \n",
       "4         ../Data/carbon_data/pet      pet  \n",
       "...                           ...      ...  \n",
       "1382  ../Data/carbon_data/labeled  labeled  \n",
       "1383  ../Data/carbon_data/labeled  labeled  \n",
       "1384  ../Data/carbon_data/labeled  labeled  \n",
       "1385  ../Data/carbon_data/labeled  labeled  \n",
       "1386  ../Data/carbon_data/labeled  labeled  \n",
       "\n",
       "[1387 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Pandas Test 데이터프레임 만들기\n",
    "tst_df = pd.DataFrame(total_test_img_paths, columns=['image_id'])\n",
    "tst_df['dir'] = tst_df['image_id'].apply(lambda x: os.path.dirname(x))\n",
    "tst_df['image_id'] = tst_df['image_id'].apply(lambda x: os.path.basename(x))\n",
    "tst_df['label'] = total_test_img_labels\n",
    "test = tst_df\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "93dba2e1-92a8-4e81-89e8-17005fb81bbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>dir</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pet_2366.jpg</td>\n",
       "      <td>../Data/carbon_data/pet</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pet_2065.jpg</td>\n",
       "      <td>../Data/carbon_data/pet</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pet_1199.jpg</td>\n",
       "      <td>../Data/carbon_data/pet</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pet_932.jpg</td>\n",
       "      <td>../Data/carbon_data/pet</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pet_201.jpg</td>\n",
       "      <td>../Data/carbon_data/pet</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1382</th>\n",
       "      <td>2294_jpg.rf.ce95ad8540f9b9d5f686614f49224dba.jpg</td>\n",
       "      <td>../Data/carbon_data/labeled</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1383</th>\n",
       "      <td>4460_jpg.rf.a92554d8db8ed19fc370562601f2c33e.jpg</td>\n",
       "      <td>../Data/carbon_data/labeled</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384</th>\n",
       "      <td>pet27463.jpg</td>\n",
       "      <td>../Data/carbon_data/labeled</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1385</th>\n",
       "      <td>pet19028.jpg</td>\n",
       "      <td>../Data/carbon_data/labeled</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1386</th>\n",
       "      <td>pte (1079).jpg</td>\n",
       "      <td>../Data/carbon_data/labeled</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1387 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              image_id  \\\n",
       "0                                         pet_2366.jpg   \n",
       "1                                         pet_2065.jpg   \n",
       "2                                         pet_1199.jpg   \n",
       "3                                          pet_932.jpg   \n",
       "4                                          pet_201.jpg   \n",
       "...                                                ...   \n",
       "1382  2294_jpg.rf.ce95ad8540f9b9d5f686614f49224dba.jpg   \n",
       "1383  4460_jpg.rf.a92554d8db8ed19fc370562601f2c33e.jpg   \n",
       "1384                                      pet27463.jpg   \n",
       "1385                                      pet19028.jpg   \n",
       "1386                                    pte (1079).jpg   \n",
       "\n",
       "                              dir  label  \n",
       "0         ../Data/carbon_data/pet      1  \n",
       "1         ../Data/carbon_data/pet      1  \n",
       "2         ../Data/carbon_data/pet      1  \n",
       "3         ../Data/carbon_data/pet      1  \n",
       "4         ../Data/carbon_data/pet      1  \n",
       "...                           ...    ...  \n",
       "1382  ../Data/carbon_data/labeled      0  \n",
       "1383  ../Data/carbon_data/labeled      0  \n",
       "1384  ../Data/carbon_data/labeled      0  \n",
       "1385  ../Data/carbon_data/labeled      0  \n",
       "1386  ../Data/carbon_data/labeled      0  \n",
       "\n",
       "[1387 rows x 3 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['label'] = le.fit_transform(test['label'].values)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "681ed966-953b-4533-a9b5-1438c1bb27de",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################## inference #############################\n",
    "def inference(model, data_loader, device):\n",
    "    model.eval()\n",
    "    image_preds_all = []\n",
    "    \n",
    "    pbar = tqdm(enumerate(data_loader), total=len(data_loader))\n",
    "    for step, (imgs) in pbar:\n",
    "        imgs = imgs.to(device).float()\n",
    "\n",
    "        image_preds = model(imgs)   #output = model(input)\n",
    "        image_preds_all += [torch.softmax(image_preds, 1).detach().cpu().numpy()]\n",
    "    \n",
    "    image_preds_all = np.concatenate(image_preds_all, axis=0)\n",
    "    return image_preds_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1f910c08-4857-43b4-b499-b5a7d799e5b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████| 22/22 [00:24<00:00,  1.13s/it]\n"
     ]
    }
   ],
   "source": [
    "model = Teacher(CFG['model'], test.label.nunique(), pretrained=True)\n",
    "load_model = CFG['model_path'] + '/resnet152_202305110003/' + CFG['model']\n",
    "test_dir = test.dir.values\n",
    "\n",
    "tst_ds = CustomDataset(test, test_dir, transform=transform_test, output_label=False)\n",
    "tst_loader = torch.utils.data.DataLoader(\n",
    "    tst_ds, \n",
    "    batch_size=CFG['train_bs'],\n",
    "    num_workers=CFG['num_workers'],\n",
    "    shuffle=False,\n",
    "    pin_memory=True\n",
    ")\n",
    "device = torch.device(CFG['device'])\n",
    "if torch.cuda.device_count() > 1:\n",
    "        model = nn.DataParallel(model)\n",
    "model.to(device)\n",
    "\n",
    "################## get inference #####################\n",
    "predictions = []\n",
    "model.load_state_dict(torch.load(load_model))\n",
    "with torch.no_grad():\n",
    "    predictions += [inference(model, tst_loader, device)]\n",
    "\n",
    "\n",
    "#tst_preds = inference_one_epoch(model, tst_loader, device)\n",
    "predictions = np.mean(predictions, axis=0) \n",
    "test['pred'] = np.argmax(predictions, axis=1)\n",
    "#test['confidence score'] =np.max(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c9584788-3514-4b01-9de9-0f5ba62c648b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>dir</th>\n",
       "      <th>label</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pet_2366.jpg</td>\n",
       "      <td>../Data/carbon_data/pet</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pet_2065.jpg</td>\n",
       "      <td>../Data/carbon_data/pet</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pet_1199.jpg</td>\n",
       "      <td>../Data/carbon_data/pet</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pet_932.jpg</td>\n",
       "      <td>../Data/carbon_data/pet</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pet_201.jpg</td>\n",
       "      <td>../Data/carbon_data/pet</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1382</th>\n",
       "      <td>2294_jpg.rf.ce95ad8540f9b9d5f686614f49224dba.jpg</td>\n",
       "      <td>../Data/carbon_data/labeled</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1383</th>\n",
       "      <td>4460_jpg.rf.a92554d8db8ed19fc370562601f2c33e.jpg</td>\n",
       "      <td>../Data/carbon_data/labeled</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384</th>\n",
       "      <td>pet27463.jpg</td>\n",
       "      <td>../Data/carbon_data/labeled</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1385</th>\n",
       "      <td>pet19028.jpg</td>\n",
       "      <td>../Data/carbon_data/labeled</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1386</th>\n",
       "      <td>pte (1079).jpg</td>\n",
       "      <td>../Data/carbon_data/labeled</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1387 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              image_id  \\\n",
       "0                                         pet_2366.jpg   \n",
       "1                                         pet_2065.jpg   \n",
       "2                                         pet_1199.jpg   \n",
       "3                                          pet_932.jpg   \n",
       "4                                          pet_201.jpg   \n",
       "...                                                ...   \n",
       "1382  2294_jpg.rf.ce95ad8540f9b9d5f686614f49224dba.jpg   \n",
       "1383  4460_jpg.rf.a92554d8db8ed19fc370562601f2c33e.jpg   \n",
       "1384                                      pet27463.jpg   \n",
       "1385                                      pet19028.jpg   \n",
       "1386                                    pte (1079).jpg   \n",
       "\n",
       "                              dir  label  pred  \n",
       "0         ../Data/carbon_data/pet      1     1  \n",
       "1         ../Data/carbon_data/pet      1     1  \n",
       "2         ../Data/carbon_data/pet      1     1  \n",
       "3         ../Data/carbon_data/pet      1     1  \n",
       "4         ../Data/carbon_data/pet      1     1  \n",
       "...                           ...    ...   ...  \n",
       "1382  ../Data/carbon_data/labeled      0     0  \n",
       "1383  ../Data/carbon_data/labeled      0     0  \n",
       "1384  ../Data/carbon_data/labeled      0     0  \n",
       "1385  ../Data/carbon_data/labeled      0     0  \n",
       "1386  ../Data/carbon_data/labeled      0     0  \n",
       "\n",
       "[1387 rows x 4 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6dc9d547-6d2c-4d13-95c6-f9baf6e0f5da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>dir</th>\n",
       "      <th>label</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pet_2366.jpg</td>\n",
       "      <td>../Data/carbon_data/pet</td>\n",
       "      <td>pet</td>\n",
       "      <td>pet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pet_2065.jpg</td>\n",
       "      <td>../Data/carbon_data/pet</td>\n",
       "      <td>pet</td>\n",
       "      <td>pet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pet_1199.jpg</td>\n",
       "      <td>../Data/carbon_data/pet</td>\n",
       "      <td>pet</td>\n",
       "      <td>pet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pet_932.jpg</td>\n",
       "      <td>../Data/carbon_data/pet</td>\n",
       "      <td>pet</td>\n",
       "      <td>pet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pet_201.jpg</td>\n",
       "      <td>../Data/carbon_data/pet</td>\n",
       "      <td>pet</td>\n",
       "      <td>pet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1382</th>\n",
       "      <td>2294_jpg.rf.ce95ad8540f9b9d5f686614f49224dba.jpg</td>\n",
       "      <td>../Data/carbon_data/labeled</td>\n",
       "      <td>labeled</td>\n",
       "      <td>labeled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1383</th>\n",
       "      <td>4460_jpg.rf.a92554d8db8ed19fc370562601f2c33e.jpg</td>\n",
       "      <td>../Data/carbon_data/labeled</td>\n",
       "      <td>labeled</td>\n",
       "      <td>labeled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384</th>\n",
       "      <td>pet27463.jpg</td>\n",
       "      <td>../Data/carbon_data/labeled</td>\n",
       "      <td>labeled</td>\n",
       "      <td>labeled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1385</th>\n",
       "      <td>pet19028.jpg</td>\n",
       "      <td>../Data/carbon_data/labeled</td>\n",
       "      <td>labeled</td>\n",
       "      <td>labeled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1386</th>\n",
       "      <td>pte (1079).jpg</td>\n",
       "      <td>../Data/carbon_data/labeled</td>\n",
       "      <td>labeled</td>\n",
       "      <td>labeled</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1387 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              image_id  \\\n",
       "0                                         pet_2366.jpg   \n",
       "1                                         pet_2065.jpg   \n",
       "2                                         pet_1199.jpg   \n",
       "3                                          pet_932.jpg   \n",
       "4                                          pet_201.jpg   \n",
       "...                                                ...   \n",
       "1382  2294_jpg.rf.ce95ad8540f9b9d5f686614f49224dba.jpg   \n",
       "1383  4460_jpg.rf.a92554d8db8ed19fc370562601f2c33e.jpg   \n",
       "1384                                      pet27463.jpg   \n",
       "1385                                      pet19028.jpg   \n",
       "1386                                    pte (1079).jpg   \n",
       "\n",
       "                              dir    label     pred  \n",
       "0         ../Data/carbon_data/pet      pet      pet  \n",
       "1         ../Data/carbon_data/pet      pet      pet  \n",
       "2         ../Data/carbon_data/pet      pet      pet  \n",
       "3         ../Data/carbon_data/pet      pet      pet  \n",
       "4         ../Data/carbon_data/pet      pet      pet  \n",
       "...                           ...      ...      ...  \n",
       "1382  ../Data/carbon_data/labeled  labeled  labeled  \n",
       "1383  ../Data/carbon_data/labeled  labeled  labeled  \n",
       "1384  ../Data/carbon_data/labeled  labeled  labeled  \n",
       "1385  ../Data/carbon_data/labeled  labeled  labeled  \n",
       "1386  ../Data/carbon_data/labeled  labeled  labeled  \n",
       "\n",
       "[1387 rows x 4 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['label'] = le.inverse_transform(test['label'].values)\n",
    "test['pred'] = le.inverse_transform(test['pred'].values)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "da647547-7a7b-4690-94df-bb42ca426f3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9971\n",
      "f1_score: 0.9968\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1500x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "test_acc = np.sum(test.label == test.pred) / len(test)\n",
    "test_matrix = confusion_matrix(test['label'], test['pred'])\n",
    "epoch_f1 = f1_score(test['label'], test['pred'], average='macro')\n",
    "print(f'accuracy: {test_acc:.4f}')\n",
    "print(f'f1_score: {epoch_f1:.4f}')\n",
    "\n",
    "test_matrix = confusion_matrix(test['label'], test['pred'], normalize='true')\n",
    "#test_matrix = confusion_matrix(test['label'], test['pred'])\n",
    "\n",
    "plt.figure(figsize = (15,10))\n",
    "sns.heatmap(test_matrix, \n",
    "            annot=True, \n",
    "            xticklabels = sorted(set(test['label'])), \n",
    "            yticklabels = sorted(set(test['label'])),\n",
    "            )\n",
    "plt.title('Normalized Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "#print(f'confusion_matrix \\n-------------------------\\n {test_matrix}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ab89fde5-9498-4a99-8bb8-4af301e4a6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv('test_result/incep_res_0403.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8cbfb49-98dd-4d2f-a778-21764270d9c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-gpu",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
