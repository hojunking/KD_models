{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32c4ea0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, magic, shutil\n",
    "from glob import glob\n",
    "import time, datetime\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import joblib\n",
    "import datetime as dt\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torch, gc\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "\n",
    "#from skimage import io\n",
    "import sklearn\n",
    "from sklearn.model_selection import GroupKFold, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, log_loss, f1_score, confusion_matrix, classification_report\n",
    "from sklearn import metrics, preprocessing\n",
    "from scipy.ndimage import zoom\n",
    "\n",
    "import timm\n",
    "from timm.data import resolve_data_config\n",
    "from timm.data.transforms_factory import create_transform\n",
    "import albumentations as A\n",
    "import albumentations.pytorch\n",
    "import wandb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29d0796-1f1d-40df-ad4a-21f57ed7fe35",
   "metadata": {},
   "source": [
    "#### Hyper Param Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57c0283c",
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'fold_num': 5,\n",
    "    'seed': 42,\n",
    "    'model': 'resnet152',\n",
    "    'img_size': 260,\n",
    "    'epochs': 200,\n",
    "    'train_bs':64,\n",
    "    'valid_bs':64,\n",
    "    'lr': 1e-4, ## learning rate\n",
    "    'num_workers': 8,\n",
    "    'verbose_step': 1,\n",
    "    'patience' : 5,\n",
    "    'device': 'cuda:0',\n",
    "    'freezing': False,\n",
    "    'trainable_layer': 12,\n",
    "    'model_path': './models'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7066a8a1-7060-4b6d-bf0c-d4164820a414",
   "metadata": {},
   "source": [
    "#### wandb init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "127461e4-c16d-47fd-b983-556c12ad0daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_now = dt.datetime.now()\n",
    "run_id = time_now.strftime(\"%Y%m%d%H%M\")\n",
    "project_name = 'KD_'+ CFG['model'] + '_pet'\n",
    "user = 'hojunking'\n",
    "run_name = project_name + '_' + run_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b6c4553-4301-4ba8-801e-e7130ac0b3cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: pet\n",
      "img_paths len : 2404\n",
      "\n",
      "label: labeled\n",
      "img_paths len : 4529\n",
      "\n",
      "Train_Images:  5546\n",
      "Train_Images_labels: 5546\n",
      "Test_Images:  1387\n",
      "Test_Images_labels: 1387\n",
      "All data 6933\n"
     ]
    }
   ],
   "source": [
    "# Data split\n",
    "main_path = '../Data/carbon_data/'\n",
    "label_list = [\"pet\",\"labeled\"]\n",
    "\n",
    "total_train_img_paths = []\n",
    "total_train_img_labels = []\n",
    "total_test_img_paths = []\n",
    "total_test_img_labels = []\n",
    "\n",
    "for label in label_list: ## 각 레이블 돌기\n",
    "    print(f'label: {label}',end=' ')\n",
    "    img_paths = [] \n",
    "    img_labels = []\n",
    "\n",
    "    # default ratio\n",
    "    train_ratio = 1500\n",
    "    test_ratio = 500\n",
    "\n",
    "    dir_path = main_path + label ## 레이블 폴더 경로\n",
    "    count = 0\n",
    "    for folder, subfolders, filenames in os.walk(dir_path): ## 폴더 내 모든 파일 탐색\n",
    "    \n",
    "        for img in filenames: ## 각 파일 경로, 레이블 저장\n",
    "            count +=1\n",
    "            if count > train_ratio + test_ratio + 10000:\n",
    "                break\n",
    "            \n",
    "            img_paths.append(folder+'/'+img)\n",
    "            img_labels.append(label)\n",
    "        \n",
    "    print(len(img_paths))\n",
    "\n",
    "    if label == 'labeled': ##  데이터 비율 설정하기 \n",
    "        train_ratio = 3623\n",
    "        test_ratio = 906\n",
    "    elif label == 'pet': ##  데이터 비율 설정하기 \n",
    "        train_ratio = 1923\n",
    "        test_ratio = 481\n",
    "        \n",
    "    total_train_img_paths.extend(img_paths[:train_ratio])\n",
    "    total_train_img_labels.extend(img_labels[:train_ratio])\n",
    "\n",
    "    total_test_img_paths.extend(img_paths[-test_ratio:])\n",
    "    total_test_img_labels.extend(img_labels[-test_ratio:])\n",
    "\n",
    "print('Train_Images: ',len(total_train_img_paths))\n",
    "print(\"Train_Images_labels:\", len(total_train_img_labels))\n",
    "print('Test_Images: ',len(total_test_img_paths))\n",
    "print(\"Test_Images_labels:\", len(total_test_img_labels))\n",
    "print(\"All data\",len(total_train_img_paths) + len(total_test_img_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2716dd8b-84db-4707-80e2-19b29eae9c23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>dir</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pet_1214.jpg</td>\n",
       "      <td>../Data/carbon_data/pet</td>\n",
       "      <td>pet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pet_663.jpg</td>\n",
       "      <td>../Data/carbon_data/pet</td>\n",
       "      <td>pet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pet_2262.jpg</td>\n",
       "      <td>../Data/carbon_data/pet</td>\n",
       "      <td>pet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pet_780.jpg</td>\n",
       "      <td>../Data/carbon_data/pet</td>\n",
       "      <td>pet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pet_176.jpg</td>\n",
       "      <td>../Data/carbon_data/pet</td>\n",
       "      <td>pet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5541</th>\n",
       "      <td>pte (872).jpg</td>\n",
       "      <td>../Data/carbon_data/labeled</td>\n",
       "      <td>labeled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5542</th>\n",
       "      <td>pet36594.jpg</td>\n",
       "      <td>../Data/carbon_data/labeled</td>\n",
       "      <td>labeled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5543</th>\n",
       "      <td>2634_jpg.rf.c07e985b8263d33898e6a2dcdec88b08.jpg</td>\n",
       "      <td>../Data/carbon_data/labeled</td>\n",
       "      <td>labeled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5544</th>\n",
       "      <td>2969_jpg.rf.5f6f9269090b49fdab83153569e91038.jpg</td>\n",
       "      <td>../Data/carbon_data/labeled</td>\n",
       "      <td>labeled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5545</th>\n",
       "      <td>pet8979.jpg</td>\n",
       "      <td>../Data/carbon_data/labeled</td>\n",
       "      <td>labeled</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5546 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              image_id  \\\n",
       "0                                         pet_1214.jpg   \n",
       "1                                          pet_663.jpg   \n",
       "2                                         pet_2262.jpg   \n",
       "3                                          pet_780.jpg   \n",
       "4                                          pet_176.jpg   \n",
       "...                                                ...   \n",
       "5541                                     pte (872).jpg   \n",
       "5542                                      pet36594.jpg   \n",
       "5543  2634_jpg.rf.c07e985b8263d33898e6a2dcdec88b08.jpg   \n",
       "5544  2969_jpg.rf.5f6f9269090b49fdab83153569e91038.jpg   \n",
       "5545                                       pet8979.jpg   \n",
       "\n",
       "                              dir    label  \n",
       "0         ../Data/carbon_data/pet      pet  \n",
       "1         ../Data/carbon_data/pet      pet  \n",
       "2         ../Data/carbon_data/pet      pet  \n",
       "3         ../Data/carbon_data/pet      pet  \n",
       "4         ../Data/carbon_data/pet      pet  \n",
       "...                           ...      ...  \n",
       "5541  ../Data/carbon_data/labeled  labeled  \n",
       "5542  ../Data/carbon_data/labeled  labeled  \n",
       "5543  ../Data/carbon_data/labeled  labeled  \n",
       "5544  ../Data/carbon_data/labeled  labeled  \n",
       "5545  ../Data/carbon_data/labeled  labeled  \n",
       "\n",
       "[5546 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Pandas 데이터프레임 만들기\n",
    "trn_df = pd.DataFrame(total_train_img_paths, columns=['image_id'])\n",
    "trn_df['dir'] = trn_df['image_id'].apply(lambda x: os.path.dirname(x))\n",
    "trn_df['image_id'] = trn_df['image_id'].apply(lambda x: os.path.basename(x))\n",
    "trn_df['label'] = total_train_img_labels\n",
    "train = trn_df\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf387b57-bb5d-4564-96db-d764e547a93a",
   "metadata": {},
   "source": [
    "##### Label Encodering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03c67d39-7933-4f98-b998-54a6036ff4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "encoder = le.fit_transform(train['label'].values)\n",
    "train['label'] = encoder\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c454bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d97a3c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img(path, sub_path=None):\n",
    "    try:\n",
    "        im_bgr = cv2.imread(path)\n",
    "        im_rgb = im_bgr[:, :, ::-1]\n",
    "        past_path = path\n",
    "    except: ## 이미지 에러 발생 시 백지로 대체\n",
    "        im_bgr = cv2.imread('../Data/carbon_reduction/temp_img.jpg')\n",
    "        im_rgb = im_bgr[:, :, ::-1]\n",
    "    return im_rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "884eb987-4341-4fe7-8094-6e61cb051af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = A.Compose(\n",
    "    [\n",
    "        A.RandomResizedCrop(p=1, height=CFG['img_size'] ,width=CFG['img_size'], scale=(0.65, 0.75),ratio=(0.90, 1.10)),\n",
    "        A.SafeRotate(p=0.5, limit=(-20, 20), interpolation=2, border_mode=0, value=(0, 0, 0), mask_value=None),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.ColorJitter(always_apply=True, p=0.5, contrast=0.2, saturation=0.3, hue=0.2),\n",
    "        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, always_apply=False, p=1.0),\n",
    "        A.pytorch.transforms.ToTensorV2()\n",
    "        ])\n",
    "\n",
    "transform_train_cap = A.Compose(\n",
    "    [\n",
    "        A.RandomResizedCrop(p=1, height=CFG['img_size'] ,width=CFG['img_size'], scale=(0.65, 0.85),ratio=(0.90, 1.10)),\n",
    "        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, always_apply=False, p=1.0),\n",
    "        A.pytorch.transforms.ToTensorV2()\n",
    "        ])\n",
    "\n",
    "transform_test = A.Compose(\n",
    "    [\n",
    "        A.Resize(height = CFG['img_size'], width = CFG['img_size']),\n",
    "        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, always_apply=False, p=1.0),\n",
    "        A.pytorch.transforms.ToTensorV2()\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f1561be",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColonDataset(Dataset):\n",
    "    def __init__(self, df, data_root, transform=None, transform2=None, output_label=True, encoder=encoder):\n",
    "        super().__init__()\n",
    "        self.df = df.reset_index(drop=True).copy()\n",
    "        self.transform = transform\n",
    "        self.transform2 = transform2\n",
    "        self.data_root = data_root\n",
    "        self.output_label = output_label\n",
    "        \n",
    "        if output_label == True:\n",
    "            self.labels = self.df['label'].values\n",
    "        \n",
    "        if transform2 == True:\n",
    "            self.cap_image = le.fit_transform(['10Kwalk', 'battery','receipt'])\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index: int):\n",
    "        # GET labels\n",
    "        if self.output_label:\n",
    "            target = self.labels[index]\n",
    "        # GET IMAGES\n",
    "        path = \"{}/{}\".format(self.data_root[index], self.df.iloc[index]['image_id'])\n",
    "        img  = get_img(path)\n",
    "        \n",
    "        # TRANSFORM1, TRANSFORM2 PROCESS\n",
    "        if self.transform2 is not None :\n",
    "            if target in self.cap_image and self.transform2:\n",
    "                transformed = self.transform2(image=img)\n",
    "            else:\n",
    "                transformed = self.transform(image=img)\n",
    "        elif self.transform:\n",
    "            transformed = self.transform(image=img)\n",
    "        img = transformed['image']\n",
    "                \n",
    "        if self.output_label == True:\n",
    "            return img, target\n",
    "        else:\n",
    "            return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7acf9a37-cf66-431c-85c2-d559515afe2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD PRE-TRAINED MODEL\n",
    "class Teacher(nn.Module):\n",
    "    def __init__(self, model_arch, num_classes= 2,pretrained=True):\n",
    "        super(Teacher, self).__init__()\n",
    "        self.backbone = models.resnet152(pretrained=pretrained) ## 모델 선언 여기 models.##(pretrained =pretrained)\n",
    "        self.backbone.fc = nn.Linear(self.backbone.fc.in_features, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b1601bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ForcepImgClassifier(nn.Module):\n",
    "#     def __init__(self, model_arch, n_class=2, pretrained=False):\n",
    "#         super().__init__()\n",
    "#         self.model = timm.create_model(model_arch, pretrained=pretrained, num_classes=n_class)\n",
    "#         # n_features = self.model.classifier.in_features\n",
    "#         # self.model.classifier = nn.Linear(n_features, n_class)\n",
    "#     def freezing(self, freeze=False, trainable_layer = 2):\n",
    "        \n",
    "#         if freeze:\n",
    "#             num_layers = len(list(model.parameters()))\n",
    "#             for i, param in enumerate(model.parameters()):\n",
    "#                 if i < num_layers - trainable_layer*2:\n",
    "#                     param.requires_grad = False    \n",
    "            \n",
    "#     def forward(self, x):\n",
    "#         x = self.model(x)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "240e5531",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataloader(df, trn_idx, val_idx, data_root=train.dir.values):\n",
    "    \n",
    "    train_ = df.loc[trn_idx,:].reset_index(drop=True)\n",
    "    valid_ = df.loc[val_idx,:].reset_index(drop=True)\n",
    "    train_data_root = data_root[trn_idx]\n",
    "    valid_data_root = data_root[val_idx]\n",
    "    \n",
    "        \n",
    "    train_ds = ColonDataset(train_,\n",
    "                            train_data_root,\n",
    "                            transform=transform_train,\n",
    "                            transform2=None,\n",
    "                            output_label=True)\n",
    "    valid_ds = ColonDataset(valid_,\n",
    "                            valid_data_root,\n",
    "                            transform=transform_test,\n",
    "                            output_label=True)\n",
    "    # WEIGHTEDRANDOMSAMPLER\n",
    "    class_counts = train_.label.value_counts(sort=False).to_dict()\n",
    "    num_samples = sum(class_counts.values())\n",
    "    print(f'cls_cnts: {len(class_counts)}\\nnum_samples:{num_samples}')\n",
    "    \n",
    "    # weight 제작, 전체 학습 데이터 수를 해당 클래스의 데이터 수로 나누어 줌\n",
    "    class_weights = {l:round(num_samples/class_counts[l], 2) for l in class_counts.keys()}\n",
    "    t_labels = train_.label.to_list()\n",
    "    \n",
    "    # class 별 weight를 전체 trainset에 대응시켜 sampler에 넣어줌\n",
    "    weights = [class_weights[t_labels[i]] for i in range(int(num_samples))]\n",
    "\n",
    "\n",
    "    # weight 제작, 전체 학습 데이터 수를 해당 클래스의 데이터 수로 나누어 줌\n",
    "    class_weights = {l:round(num_samples/class_counts[l], 2) for l in class_counts.keys()}\n",
    "\n",
    "    # class 별 weight를 전체 trainset에 대응시켜 sampler에 넣어줌\n",
    "    weights = [class_weights[t_labels[i]] for i in range(int(num_samples))] \n",
    "    sampler = torch.utils.data.WeightedRandomSampler(torch.DoubleTensor(weights), int(num_samples))\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_ds,\n",
    "        batch_size=CFG['train_bs'],\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "        shuffle=True,\n",
    "        #sampler=sampler, \n",
    "        num_workers=CFG['num_workers']\n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        valid_ds, \n",
    "        batch_size=CFG['valid_bs'],\n",
    "        num_workers=CFG['num_workers'],\n",
    "        shuffle=False,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "08ffa2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(epoch, model, loss_fn, optimizer, train_loader, device, scheduler=None):\n",
    "    ## Sets the model to training mode\n",
    "    model.train()\n",
    "    \n",
    "    t = time.time()\n",
    "    running_loss = None\n",
    "    loss_sum = 0\n",
    "    image_preds_all = []\n",
    "    image_targets_all = []\n",
    "    acc_list = []\n",
    "    \n",
    "    pbar = tqdm(enumerate(train_loader), total=len(train_loader))\n",
    "    for step, (imgs, image_labels) in pbar:\n",
    "        imgs = imgs.to(device).float()\n",
    "        image_labels = image_labels.to(device).long()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        with torch.cuda.amp.autocast():\n",
    "            image_preds = model(imgs)   #output = model(input)\n",
    "\n",
    "            loss = loss_fn(image_preds, image_labels)\n",
    "            loss_sum+=loss.detach()\n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        \n",
    "            if running_loss is None:\n",
    "                running_loss = loss.item()\n",
    "            else:\n",
    "                running_loss = running_loss * .99 + loss.item() * .01    \n",
    "        \n",
    "        \n",
    "            if ((step + 1) % CFG['verbose_step'] == 0) or ((step + 1) == len(train_loader)):\n",
    "                description = f'epoch {epoch} loss: {running_loss:.4f}'\n",
    "                pbar.set_description(description)\n",
    "        \n",
    "        image_preds_all += [torch.argmax(image_preds, 1).detach().cpu().numpy()]\n",
    "        image_targets_all += [image_labels.detach().cpu().numpy()]\n",
    "        \n",
    "    if scheduler is not None:\n",
    "        scheduler.step()\n",
    "    \n",
    "    image_preds_all = np.concatenate(image_preds_all)\n",
    "    image_targets_all = np.concatenate(image_targets_all)\n",
    "    \n",
    "    matrix = confusion_matrix(image_targets_all,image_preds_all)\n",
    "    epoch_f1 = f1_score(image_targets_all, image_preds_all, average='macro')\n",
    "    \n",
    "    accuracy = (image_preds_all==image_targets_all).mean()\n",
    "    trn_loss = loss_sum/len(train_loader)\n",
    "    \n",
    "    return image_preds_all, accuracy, trn_loss, matrix, epoch_f1\n",
    "\n",
    "def valid_one_epoch(epoch, model, loss_fn, val_loader, device, scheduler=None, schd_loss_update=False):\n",
    "    ## Sets the model to valid mode\n",
    "    model.eval()\n",
    "\n",
    "    t = time.time()\n",
    "    loss_sum = 0\n",
    "    sample_num = 0\n",
    "    avg_loss = 0\n",
    "    image_preds_all = []\n",
    "    image_targets_all = []\n",
    "    \n",
    "    acc_list = []\n",
    "    \n",
    "    pbar = tqdm(enumerate(val_loader), total=len(val_loader))\n",
    "    for step, (imgs, image_labels) in pbar:\n",
    "        imgs = imgs.to(device).float()\n",
    "        image_labels = image_labels.to(device).long()\n",
    "        \n",
    "        image_preds = model(imgs)   #output = model(input)\n",
    "        image_preds_all += [torch.argmax(image_preds, 1).detach().cpu().numpy()]\n",
    "        image_targets_all += [image_labels.detach().cpu().numpy()]\n",
    "        \n",
    "        loss = loss_fn(image_preds, image_labels)\n",
    "        avg_loss += loss.item()\n",
    "        loss_sum += loss.item()*image_labels.shape[0]\n",
    "        sample_num += image_labels.shape[0]\n",
    "        \n",
    "        description = f'epoch {epoch} loss: {loss_sum/sample_num:.4f}'\n",
    "        pbar.set_description(description)\n",
    "    \n",
    "    image_preds_all = np.concatenate(image_preds_all)\n",
    "    image_targets_all = np.concatenate(image_targets_all)\n",
    "    matrix = confusion_matrix(image_targets_all,image_preds_all)\n",
    "    \n",
    "    epoch_f1 = f1_score(image_targets_all, image_preds_all, average='macro')\n",
    "    acc = (image_preds_all==image_targets_all).mean()\n",
    "    val_loss = avg_loss/len(val_loader)\n",
    "    \n",
    "    return image_preds_all, acc, val_loss, matrix, epoch_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "77e9950b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10, verbose=False, delta=0):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "\n",
    "    def __call__(self, score):\n",
    "        print(f' present score: {score}')\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "        elif score <= self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            print(f'Best F1 score from now: {self.best_score}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.counter = 0\n",
    "        \n",
    "        return self.early_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37102a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhojunking\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/hojun/git/KD_models/wandb/run-20230430_175828-3hk91zqg</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/hojunking/KD_resnet152_bin_class_20230430175553/runs/3hk91zqg\" target=\"_blank\">daily-plant-1</a></strong> to <a href=\"https://wandb.ai/hojunking/KD_resnet152_bin_class_20230430175553\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: resnet152\n",
      "Training start with fold: 0 epoch: 200 \n",
      "\n",
      "cls_cnts: 2\n",
      "num_samples:4436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hojun/miniconda3/envs/torch/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/hojun/miniconda3/envs/torch/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet152_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet152_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 0\n",
      "Epoch 0/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 0 loss: 0.3705: 100%|█████████████████████| 70/70 [00:58<00:00,  1.20it/s]\n",
      "epoch 0 loss: 0.0279: 100%|█████████████████████| 18/18 [00:19<00:00,  1.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], Train Loss : [0.07104] Val Loss : [0.02685] Val F1 Score : [0.99008]\n",
      " present score: 0.9900822370184523\n",
      "Epoch 1/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 loss: 0.0227: 100%|█████████████████████| 70/70 [00:51<00:00,  1.36it/s]\n",
      "epoch 1 loss: 0.0289: 100%|█████████████████████| 18/18 [00:17<00:00,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1], Train Loss : [0.02555] Val Loss : [0.02783] Val F1 Score : [0.99702]\n",
      " present score: 0.9970228809036138\n",
      "Epoch 2/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 2 loss: 0.0082: 100%|█████████████████████| 70/70 [00:51<00:00,  1.35it/s]\n",
      "epoch 2 loss: 0.0425: 100%|█████████████████████| 18/18 [00:17<00:00,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2], Train Loss : [0.01455] Val Loss : [0.04103] Val F1 Score : [0.99603]\n",
      " present score: 0.996032894807381\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Best F1 score from now: 0.9970228809036138\n",
      "Epoch 3/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 3 loss: 0.0155: 100%|█████████████████████| 70/70 [00:51<00:00,  1.37it/s]\n",
      "epoch 3 loss: 0.0304: 100%|█████████████████████| 18/18 [00:16<00:00,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3], Train Loss : [0.02138] Val Loss : [0.02959] Val F1 Score : [0.98815]\n",
      " present score: 0.9881549039764663\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Best F1 score from now: 0.9970228809036138\n",
      "Epoch 4/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 4 loss: 0.0153: 100%|█████████████████████| 70/70 [00:51<00:00,  1.36it/s]\n",
      "epoch 4 loss: 0.0146: 100%|█████████████████████| 18/18 [00:17<00:00,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4], Train Loss : [0.02160] Val Loss : [0.01470] Val F1 Score : [0.99504]\n",
      " present score: 0.9950440897421586\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Best F1 score from now: 0.9970228809036138\n",
      "Epoch 5/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 5 loss: 0.0057: 100%|█████████████████████| 70/70 [00:52<00:00,  1.34it/s]\n",
      "epoch 5 loss: 0.0130: 100%|█████████████████████| 18/18 [00:17<00:00,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5], Train Loss : [0.00708] Val Loss : [0.01254] Val F1 Score : [0.99504]\n",
      " present score: 0.9950440897421586\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Best F1 score from now: 0.9970228809036138\n",
      "Epoch 6/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 6 loss: 0.0012:   4%|▉                     | 3/70 [00:07<02:05,  1.87s/it]"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    seed_everything(CFG['seed'])\n",
    "    \n",
    "    # WANDB TRACKER INIT\n",
    "    wandb.init(project=project_name, entity=user)\n",
    "    wandb.config.update(CFG)\n",
    "    wandb.run.name = run_name\n",
    "    wandb.define_metric(\"Train Accuracy\", step_metric=\"epoch\")\n",
    "    wandb.define_metric(\"Valid Accuracy\", step_metric=\"epoch\")\n",
    "    wandb.define_metric(\"Train Loss\", step_metric=\"epoch\")\n",
    "    wandb.define_metric(\"Valid Loss\", step_metric=\"epoch\")\n",
    "    wandb.define_metric(\"Train Macro F1 Score\", step_metric=\"epoch\")\n",
    "    wandb.define_metric(\"Valid Macro F1 Score\", step_metric=\"epoch\")\n",
    "    wandb.define_metric(\"Train-Valid Accuracy\", step_metric=\"epoch\")\n",
    "    \n",
    "    model_dir = CFG['model_path'] + '/{}_{}'.format(CFG['model'], run_id)\n",
    "    train_dir = train.dir.values\n",
    "    best_fold = 0\n",
    "    best_f1 =0.0\n",
    "    print('Model: {}'.format(CFG['model']))\n",
    "    # MAKE MODEL DIR\n",
    "    if not os.path.isdir(model_dir):\n",
    "        os.makedirs(model_dir)\n",
    "    \n",
    "    # STRATIFIED K-FOLD DEFINITION\n",
    "    folds = StratifiedKFold(n_splits=CFG['fold_num'], shuffle=True, random_state=CFG['seed']).split(np.arange(train.shape[0]), train.label.values)\n",
    "    \n",
    "    # TEST PROCESS FOLD BREAK\n",
    "    for fold, (trn_idx, val_idx) in enumerate(folds):\n",
    "        print(f'Training start with fold: {fold} epoch: {CFG[\"epochs\"]} \\n')\n",
    "\n",
    "        # EARLY STOPPING DEFINITION\n",
    "        early_stopping = EarlyStopping(patience=CFG[\"patience\"], verbose=True)\n",
    "\n",
    "        # DATALOADER DEFINITION\n",
    "        train_loader, val_loader = prepare_dataloader(train, trn_idx, val_idx, data_root=train_dir)\n",
    "\n",
    "        # MODEL & DEVICE DEFINITION \n",
    "        device = torch.device(CFG['device'])\n",
    "        #model = ForcepImgClassifier(CFG['model'], train.label.nunique(), pretrained=True)\n",
    "        model =Teacher(CFG['model'], train.label.nunique(), pretrained=True)\n",
    "        \n",
    "        # MODEL FREEZING\n",
    "        #model.freezing(freeze = CFG['freezing'], trainable_layer = CFG['trainable_layer'])\n",
    "        if CFG['freezing'] ==True:\n",
    "            for name, param in model.named_parameters():\n",
    "                if param.requires_grad == True:\n",
    "                    print(f\"{name}: {param.requires_grad}\")\n",
    "\n",
    "        model.to(device)\n",
    "        # MODEL DATA PARALLEL\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            model = nn.DataParallel(model)\n",
    "\n",
    "        scaler = torch.cuda.amp.GradScaler()   \n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=CFG['lr'])\n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, gamma=0.5, step_size=5)\n",
    "\n",
    "        # CRITERION (LOSS FUNCTION)\n",
    "        loss_tr = nn.CrossEntropyLoss().to(device) #MyCrossEntropyLoss().to(device)\n",
    "        loss_fn = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "        wandb.watch(model, loss_tr, log='all')\n",
    "        train_acc_list = []\n",
    "        train_matrix_list = []\n",
    "        train_f1_list = []\n",
    "        valid_acc_list = []\n",
    "        valid_matrix_list = []\n",
    "        valid_f1_list = []\n",
    "        \n",
    "\n",
    "        start = time.time()\n",
    "        print(f'Fold: {fold}')\n",
    "        for epoch in range(CFG['epochs']):\n",
    "            print('Epoch {}/{}'.format(epoch, CFG['epochs'] - 1))\n",
    "\n",
    "            # TRAINIG\n",
    "            train_preds_all, train_acc, train_loss, train_matrix, train_f1 = train_one_epoch(epoch, model, loss_tr,\n",
    "                                                                        optimizer, train_loader, device, scheduler=scheduler)\n",
    "            wandb.log({'Train Accuracy':train_acc, 'Train Loss' : train_loss, 'Train F1': train_f1, 'epoch' : epoch})\n",
    "\n",
    "            # VALIDATION\n",
    "            with torch.no_grad():\n",
    "                valid_preds_all, valid_acc, valid_loss, valid_matrix, valid_f1= valid_one_epoch(epoch, model, loss_fn,\n",
    "                                                                        val_loader, device, scheduler=None)\n",
    "                wandb.log({'Valid Accuracy':valid_acc, 'Valid Loss' : valid_loss, 'Valid F1': valid_f1 ,'epoch' : epoch})\n",
    "            print(f'Epoch [{epoch}], Train Loss : [{train_loss :.5f}] Val Loss : [{valid_loss :.5f}] Val F1 Score : [{valid_f1:.5f}]')\n",
    "            \n",
    "            # SAVE ALL RESULTS\n",
    "            train_acc_list.append(train_acc)\n",
    "            train_matrix_list.append(train_matrix)\n",
    "            train_f1_list.append(train_f1)\n",
    "\n",
    "            valid_acc_list.append(valid_acc)\n",
    "            valid_matrix_list.append(valid_matrix)\n",
    "            valid_f1_list.append(valid_f1)\n",
    "\n",
    "            # MODEL SAVE (THE BEST MODEL OF ALL OF FOLD PROCESS)\n",
    "            if valid_f1 > best_f1:\n",
    "                best_f1 = valid_f1\n",
    "                best_epoch = epoch\n",
    "                torch.save(model.state_dict(), (model_dir+'/{}').format(CFG['model']))\n",
    "\n",
    "            # EARLY STOPPING\n",
    "            stop = early_stopping(valid_f1)\n",
    "            if stop:\n",
    "                print(\"stop called\")   \n",
    "                break\n",
    "\n",
    "        end = time.time() - start\n",
    "        time_ = str(datetime.timedelta(seconds=end)).split(\".\")[0]\n",
    "        print(\"time :\", time_)\n",
    "\n",
    "        # PRINT BEST F1 SCORE MODEL OF FOLD\n",
    "        best_index = valid_f1_list.index(max(valid_f1_list))\n",
    "        print(f'fold: {fold}, Best Epoch : {best_index}/ {len(valid_f1_list)}')\n",
    "        print(f'Best Train Marco F1 : {train_f1_list[best_index]:.5f}')\n",
    "        print(train_matrix_list[best_index])\n",
    "        print(f'Best Valid Marco F1 : {valid_f1_list[best_index]:.5f}')\n",
    "        print(valid_matrix_list[best_index])\n",
    "        print('-----------------------------------------------------------------------')\n",
    "\n",
    "        # K-FOLD END\n",
    "        if valid_f1_list[best_index] > best_fold:\n",
    "            best_fold = valid_f1_list[best_index]\n",
    "            top_fold = fold\n",
    "    print(f'Best Fold F1 score: {best_fold} Top fold : {top_fold}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c9ab9299-b98a-43ef-ad42-51e4aad3ddd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>dir</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pet_2366.jpg</td>\n",
       "      <td>../Data/carbon_data/pet</td>\n",
       "      <td>pet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pet_2065.jpg</td>\n",
       "      <td>../Data/carbon_data/pet</td>\n",
       "      <td>pet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pet_1199.jpg</td>\n",
       "      <td>../Data/carbon_data/pet</td>\n",
       "      <td>pet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pet_932.jpg</td>\n",
       "      <td>../Data/carbon_data/pet</td>\n",
       "      <td>pet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pet_201.jpg</td>\n",
       "      <td>../Data/carbon_data/pet</td>\n",
       "      <td>pet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1382</th>\n",
       "      <td>2294_jpg.rf.ce95ad8540f9b9d5f686614f49224dba.jpg</td>\n",
       "      <td>../Data/carbon_data/labeled</td>\n",
       "      <td>labeled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1383</th>\n",
       "      <td>4460_jpg.rf.a92554d8db8ed19fc370562601f2c33e.jpg</td>\n",
       "      <td>../Data/carbon_data/labeled</td>\n",
       "      <td>labeled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384</th>\n",
       "      <td>pet27463.jpg</td>\n",
       "      <td>../Data/carbon_data/labeled</td>\n",
       "      <td>labeled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1385</th>\n",
       "      <td>pet19028.jpg</td>\n",
       "      <td>../Data/carbon_data/labeled</td>\n",
       "      <td>labeled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1386</th>\n",
       "      <td>pte (1079).jpg</td>\n",
       "      <td>../Data/carbon_data/labeled</td>\n",
       "      <td>labeled</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1387 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              image_id  \\\n",
       "0                                         pet_2366.jpg   \n",
       "1                                         pet_2065.jpg   \n",
       "2                                         pet_1199.jpg   \n",
       "3                                          pet_932.jpg   \n",
       "4                                          pet_201.jpg   \n",
       "...                                                ...   \n",
       "1382  2294_jpg.rf.ce95ad8540f9b9d5f686614f49224dba.jpg   \n",
       "1383  4460_jpg.rf.a92554d8db8ed19fc370562601f2c33e.jpg   \n",
       "1384                                      pet27463.jpg   \n",
       "1385                                      pet19028.jpg   \n",
       "1386                                    pte (1079).jpg   \n",
       "\n",
       "                              dir    label  \n",
       "0         ../Data/carbon_data/pet      pet  \n",
       "1         ../Data/carbon_data/pet      pet  \n",
       "2         ../Data/carbon_data/pet      pet  \n",
       "3         ../Data/carbon_data/pet      pet  \n",
       "4         ../Data/carbon_data/pet      pet  \n",
       "...                           ...      ...  \n",
       "1382  ../Data/carbon_data/labeled  labeled  \n",
       "1383  ../Data/carbon_data/labeled  labeled  \n",
       "1384  ../Data/carbon_data/labeled  labeled  \n",
       "1385  ../Data/carbon_data/labeled  labeled  \n",
       "1386  ../Data/carbon_data/labeled  labeled  \n",
       "\n",
       "[1387 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Pandas Test 데이터프레임 만들기\n",
    "tst_df = pd.DataFrame(total_test_img_paths, columns=['image_id'])\n",
    "tst_df['dir'] = tst_df['image_id'].apply(lambda x: os.path.dirname(x))\n",
    "tst_df['image_id'] = tst_df['image_id'].apply(lambda x: os.path.basename(x))\n",
    "tst_df['label'] = total_test_img_labels\n",
    "test = tst_df\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "93dba2e1-92a8-4e81-89e8-17005fb81bbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>dir</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pet_2366.jpg</td>\n",
       "      <td>../Data/carbon_data/pet</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pet_2065.jpg</td>\n",
       "      <td>../Data/carbon_data/pet</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pet_1199.jpg</td>\n",
       "      <td>../Data/carbon_data/pet</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pet_932.jpg</td>\n",
       "      <td>../Data/carbon_data/pet</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pet_201.jpg</td>\n",
       "      <td>../Data/carbon_data/pet</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1382</th>\n",
       "      <td>2294_jpg.rf.ce95ad8540f9b9d5f686614f49224dba.jpg</td>\n",
       "      <td>../Data/carbon_data/labeled</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1383</th>\n",
       "      <td>4460_jpg.rf.a92554d8db8ed19fc370562601f2c33e.jpg</td>\n",
       "      <td>../Data/carbon_data/labeled</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384</th>\n",
       "      <td>pet27463.jpg</td>\n",
       "      <td>../Data/carbon_data/labeled</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1385</th>\n",
       "      <td>pet19028.jpg</td>\n",
       "      <td>../Data/carbon_data/labeled</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1386</th>\n",
       "      <td>pte (1079).jpg</td>\n",
       "      <td>../Data/carbon_data/labeled</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1387 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              image_id  \\\n",
       "0                                         pet_2366.jpg   \n",
       "1                                         pet_2065.jpg   \n",
       "2                                         pet_1199.jpg   \n",
       "3                                          pet_932.jpg   \n",
       "4                                          pet_201.jpg   \n",
       "...                                                ...   \n",
       "1382  2294_jpg.rf.ce95ad8540f9b9d5f686614f49224dba.jpg   \n",
       "1383  4460_jpg.rf.a92554d8db8ed19fc370562601f2c33e.jpg   \n",
       "1384                                      pet27463.jpg   \n",
       "1385                                      pet19028.jpg   \n",
       "1386                                    pte (1079).jpg   \n",
       "\n",
       "                              dir  label  \n",
       "0         ../Data/carbon_data/pet      1  \n",
       "1         ../Data/carbon_data/pet      1  \n",
       "2         ../Data/carbon_data/pet      1  \n",
       "3         ../Data/carbon_data/pet      1  \n",
       "4         ../Data/carbon_data/pet      1  \n",
       "...                           ...    ...  \n",
       "1382  ../Data/carbon_data/labeled      0  \n",
       "1383  ../Data/carbon_data/labeled      0  \n",
       "1384  ../Data/carbon_data/labeled      0  \n",
       "1385  ../Data/carbon_data/labeled      0  \n",
       "1386  ../Data/carbon_data/labeled      0  \n",
       "\n",
       "[1387 rows x 3 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['label'] = le.fit_transform(test['label'].values)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "681ed966-953b-4533-a9b5-1438c1bb27de",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################## inference #############################\n",
    "def inference(model, data_loader, device):\n",
    "    model.eval()\n",
    "    image_preds_all = []\n",
    "    \n",
    "    pbar = tqdm(enumerate(data_loader), total=len(data_loader))\n",
    "    for step, (imgs) in pbar:\n",
    "        imgs = imgs.to(device).float()\n",
    "\n",
    "        image_preds = model(imgs)   #output = model(input)\n",
    "        image_preds_all += [torch.softmax(image_preds, 1).detach().cpu().numpy()]\n",
    "    \n",
    "    image_preds_all = np.concatenate(image_preds_all, axis=0)\n",
    "    return image_preds_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1f910c08-4857-43b4-b499-b5a7d799e5b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hojun/miniconda3/envs/torch/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/hojun/miniconda3/envs/torch/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet152_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet152_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "100%|███████████████████████████████████████████| 22/22 [00:24<00:00,  1.09s/it]\n"
     ]
    }
   ],
   "source": [
    "model = Teacher(CFG['model'], test.label.nunique(), pretrained=True)\n",
    "load_model = CFG['model_path'] + '/resnet152_20230430175553/' + CFG['model']\n",
    "test_dir = test.dir.values\n",
    "\n",
    "tst_ds = ColonDataset(test, test_dir, transform=transform_test, output_label=False)\n",
    "tst_loader = torch.utils.data.DataLoader(\n",
    "    tst_ds, \n",
    "    batch_size=CFG['train_bs'],\n",
    "    num_workers=CFG['num_workers'],\n",
    "    shuffle=False,\n",
    "    pin_memory=True\n",
    ")\n",
    "device = torch.device(CFG['device'])\n",
    "if torch.cuda.device_count() > 1:\n",
    "        model = nn.DataParallel(model)\n",
    "model.to(device)\n",
    "\n",
    "################## get inference #####################\n",
    "predictions = []\n",
    "model.load_state_dict(torch.load(load_model))\n",
    "with torch.no_grad():\n",
    "    predictions += [inference(model, tst_loader, device)]\n",
    "\n",
    "\n",
    "#tst_preds = inference_one_epoch(model, tst_loader, device)\n",
    "predictions = np.mean(predictions, axis=0) \n",
    "test['pred'] = np.argmax(predictions, axis=1)\n",
    "#test['confidence score'] =np.max(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c9584788-3514-4b01-9de9-0f5ba62c648b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>dir</th>\n",
       "      <th>label</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pet_2366.jpg</td>\n",
       "      <td>../Data/carbon_data/pet</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pet_2065.jpg</td>\n",
       "      <td>../Data/carbon_data/pet</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pet_1199.jpg</td>\n",
       "      <td>../Data/carbon_data/pet</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pet_932.jpg</td>\n",
       "      <td>../Data/carbon_data/pet</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pet_201.jpg</td>\n",
       "      <td>../Data/carbon_data/pet</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1382</th>\n",
       "      <td>2294_jpg.rf.ce95ad8540f9b9d5f686614f49224dba.jpg</td>\n",
       "      <td>../Data/carbon_data/labeled</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1383</th>\n",
       "      <td>4460_jpg.rf.a92554d8db8ed19fc370562601f2c33e.jpg</td>\n",
       "      <td>../Data/carbon_data/labeled</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384</th>\n",
       "      <td>pet27463.jpg</td>\n",
       "      <td>../Data/carbon_data/labeled</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1385</th>\n",
       "      <td>pet19028.jpg</td>\n",
       "      <td>../Data/carbon_data/labeled</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1386</th>\n",
       "      <td>pte (1079).jpg</td>\n",
       "      <td>../Data/carbon_data/labeled</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1387 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              image_id  \\\n",
       "0                                         pet_2366.jpg   \n",
       "1                                         pet_2065.jpg   \n",
       "2                                         pet_1199.jpg   \n",
       "3                                          pet_932.jpg   \n",
       "4                                          pet_201.jpg   \n",
       "...                                                ...   \n",
       "1382  2294_jpg.rf.ce95ad8540f9b9d5f686614f49224dba.jpg   \n",
       "1383  4460_jpg.rf.a92554d8db8ed19fc370562601f2c33e.jpg   \n",
       "1384                                      pet27463.jpg   \n",
       "1385                                      pet19028.jpg   \n",
       "1386                                    pte (1079).jpg   \n",
       "\n",
       "                              dir  label  pred  \n",
       "0         ../Data/carbon_data/pet      1     1  \n",
       "1         ../Data/carbon_data/pet      1     1  \n",
       "2         ../Data/carbon_data/pet      1     1  \n",
       "3         ../Data/carbon_data/pet      1     1  \n",
       "4         ../Data/carbon_data/pet      1     1  \n",
       "...                           ...    ...   ...  \n",
       "1382  ../Data/carbon_data/labeled      0     0  \n",
       "1383  ../Data/carbon_data/labeled      0     0  \n",
       "1384  ../Data/carbon_data/labeled      0     0  \n",
       "1385  ../Data/carbon_data/labeled      0     0  \n",
       "1386  ../Data/carbon_data/labeled      0     0  \n",
       "\n",
       "[1387 rows x 4 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6dc9d547-6d2c-4d13-95c6-f9baf6e0f5da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>dir</th>\n",
       "      <th>label</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pet_2366.jpg</td>\n",
       "      <td>../Data/carbon_data/pet</td>\n",
       "      <td>pet</td>\n",
       "      <td>pet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pet_2065.jpg</td>\n",
       "      <td>../Data/carbon_data/pet</td>\n",
       "      <td>pet</td>\n",
       "      <td>pet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pet_1199.jpg</td>\n",
       "      <td>../Data/carbon_data/pet</td>\n",
       "      <td>pet</td>\n",
       "      <td>pet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pet_932.jpg</td>\n",
       "      <td>../Data/carbon_data/pet</td>\n",
       "      <td>pet</td>\n",
       "      <td>pet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pet_201.jpg</td>\n",
       "      <td>../Data/carbon_data/pet</td>\n",
       "      <td>pet</td>\n",
       "      <td>pet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1382</th>\n",
       "      <td>2294_jpg.rf.ce95ad8540f9b9d5f686614f49224dba.jpg</td>\n",
       "      <td>../Data/carbon_data/labeled</td>\n",
       "      <td>labeled</td>\n",
       "      <td>labeled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1383</th>\n",
       "      <td>4460_jpg.rf.a92554d8db8ed19fc370562601f2c33e.jpg</td>\n",
       "      <td>../Data/carbon_data/labeled</td>\n",
       "      <td>labeled</td>\n",
       "      <td>labeled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384</th>\n",
       "      <td>pet27463.jpg</td>\n",
       "      <td>../Data/carbon_data/labeled</td>\n",
       "      <td>labeled</td>\n",
       "      <td>labeled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1385</th>\n",
       "      <td>pet19028.jpg</td>\n",
       "      <td>../Data/carbon_data/labeled</td>\n",
       "      <td>labeled</td>\n",
       "      <td>labeled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1386</th>\n",
       "      <td>pte (1079).jpg</td>\n",
       "      <td>../Data/carbon_data/labeled</td>\n",
       "      <td>labeled</td>\n",
       "      <td>labeled</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1387 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              image_id  \\\n",
       "0                                         pet_2366.jpg   \n",
       "1                                         pet_2065.jpg   \n",
       "2                                         pet_1199.jpg   \n",
       "3                                          pet_932.jpg   \n",
       "4                                          pet_201.jpg   \n",
       "...                                                ...   \n",
       "1382  2294_jpg.rf.ce95ad8540f9b9d5f686614f49224dba.jpg   \n",
       "1383  4460_jpg.rf.a92554d8db8ed19fc370562601f2c33e.jpg   \n",
       "1384                                      pet27463.jpg   \n",
       "1385                                      pet19028.jpg   \n",
       "1386                                    pte (1079).jpg   \n",
       "\n",
       "                              dir    label     pred  \n",
       "0         ../Data/carbon_data/pet      pet      pet  \n",
       "1         ../Data/carbon_data/pet      pet      pet  \n",
       "2         ../Data/carbon_data/pet      pet      pet  \n",
       "3         ../Data/carbon_data/pet      pet      pet  \n",
       "4         ../Data/carbon_data/pet      pet      pet  \n",
       "...                           ...      ...      ...  \n",
       "1382  ../Data/carbon_data/labeled  labeled  labeled  \n",
       "1383  ../Data/carbon_data/labeled  labeled  labeled  \n",
       "1384  ../Data/carbon_data/labeled  labeled  labeled  \n",
       "1385  ../Data/carbon_data/labeled  labeled  labeled  \n",
       "1386  ../Data/carbon_data/labeled  labeled  labeled  \n",
       "\n",
       "[1387 rows x 4 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['label'] = le.inverse_transform(test['label'].values)\n",
    "test['pred'] = le.inverse_transform(test['pred'].values)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "da647547-7a7b-4690-94df-bb42ca426f3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9986\n",
      "f1_score: 0.9984\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1500x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "test_acc = np.sum(test.label == test.pred) / len(test)\n",
    "test_matrix = confusion_matrix(test['label'], test['pred'])\n",
    "epoch_f1 = f1_score(test['label'], test['pred'], average='macro')\n",
    "print(f'accuracy: {test_acc:.4f}')\n",
    "print(f'f1_score: {epoch_f1:.4f}')\n",
    "\n",
    "test_matrix = confusion_matrix(test['label'], test['pred'], normalize='true')\n",
    "#test_matrix = confusion_matrix(test['label'], test['pred'])\n",
    "\n",
    "plt.figure(figsize = (15,10))\n",
    "sns.heatmap(test_matrix, \n",
    "            annot=True, \n",
    "            xticklabels = sorted(set(test['label'])), \n",
    "            yticklabels = sorted(set(test['label'])),\n",
    "            )\n",
    "plt.title('Normalized Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "#print(f'confusion_matrix \\n-------------------------\\n {test_matrix}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ab89fde5-9498-4a99-8bb8-4af301e4a6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv('test_result/incep_res_0403.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8cbfb49-98dd-4d2f-a778-21764270d9c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-gpu",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
