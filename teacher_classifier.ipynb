{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32c4ea0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, magic, shutil\n",
    "from glob import glob\n",
    "import time, datetime\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import joblib\n",
    "import datetime as dt\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torch, gc\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "\n",
    "#from skimage import io\n",
    "import sklearn\n",
    "from sklearn.model_selection import GroupKFold, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, log_loss, f1_score, confusion_matrix, classification_report\n",
    "from sklearn import metrics, preprocessing\n",
    "from scipy.ndimage import zoom\n",
    "import timm\n",
    "from timm.data import resolve_data_config\n",
    "from timm.data.transforms_factory import create_transform\n",
    "import albumentations as A\n",
    "import albumentations.pytorch\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29d0796-1f1d-40df-ad4a-21f57ed7fe35",
   "metadata": {},
   "source": [
    "#### Hyper Param Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57c0283c",
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'fold_num': 5,\n",
    "    'seed': 42,\n",
    "    'model': 'resnet152',\n",
    "    'img_size': 260,\n",
    "    'epochs': 200,\n",
    "    'train_bs':64,\n",
    "    'valid_bs':64,\n",
    "    'lr': 1e-4, ## learning rate\n",
    "    'num_workers': 8,\n",
    "    'verbose_step': 1,\n",
    "    'patience' : 5,\n",
    "    'label_encoder':False,\n",
    "    'device': 'cuda:0',\n",
    "    'freezing': False,\n",
    "    'trainable_layer': 12,\n",
    "    'model_path': './models'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7066a8a1-7060-4b6d-bf0c-d4164820a414",
   "metadata": {},
   "source": [
    "#### wandb init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "127461e4-c16d-47fd-b983-556c12ad0daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "category = 'box'\n",
    "time_now = dt.datetime.now()\n",
    "run_id = time_now.strftime(\"%Y%m%d%H%M\")\n",
    "project_name = 'KD_'+ CFG['model'] + '_' + category\n",
    "user = 'hojunking'\n",
    "run_name = project_name + '_' + run_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b6c4553-4301-4ba8-801e-e7130ac0b3cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: box 3919\n",
      "label: untapedBox 1987\n",
      "Train_Images:  5906\n",
      "Train_Images_labels: 5906\n"
     ]
    }
   ],
   "source": [
    "# TRAIN DATASET DATAFRAME\n",
    "train_path = '../Data/carbon_reduction_data/bin/train/'\n",
    "label_list = [\"box\",\"untapedBox\"]\n",
    "\n",
    "train_img_paths = []\n",
    "train_img_labels = []\n",
    "\n",
    "for label in label_list: ## 각 레이블 돌기\n",
    "    print(f'label: {label}',end=' ')\n",
    "    img_paths = [] \n",
    "    img_labels = []\n",
    "\n",
    "    dir_path = train_path + label ## 레이블 폴더 경로\n",
    "    \n",
    "    for folder, subfolders, filenames in os.walk(dir_path): ## 폴더 내 모든 파일 탐색\n",
    "        for img in filenames: ## 각 파일 경로, 레이블 저장\n",
    "            img_paths.append(folder+'/'+img)\n",
    "            img_labels.append(label)\n",
    "        \n",
    "    print(len(img_paths))\n",
    "\n",
    "    train_img_paths.extend(img_paths)\n",
    "    train_img_labels.extend(img_labels)\n",
    "\n",
    "print('Train_Images: ',len(train_img_paths))\n",
    "print(\"Train_Images_labels:\", len(train_img_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6aef7874-aa53-4c21-b0ff-f8985c3dc8d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: box 1307\n",
      "label: untapedBox 663\n",
      "Test_Images:  1970\n",
      "Test_Images_labels: 1970\n"
     ]
    }
   ],
   "source": [
    "# TEST DATASET DATAFRAME\n",
    "test_path = '../Data/carbon_reduction_data/bin/test/'\n",
    "test_img_paths = []\n",
    "test_img_labels = []\n",
    "\n",
    "for label in label_list: ## 각 레이블 돌기\n",
    "    print(f'label: {label}',end=' ')\n",
    "    img_paths = [] \n",
    "    img_labels = []\n",
    "    dir_path = test_path + label ## 레이블 폴더 경로\n",
    "    \n",
    "    for folder, subfolders, filenames in os.walk(dir_path): ## 폴더 내 모든 파일 탐색\n",
    "        for img in filenames: ## 각 파일 경로, 레이블 저장\n",
    "            img_paths.append(folder+'/'+img)\n",
    "            img_labels.append(label)\n",
    "        \n",
    "    print(len(img_paths))\n",
    "\n",
    "    test_img_paths.extend(img_paths)\n",
    "    test_img_labels.extend(img_labels)\n",
    "\n",
    "print('Test_Images: ',len(test_img_paths))\n",
    "print(\"Test_Images_labels:\", len(test_img_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2716dd8b-84db-4707-80e2-19b29eae9c23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>dir</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2449.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/bin/train/box</td>\n",
       "      <td>box</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0720.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/bin/train/box</td>\n",
       "      <td>box</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3004.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/bin/train/box</td>\n",
       "      <td>box</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0282.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/bin/train/box</td>\n",
       "      <td>box</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2404.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/bin/train/box</td>\n",
       "      <td>box</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5901</th>\n",
       "      <td>1378.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/bin/train/untape...</td>\n",
       "      <td>untapedBox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5902</th>\n",
       "      <td>1304.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/bin/train/untape...</td>\n",
       "      <td>untapedBox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5903</th>\n",
       "      <td>1492.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/bin/train/untape...</td>\n",
       "      <td>untapedBox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5904</th>\n",
       "      <td>1059.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/bin/train/untape...</td>\n",
       "      <td>untapedBox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5905</th>\n",
       "      <td>1512.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/bin/train/untape...</td>\n",
       "      <td>untapedBox</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5906 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      image_id                                                dir       label\n",
       "0     2449.jpg        ../Data/carbon_reduction_data/bin/train/box         box\n",
       "1     0720.jpg        ../Data/carbon_reduction_data/bin/train/box         box\n",
       "2     3004.jpg        ../Data/carbon_reduction_data/bin/train/box         box\n",
       "3     0282.jpg        ../Data/carbon_reduction_data/bin/train/box         box\n",
       "4     2404.jpg        ../Data/carbon_reduction_data/bin/train/box         box\n",
       "...        ...                                                ...         ...\n",
       "5901  1378.jpg  ../Data/carbon_reduction_data/bin/train/untape...  untapedBox\n",
       "5902  1304.jpg  ../Data/carbon_reduction_data/bin/train/untape...  untapedBox\n",
       "5903  1492.jpg  ../Data/carbon_reduction_data/bin/train/untape...  untapedBox\n",
       "5904  1059.jpg  ../Data/carbon_reduction_data/bin/train/untape...  untapedBox\n",
       "5905  1512.jpg  ../Data/carbon_reduction_data/bin/train/untape...  untapedBox\n",
       "\n",
       "[5906 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Pandas 데이터프레임 만들기\n",
    "trn_df = pd.DataFrame(train_img_paths, columns=['image_id'])\n",
    "trn_df['dir'] = trn_df['image_id'].apply(lambda x: os.path.dirname(x))\n",
    "trn_df['image_id'] = trn_df['image_id'].apply(lambda x: os.path.basename(x))\n",
    "trn_df['label'] = train_img_labels\n",
    "train = trn_df\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "105ae88a-4d4f-49a9-bffc-8689e2db0826",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>dir</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0720.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/bin/test/box</td>\n",
       "      <td>box</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0282.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/bin/test/box</td>\n",
       "      <td>box</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1028.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/bin/test/box</td>\n",
       "      <td>box</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0540.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/bin/test/box</td>\n",
       "      <td>box</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0466.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/bin/test/box</td>\n",
       "      <td>box</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1965</th>\n",
       "      <td>0384.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/bin/test/untapedBox</td>\n",
       "      <td>untapedBox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1966</th>\n",
       "      <td>0074.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/bin/test/untapedBox</td>\n",
       "      <td>untapedBox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1967</th>\n",
       "      <td>0515.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/bin/test/untapedBox</td>\n",
       "      <td>untapedBox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1968</th>\n",
       "      <td>0011.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/bin/test/untapedBox</td>\n",
       "      <td>untapedBox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1969</th>\n",
       "      <td>0611.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/bin/test/untapedBox</td>\n",
       "      <td>untapedBox</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1970 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      image_id                                                dir       label\n",
       "0     0720.jpg         ../Data/carbon_reduction_data/bin/test/box         box\n",
       "1     0282.jpg         ../Data/carbon_reduction_data/bin/test/box         box\n",
       "2     1028.jpg         ../Data/carbon_reduction_data/bin/test/box         box\n",
       "3     0540.jpg         ../Data/carbon_reduction_data/bin/test/box         box\n",
       "4     0466.jpg         ../Data/carbon_reduction_data/bin/test/box         box\n",
       "...        ...                                                ...         ...\n",
       "1965  0384.jpg  ../Data/carbon_reduction_data/bin/test/untapedBox  untapedBox\n",
       "1966  0074.jpg  ../Data/carbon_reduction_data/bin/test/untapedBox  untapedBox\n",
       "1967  0515.jpg  ../Data/carbon_reduction_data/bin/test/untapedBox  untapedBox\n",
       "1968  0011.jpg  ../Data/carbon_reduction_data/bin/test/untapedBox  untapedBox\n",
       "1969  0611.jpg  ../Data/carbon_reduction_data/bin/test/untapedBox  untapedBox\n",
       "\n",
       "[1970 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Pandas 데이터프레임 만들기\n",
    "tst_df = pd.DataFrame(test_img_paths, columns=['image_id'])\n",
    "tst_df['dir'] = tst_df['image_id'].apply(lambda x: os.path.dirname(x))\n",
    "tst_df['image_id'] = tst_df['image_id'].apply(lambda x: os.path.basename(x))\n",
    "tst_df['label'] = test_img_labels\n",
    "test = tst_df\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf387b57-bb5d-4564-96db-d764e547a93a",
   "metadata": {},
   "source": [
    "##### Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03c67d39-7933-4f98-b998-54a6036ff4a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>dir</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2449.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/bin/train/box</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0720.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/bin/train/box</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3004.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/bin/train/box</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0282.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/bin/train/box</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2404.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/bin/train/box</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5901</th>\n",
       "      <td>1378.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/bin/train/untape...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5902</th>\n",
       "      <td>1304.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/bin/train/untape...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5903</th>\n",
       "      <td>1492.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/bin/train/untape...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5904</th>\n",
       "      <td>1059.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/bin/train/untape...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5905</th>\n",
       "      <td>1512.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/bin/train/untape...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5906 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      image_id                                                dir  label\n",
       "0     2449.jpg        ../Data/carbon_reduction_data/bin/train/box      0\n",
       "1     0720.jpg        ../Data/carbon_reduction_data/bin/train/box      0\n",
       "2     3004.jpg        ../Data/carbon_reduction_data/bin/train/box      0\n",
       "3     0282.jpg        ../Data/carbon_reduction_data/bin/train/box      0\n",
       "4     2404.jpg        ../Data/carbon_reduction_data/bin/train/box      0\n",
       "...        ...                                                ...    ...\n",
       "5901  1378.jpg  ../Data/carbon_reduction_data/bin/train/untape...      1\n",
       "5902  1304.jpg  ../Data/carbon_reduction_data/bin/train/untape...      1\n",
       "5903  1492.jpg  ../Data/carbon_reduction_data/bin/train/untape...      1\n",
       "5904  1059.jpg  ../Data/carbon_reduction_data/bin/train/untape...      1\n",
       "5905  1512.jpg  ../Data/carbon_reduction_data/bin/train/untape...      1\n",
       "\n",
       "[5906 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "train['label'] = le.fit_transform(train['label'].values)\n",
    "test['label'] = le.transform(test['label'].values)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29be149b-1ea0-4e34-846e-7395d4e94f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_encoding_classes():\n",
    "    # define certain classes to transform differently\n",
    "    capture_image_classes = ['10Kwalk', 'battery','receipt']\n",
    "    return le.transform(capture_image_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c454bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d97a3c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img(path, sub_path=None):\n",
    "    try:\n",
    "        im_bgr = cv2.imread(path)\n",
    "        im_rgb = im_bgr[:, :, ::-1]\n",
    "        past_path = path\n",
    "    except: ## 이미지 에러 발생 시 백지로 대체\n",
    "        im_bgr = cv2.imread('../Data/carbon_reduction/temp_img.jpg')\n",
    "        im_rgb = im_bgr[:, :, ::-1]\n",
    "    return im_rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "884eb987-4341-4fe7-8094-6e61cb051af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = A.Compose([\n",
    "    A.OneOf([\n",
    "        A.Compose([\n",
    "            A.RandomResizedCrop(p=1, height=CFG['img_size'] ,width=CFG['img_size'], scale=(0.65, 0.75),ratio=(0.90, 1.10)),\n",
    "        ], p=0.8),\n",
    "        A.Compose([\n",
    "            A.Resize(p=1, height = CFG['img_size'], width = CFG['img_size']),\n",
    "        ], p=0.2),\n",
    "    ], p=1.0),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.SafeRotate(p=0.5, limit=(-20, 20), interpolation=2, border_mode=0, value=(0, 0, 0), mask_value=None),\n",
    "    A.ColorJitter(always_apply=True, p=0.5, contrast=0.2, saturation=0.3, hue=0.2),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, always_apply=True, p=1.0),\n",
    "    A.pytorch.transforms.ToTensorV2()\n",
    "        ])\n",
    "\n",
    "transform_train_cap = A.Compose([\n",
    "    A.OneOf([\n",
    "        A.Compose([\n",
    "            A.RandomResizedCrop(p=1, height=CFG['img_size'] ,width=CFG['img_size'], scale=(0.65, 0.85),ratio=(0.90, 1.10)),\n",
    "        ], p=0.6),\n",
    "        A.Compose([\n",
    "            A.Resize(p=1, height = CFG['img_size'], width = CFG['img_size']),\n",
    "        ], p=0.4),\n",
    "    ], p=1.0),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, always_apply=True, p=1.0),\n",
    "    A.pytorch.transforms.ToTensorV2()\n",
    "])\n",
    "\n",
    "transform_test = A.Compose([\n",
    "    A.Resize(height = CFG['img_size'], width = CFG['img_size']),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, p=1.0),\n",
    "    A.pytorch.transforms.ToTensorV2()\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f1561be",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, df, data_root, transform=None, transform2=None, output_label=True, encoded_class=False):\n",
    "        super(CustomDataset,self).__init__()\n",
    "        self.df = df.reset_index(drop=True).copy()\n",
    "        self.transform = transform\n",
    "        self.transform2 = transform2\n",
    "        self.data_root = data_root\n",
    "        self.output_label = output_label\n",
    "         \n",
    "        if encoded_class == True:\n",
    "            self.encoded_class = label_encoding_classes()\n",
    "        else:\n",
    "            self.encoded_class = encoded_class\n",
    "            \n",
    "        if output_label == True:\n",
    "            self.labels = self.df['label'].values\n",
    "        \n",
    "    # AUGMENTATION DIFFERENTLY DEPENDING ON THE TARGET\n",
    "    def custom_augmentation(self, img, target):\n",
    "        if self.encoded_class is not False and target in self.encoded_class:\n",
    "            return self.transform2(image=img)\n",
    "        else:\n",
    "            return self.transform(image=img)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index: int):\n",
    "        \n",
    "        # GET IMAGES\n",
    "        path = \"{}/{}\".format(self.data_root[index], self.df.iloc[index]['image_id'])\n",
    "        img  = get_img(path)\n",
    "        \n",
    "        # GET LABELS\n",
    "        if self.output_label:\n",
    "            target = self.labels[index]\n",
    "            \n",
    "            # CUSTOM AUGMENTATION\n",
    "            transformed = self.custom_augmentation(img, target) \n",
    "            img = transformed['image']\n",
    "            return img, target\n",
    "        else:\n",
    "            transformed =self.transform(image=img)\n",
    "            img = transformed['image']\n",
    "            return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7acf9a37-cf66-431c-85c2-d559515afe2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD PRE-TRAINED MODEL\n",
    "class Teacher(nn.Module):\n",
    "    def __init__(self, model_arch_str, num_classes= 2,pretrained=True):\n",
    "        super(Teacher, self).__init__()\n",
    "        model_arch = getattr(models, model_arch_str)\n",
    "        self.backbone = model_arch(pretrained=pretrained) ## 모델 선언 여기 models.##(pretrained =pretrained)\n",
    "        self.backbone.fc = nn.Linear(self.backbone.fc.in_features, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "240e5531",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataloader(df, trn_idx, val_idx, data_root=train.dir.values):\n",
    "    \n",
    "    train_ = df.loc[trn_idx,:].reset_index(drop=True)\n",
    "    valid_ = df.loc[val_idx,:].reset_index(drop=True)\n",
    "    train_data_root = data_root[trn_idx]\n",
    "    valid_data_root = data_root[val_idx]\n",
    "    \n",
    "        \n",
    "    train_ds = CustomDataset(train_, train_data_root, transform=transform_train,\n",
    "                            transform2=transform_train_cap, output_label=True, encoded_class=CFG['label_encoder'])\n",
    "    valid_ds = CustomDataset(valid_, valid_data_root, transform=transform_test,\n",
    "                            output_label=True)\n",
    "    # WEIGHTEDRANDOMSAMPLER\n",
    "    class_counts = train_.label.value_counts(sort=False).to_dict()\n",
    "    num_samples = sum(class_counts.values())\n",
    "    print(f'cls_cnts: {len(class_counts)}\\nnum_samples:{num_samples}')\n",
    "    \n",
    "    # weight 제작, 전체 학습 데이터 수를 해당 클래스의 데이터 수로 나누어 줌\n",
    "    class_weights = {l:round(num_samples/class_counts[l], 2) for l in class_counts.keys()}\n",
    "    t_labels = train_.label.to_list()\n",
    "    \n",
    "    # class 별 weight를 전체 trainset에 대응시켜 sampler에 넣어줌\n",
    "    weights = [class_weights[t_labels[i]] for i in range(int(num_samples))]\n",
    "\n",
    "\n",
    "    # weight 제작, 전체 학습 데이터 수를 해당 클래스의 데이터 수로 나누어 줌\n",
    "    class_weights = {l:round(num_samples/class_counts[l], 2) for l in class_counts.keys()}\n",
    "\n",
    "    # class 별 weight를 전체 trainset에 대응시켜 sampler에 넣어줌\n",
    "    weights = [class_weights[t_labels[i]] for i in range(int(num_samples))] \n",
    "    sampler = torch.utils.data.WeightedRandomSampler(torch.DoubleTensor(weights), int(num_samples))\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_ds,\n",
    "        batch_size=CFG['train_bs'],\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "        shuffle=False,\n",
    "        sampler=sampler, \n",
    "        num_workers=CFG['num_workers']\n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        valid_ds, \n",
    "        batch_size=CFG['valid_bs'],\n",
    "        num_workers=CFG['num_workers'],\n",
    "        shuffle=False,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "08ffa2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(epoch, model, loss_fn, optimizer, train_loader, device, scheduler=None):\n",
    "    t = time.time()\n",
    "    \n",
    "    # SET MODEL TRAINING MODE\n",
    "    model.train()\n",
    "    \n",
    "    running_loss = None\n",
    "    loss_sum = 0\n",
    "    image_preds_all = []\n",
    "    image_targets_all = []\n",
    "    acc_list = []\n",
    "    \n",
    "    pbar = tqdm(enumerate(train_loader), total=len(train_loader))\n",
    "    for step, (imgs, image_labels) in pbar:\n",
    "        imgs = imgs.to(device).float()\n",
    "        image_labels = image_labels.to(device).long()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # TEACHER MODEL PREDICTION\n",
    "        with torch.cuda.amp.autocast():\n",
    "            image_preds = model(imgs)   #output = model(input)\n",
    "\n",
    "            loss = loss_fn(image_preds, image_labels)\n",
    "            loss_sum+=loss.detach()\n",
    "            \n",
    "            # BACKPROPAGATION\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        \n",
    "            if running_loss is None:\n",
    "                running_loss = loss.item()\n",
    "            else:\n",
    "                running_loss = running_loss * .99 + loss.item() * .01    \n",
    "        \n",
    "            # TQDM VERBOSE_STEP TRACKING\n",
    "            if ((step + 1) % CFG['verbose_step'] == 0) or ((step + 1) == len(train_loader)):\n",
    "                description = f'epoch {epoch} loss: {running_loss:.4f}'\n",
    "                pbar.set_description(description)\n",
    "        \n",
    "        image_preds_all += [torch.argmax(image_preds, 1).detach().cpu().numpy()]\n",
    "        image_targets_all += [image_labels.detach().cpu().numpy()]\n",
    "        \n",
    "    if scheduler is not None:\n",
    "        scheduler.step()\n",
    "    \n",
    "    image_preds_all = np.concatenate(image_preds_all)\n",
    "    image_targets_all = np.concatenate(image_targets_all)\n",
    "    \n",
    "    matrix = confusion_matrix(image_targets_all,image_preds_all)\n",
    "    epoch_f1 = f1_score(image_targets_all, image_preds_all, average='macro')\n",
    "    \n",
    "    accuracy = (image_preds_all==image_targets_all).mean()\n",
    "    trn_loss = loss_sum/len(train_loader)\n",
    "    \n",
    "    return image_preds_all, accuracy, trn_loss, matrix, epoch_f1\n",
    "\n",
    "def valid_one_epoch(epoch, model, loss_fn, val_loader, device, scheduler=None, schd_loss_update=False):\n",
    "    t = time.time()\n",
    "    \n",
    "    # SET MODEL VALID MODE\n",
    "    model.eval()\n",
    "    \n",
    "    loss_sum = 0\n",
    "    sample_num = 0\n",
    "    avg_loss = 0\n",
    "    image_preds_all = []\n",
    "    image_targets_all = []\n",
    "    acc_list = []\n",
    "    \n",
    "    pbar = tqdm(enumerate(val_loader), total=len(val_loader))\n",
    "    for step, (imgs, image_labels) in pbar:\n",
    "        imgs = imgs.to(device).float()\n",
    "        image_labels = image_labels.to(device).long()\n",
    "        \n",
    "        # TEACHER MODEL PREDICTION\n",
    "        image_preds = model(imgs)\n",
    "        image_preds_all += [torch.argmax(image_preds, 1).detach().cpu().numpy()]\n",
    "        image_targets_all += [image_labels.detach().cpu().numpy()]\n",
    "        \n",
    "        loss = loss_fn(image_preds, image_labels)\n",
    "        \n",
    "        avg_loss += loss.item()\n",
    "        loss_sum += loss.item()*image_labels.shape[0]\n",
    "        sample_num += image_labels.shape[0]\n",
    "        \n",
    "        # TQDM\n",
    "        description = f'epoch {epoch} loss: {loss_sum/sample_num:.4f}'\n",
    "        pbar.set_description(description)\n",
    "    \n",
    "    image_preds_all = np.concatenate(image_preds_all)\n",
    "    image_targets_all = np.concatenate(image_targets_all)\n",
    "    matrix = confusion_matrix(image_targets_all,image_preds_all)\n",
    "    \n",
    "    epoch_f1 = f1_score(image_targets_all, image_preds_all, average='macro')\n",
    "    acc = (image_preds_all==image_targets_all).mean()\n",
    "    val_loss = avg_loss/len(val_loader)\n",
    "    \n",
    "    return image_preds_all, acc, val_loss, matrix, epoch_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "77e9950b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10, verbose=False, delta=0):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "\n",
    "    def __call__(self, score):\n",
    "        print(f' present score: {score}')\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "        elif score <= self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            print(f'Best F1 score from now: {self.best_score}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.counter = 0\n",
    "        \n",
    "        return self.early_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "37102a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhojunking\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/hojun/git/KD_models/wandb/run-20230519_125659-pu3z3zom</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/hojunking/KD_resnet152_box/runs/pu3z3zom' target=\"_blank\">amber-water-5</a></strong> to <a href='https://wandb.ai/hojunking/KD_resnet152_box' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/hojunking/KD_resnet152_box' target=\"_blank\">https://wandb.ai/hojunking/KD_resnet152_box</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/hojunking/KD_resnet152_box/runs/pu3z3zom' target=\"_blank\">https://wandb.ai/hojunking/KD_resnet152_box/runs/pu3z3zom</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: resnet152\n",
      "Training start with fold: 0 epoch: 200 \n",
      "\n",
      "cls_cnts: 2\n",
      "num_samples:4724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hojun/miniconda3/envs/torch/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/hojun/miniconda3/envs/torch/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet152_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet152_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 0\n",
      "Epoch 0/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 0 loss: 0.3853: 100%|████████████████████████████████████████████████████████████████████████| 74/74 [01:11<00:00,  1.03it/s]\n",
      "epoch 0 loss: 0.0757: 100%|████████████████████████████████████████████████████████████████████████| 19/19 [00:13<00:00,  1.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], Train Loss : [0.12802] Val Loss : [0.07467] Val F1 Score : [0.97066]\n",
      " present score: 0.9706605578193273\n",
      "Epoch 1/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 loss: 0.0479: 100%|████████████████████████████████████████████████████████████████████████| 74/74 [01:00<00:00,  1.23it/s]\n",
      "epoch 1 loss: 0.0548: 100%|████████████████████████████████████████████████████████████████████████| 19/19 [00:13<00:00,  1.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1], Train Loss : [0.07252] Val Loss : [0.05800] Val F1 Score : [0.97992]\n",
      " present score: 0.9799227224600691\n",
      "Epoch 2/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 2 loss: 0.0692: 100%|████████████████████████████████████████████████████████████████████████| 74/74 [01:03<00:00,  1.17it/s]\n",
      "epoch 2 loss: 0.0543: 100%|████████████████████████████████████████████████████████████████████████| 19/19 [00:11<00:00,  1.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2], Train Loss : [0.05072] Val Loss : [0.05437] Val F1 Score : [0.98387]\n",
      " present score: 0.9838706440745447\n",
      "Epoch 3/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 3 loss: 0.0353: 100%|████████████████████████████████████████████████████████████████████████| 74/74 [01:01<00:00,  1.20it/s]\n",
      "epoch 3 loss: 0.0542: 100%|████████████████████████████████████████████████████████████████████████| 19/19 [00:12<00:00,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3], Train Loss : [0.03875] Val Loss : [0.05303] Val F1 Score : [0.97559]\n",
      " present score: 0.9755851089184422\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Best F1 score from now: 0.9838706440745447\n",
      "Epoch 4/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 4 loss: 0.0486: 100%|████████████████████████████████████████████████████████████████████████| 74/74 [01:02<00:00,  1.19it/s]\n",
      "epoch 4 loss: 0.0657: 100%|████████████████████████████████████████████████████████████████████████| 19/19 [00:12<00:00,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4], Train Loss : [0.03366] Val Loss : [0.06583] Val F1 Score : [0.98096]\n",
      " present score: 0.9809644670050762\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Best F1 score from now: 0.9838706440745447\n",
      "Epoch 5/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 5 loss: 0.0287: 100%|████████████████████████████████████████████████████████████████████████| 74/74 [01:01<00:00,  1.20it/s]\n",
      "epoch 5 loss: 0.0398: 100%|████████████████████████████████████████████████████████████████████████| 19/19 [00:12<00:00,  1.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5], Train Loss : [0.03593] Val Loss : [0.03947] Val F1 Score : [0.98773]\n",
      " present score: 0.987726474344689\n",
      "Epoch 6/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 6 loss: 0.0123: 100%|████████████████████████████████████████████████████████████████████████| 74/74 [01:03<00:00,  1.16it/s]\n",
      "epoch 6 loss: 0.0394: 100%|████████████████████████████████████████████████████████████████████████| 19/19 [00:12<00:00,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6], Train Loss : [0.01790] Val Loss : [0.03921] Val F1 Score : [0.98481]\n",
      " present score: 0.9848099313748168\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Best F1 score from now: 0.987726474344689\n",
      "Epoch 7/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 7 loss: 0.0066: 100%|████████████████████████████████████████████████████████████████████████| 74/74 [01:02<00:00,  1.19it/s]\n",
      "epoch 7 loss: 0.0364: 100%|████████████████████████████████████████████████████████████████████████| 19/19 [00:12<00:00,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7], Train Loss : [0.00998] Val Loss : [0.03561] Val F1 Score : [0.98395]\n",
      " present score: 0.9839500049122858\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Best F1 score from now: 0.987726474344689\n",
      "Epoch 8/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 8 loss: 0.0420: 100%|████████████████████████████████████████████████████████████████████████| 74/74 [01:01<00:00,  1.20it/s]\n",
      "epoch 8 loss: 0.0350: 100%|████████████████████████████████████████████████████████████████████████| 19/19 [00:12<00:00,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8], Train Loss : [0.00898] Val Loss : [0.03566] Val F1 Score : [0.98580]\n",
      " present score: 0.9858034957190294\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Best F1 score from now: 0.987726474344689\n",
      "Epoch 9/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 9 loss: 0.0042: 100%|████████████████████████████████████████████████████████████████████████| 74/74 [01:03<00:00,  1.17it/s]\n",
      "epoch 9 loss: 0.0448: 100%|████████████████████████████████████████████████████████████████████████| 19/19 [00:11<00:00,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9], Train Loss : [0.00749] Val Loss : [0.04803] Val F1 Score : [0.98096]\n",
      " present score: 0.9809644670050762\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Best F1 score from now: 0.987726474344689\n",
      "Epoch 10/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 10 loss: 0.0057: 100%|███████████████████████████████████████████████████████████████████████| 74/74 [01:01<00:00,  1.20it/s]\n",
      "epoch 10 loss: 0.0354: 100%|███████████████████████████████████████████████████████████████████████| 19/19 [00:12<00:00,  1.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10], Train Loss : [0.00972] Val Loss : [0.03453] Val F1 Score : [0.98865]\n",
      " present score: 0.9886497853829977\n",
      "Epoch 11/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 11 loss: 0.0034: 100%|███████████████████████████████████████████████████████████████████████| 74/74 [00:58<00:00,  1.27it/s]\n",
      "epoch 11 loss: 0.0337: 100%|███████████████████████████████████████████████████████████████████████| 19/19 [00:10<00:00,  1.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11], Train Loss : [0.00535] Val Loss : [0.03296] Val F1 Score : [0.98959]\n",
      " present score: 0.9895892301939548\n",
      "Epoch 12/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 12 loss: 0.0029: 100%|███████████████████████████████████████████████████████████████████████| 74/74 [00:55<00:00,  1.33it/s]\n",
      "epoch 12 loss: 0.0360: 100%|███████████████████████████████████████████████████████████████████████| 19/19 [00:11<00:00,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12], Train Loss : [0.00468] Val Loss : [0.03539] Val F1 Score : [0.98765]\n",
      " present score: 0.9876503223244977\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Best F1 score from now: 0.9895892301939548\n",
      "Epoch 13/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 15 loss: 0.0013: 100%|███████████████████████████████████████████████████████████████████████| 74/74 [00:55<00:00,  1.34it/s]\n",
      "epoch 15 loss: 0.0346: 100%|███████████████████████████████████████████████████████████████████████| 19/19 [00:11<00:00,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15], Train Loss : [0.00199] Val Loss : [0.03373] Val F1 Score : [0.98958]\n",
      " present score: 0.9895763435429369\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Best F1 score from now: 0.9895892301939548\n",
      "Epoch 16/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 16 loss: 0.0037: 100%|███████████████████████████████████████████████████████████████████████| 74/74 [00:56<00:00,  1.31it/s]\n",
      "epoch 16 loss: 0.0336: 100%|███████████████████████████████████████████████████████████████████████| 19/19 [00:10<00:00,  1.76it/s]\n",
      "/home/hojun/miniconda3/envs/torch/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/hojun/miniconda3/envs/torch/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet152_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet152_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16], Train Loss : [0.00327] Val Loss : [0.03273] Val F1 Score : [0.98864]\n",
      " present score: 0.988635780945544\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Best F1 score from now: 0.9895892301939548\n",
      "stop called\n",
      "time : 0:20:50\n",
      "fold: 0, Best Epoch : 11/ 17\n",
      "Best Train Marco F1 : 0.99809\n",
      "[[2397    5]\n",
      " [   4 2318]]\n",
      "Best Valid Marco F1 : 0.98959\n",
      "[[778   6]\n",
      " [  5 393]]\n",
      "-----------------------------------------------------------------------\n",
      "Training start with fold: 1 epoch: 200 \n",
      "\n",
      "cls_cnts: 2\n",
      "num_samples:4725\n",
      "Fold: 1\n",
      "Epoch 0/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 0 loss: 0.3903: 100%|████████████████████████████████████████████████████████████████████████| 74/74 [00:58<00:00,  1.26it/s]\n",
      "epoch 0 loss: 0.0631: 100%|████████████████████████████████████████████████████████████████████████| 19/19 [00:11<00:00,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], Train Loss : [0.13588] Val Loss : [0.06371] Val F1 Score : [0.97700]\n",
      " present score: 0.9770000778998209\n",
      "Epoch 1/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 1 loss: 0.0562: 100%|████████████████████████████████████████████████████████████████████████| 74/74 [00:55<00:00,  1.34it/s]\n",
      "epoch 1 loss: 0.0462: 100%|████████████████████████████████████████████████████████████████████████| 19/19 [00:10<00:00,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1], Train Loss : [0.06582] Val Loss : [0.04610] Val F1 Score : [0.98183]\n",
      " present score: 0.9818272523994522\n",
      "Epoch 2/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 2 loss: 0.0535: 100%|████████████████████████████████████████████████████████████████████████| 74/74 [00:56<00:00,  1.30it/s]\n",
      "epoch 2 loss: 0.0464: 100%|████████████████████████████████████████████████████████████████████████| 19/19 [00:11<00:00,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2], Train Loss : [0.05069] Val Loss : [0.04818] Val F1 Score : [0.98088]\n",
      " present score: 0.9808831622907832\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Best F1 score from now: 0.9818272523994522\n",
      "Epoch 3/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 3 loss: 0.0460: 100%|████████████████████████████████████████████████████████████████████████| 74/74 [00:55<00:00,  1.33it/s]\n",
      "epoch 3 loss: 0.0910: 100%|████████████████████████████████████████████████████████████████████████| 19/19 [00:11<00:00,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3], Train Loss : [0.04530] Val Loss : [0.08875] Val F1 Score : [0.96467]\n",
      " present score: 0.9646672209310381\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Best F1 score from now: 0.9818272523994522\n",
      "Epoch 4/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 4 loss: 0.0279: 100%|████████████████████████████████████████████████████████████████████████| 74/74 [00:55<00:00,  1.34it/s]\n",
      "epoch 4 loss: 0.0443: 100%|████████████████████████████████████████████████████████████████████████| 19/19 [00:10<00:00,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4], Train Loss : [0.04061] Val Loss : [0.04575] Val F1 Score : [0.98478]\n",
      " present score: 0.984784359197346\n",
      "Epoch 5/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 5 loss: 0.0123: 100%|████████████████████████████████████████████████████████████████████████| 74/74 [00:55<00:00,  1.33it/s]\n",
      "epoch 5 loss: 0.0371: 100%|████████████████████████████████████████████████████████████████████████| 19/19 [00:10<00:00,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5], Train Loss : [0.02157] Val Loss : [0.03703] Val F1 Score : [0.98667]\n",
      " present score: 0.9866694831623011\n",
      "Epoch 6/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 6 loss: 0.0126: 100%|████████████████████████████████████████████████████████████████████████| 74/74 [00:55<00:00,  1.34it/s]\n",
      "epoch 6 loss: 0.0346: 100%|████████████████████████████████████████████████████████████████████████| 19/19 [00:11<00:00,  1.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6], Train Loss : [0.01268] Val Loss : [0.03419] Val F1 Score : [0.99144]\n",
      " present score: 0.9914358023587198\n",
      "Epoch 7/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 7 loss: 0.0256: 100%|████████████████████████████████████████████████████████████████████████| 74/74 [00:53<00:00,  1.38it/s]\n",
      "epoch 7 loss: 0.0324: 100%|████████████████████████████████████████████████████████████████████████| 19/19 [00:10<00:00,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7], Train Loss : [0.01098] Val Loss : [0.03192] Val F1 Score : [0.99050]\n",
      " present score: 0.9905021553110726\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Best F1 score from now: 0.9914358023587198\n",
      "Epoch 8/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 8 loss: 0.0079: 100%|████████████████████████████████████████████████████████████████████████| 74/74 [00:54<00:00,  1.35it/s]\n",
      "epoch 8 loss: 0.0498: 100%|████████████████████████████████████████████████████████████████████████| 19/19 [00:10<00:00,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8], Train Loss : [0.01101] Val Loss : [0.04863] Val F1 Score : [0.99050]\n",
      " present score: 0.9905021553110726\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Best F1 score from now: 0.9914358023587198\n",
      "Epoch 9/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 9 loss: 0.0087: 100%|████████████████████████████████████████████████████████████████████████| 74/74 [00:55<00:00,  1.33it/s]\n",
      "epoch 9 loss: 0.0477: 100%|████████████████████████████████████████████████████████████████████████| 19/19 [00:10<00:00,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9], Train Loss : [0.01063] Val Loss : [0.04680] Val F1 Score : [0.98766]\n",
      " present score: 0.9876605125954717\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Best F1 score from now: 0.9914358023587198\n",
      "Epoch 10/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 10 loss: 0.0136: 100%|███████████████████████████████████████████████████████████████████████| 74/74 [00:56<00:00,  1.31it/s]\n",
      "epoch 10 loss: 0.0448: 100%|███████████████████████████████████████████████████████████████████████| 19/19 [00:10<00:00,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10], Train Loss : [0.00746] Val Loss : [0.04357] Val F1 Score : [0.98768]\n",
      " present score: 0.9876758457654533\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Best F1 score from now: 0.9914358023587198\n",
      "Epoch 11/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 11 loss: 0.0032: 100%|███████████████████████████████████████████████████████████████████████| 74/74 [00:54<00:00,  1.35it/s]\n",
      "epoch 11 loss: 0.0387: 100%|███████████████████████████████████████████████████████████████████████| 19/19 [00:10<00:00,  1.88it/s]\n",
      "/home/hojun/miniconda3/envs/torch/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/hojun/miniconda3/envs/torch/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet152_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet152_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11], Train Loss : [0.00496] Val Loss : [0.03775] Val F1 Score : [0.98955]\n",
      " present score: 0.9895458214267608\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Best F1 score from now: 0.9914358023587198\n",
      "stop called\n",
      "time : 0:13:26\n",
      "fold: 1, Best Epoch : 6/ 12\n",
      "Best Train Marco F1 : 0.99577\n",
      "[[2383   10]\n",
      " [  10 2322]]\n",
      "Best Valid Marco F1 : 0.99144\n",
      "[[782   2]\n",
      " [  7 390]]\n",
      "-----------------------------------------------------------------------\n",
      "Training start with fold: 2 epoch: 200 \n",
      "\n",
      "cls_cnts: 2\n",
      "num_samples:4725\n",
      "Fold: 2\n",
      "Epoch 0/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 0 loss: 0.4012: 100%|████████████████████████████████████████████████████████████████████████| 74/74 [00:54<00:00,  1.37it/s]\n",
      "epoch 0 loss: 0.0936: 100%|████████████████████████████████████████████████████████████████████████| 19/19 [00:10<00:00,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], Train Loss : [0.11524] Val Loss : [0.09277] Val F1 Score : [0.96733]\n",
      " present score: 0.9673308860380501\n",
      "Epoch 1/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 1 loss: 0.0437: 100%|████████████████████████████████████████████████████████████████████████| 74/74 [00:55<00:00,  1.34it/s]\n",
      "epoch 1 loss: 0.0524: 100%|████████████████████████████████████████████████████████████████████████| 19/19 [00:11<00:00,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1], Train Loss : [0.06933] Val Loss : [0.05428] Val F1 Score : [0.97424]\n",
      " present score: 0.9742419897491408\n",
      "Epoch 2/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 2 loss: 0.0285: 100%|████████████████████████████████████████████████████████████████████████| 74/74 [00:56<00:00,  1.32it/s]\n",
      "epoch 2 loss: 0.0540: 100%|████████████████████████████████████████████████████████████████████████| 19/19 [00:10<00:00,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2], Train Loss : [0.04494] Val Loss : [0.05863] Val F1 Score : [0.98014]\n",
      " present score: 0.9801407229286128\n",
      "Epoch 3/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 3 loss: 0.0617: 100%|████████████████████████████████████████████████████████████████████████| 74/74 [00:56<00:00,  1.32it/s]\n",
      "epoch 3 loss: 0.0747: 100%|████████████████████████████████████████████████████████████████████████| 19/19 [00:10<00:00,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3], Train Loss : [0.04554] Val Loss : [0.07688] Val F1 Score : [0.97453]\n",
      " present score: 0.9745286477824898\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Best F1 score from now: 0.9801407229286128\n",
      "Epoch 4/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 4 loss: 0.0629: 100%|████████████████████████████████████████████████████████████████████████| 74/74 [00:54<00:00,  1.37it/s]\n",
      "epoch 4 loss: 0.0659: 100%|████████████████████████████████████████████████████████████████████████| 19/19 [00:10<00:00,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4], Train Loss : [0.03299] Val Loss : [0.06595] Val F1 Score : [0.97721]\n",
      " present score: 0.9772051727465739\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Best F1 score from now: 0.9801407229286128\n",
      "Epoch 5/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 5 loss: 0.0317: 100%|████████████████████████████████████████████████████████████████████████| 74/74 [00:53<00:00,  1.38it/s]\n",
      "epoch 5 loss: 0.0533: 100%|████████████████████████████████████████████████████████████████████████| 19/19 [00:11<00:00,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5], Train Loss : [0.02436] Val Loss : [0.05505] Val F1 Score : [0.98386]\n",
      " present score: 0.9838637472402323\n",
      "Epoch 6/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 6 loss: 0.0105: 100%|████████████████████████████████████████████████████████████████████████| 74/74 [00:57<00:00,  1.29it/s]\n",
      "epoch 6 loss: 0.0485: 100%|████████████████████████████████████████████████████████████████████████| 19/19 [00:11<00:00,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6], Train Loss : [0.01685] Val Loss : [0.05060] Val F1 Score : [0.98098]\n",
      " present score: 0.9809804489966825\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Best F1 score from now: 0.9838637472402323\n",
      "Epoch 7/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 7 loss: 0.0048: 100%|████████████████████████████████████████████████████████████████████████| 74/74 [00:55<00:00,  1.34it/s]\n",
      "epoch 7 loss: 0.0582: 100%|████████████████████████████████████████████████████████████████████████| 19/19 [00:11<00:00,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7], Train Loss : [0.00860] Val Loss : [0.05912] Val F1 Score : [0.97624]\n",
      " present score: 0.9762405032426382\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Best F1 score from now: 0.9838637472402323\n",
      "Epoch 8/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 8 loss: 0.0078: 100%|████████████████████████████████████████████████████████████████████████| 74/74 [00:55<00:00,  1.33it/s]\n",
      "epoch 8 loss: 0.0756: 100%|████████████████████████████████████████████████████████████████████████| 19/19 [00:11<00:00,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8], Train Loss : [0.01164] Val Loss : [0.07728] Val F1 Score : [0.97421]\n",
      " present score: 0.9742089056801555\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Best F1 score from now: 0.9838637472402323\n",
      "Epoch 9/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 9 loss: 0.0059: 100%|████████████████████████████████████████████████████████████████████████| 74/74 [00:56<00:00,  1.30it/s]\n",
      "epoch 9 loss: 0.0673: 100%|████████████████████████████████████████████████████████████████████████| 19/19 [00:10<00:00,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9], Train Loss : [0.00977] Val Loss : [0.07048] Val F1 Score : [0.97624]\n",
      " present score: 0.9762405032426382\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Best F1 score from now: 0.9838637472402323\n",
      "Epoch 10/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 10 loss: 0.0272: 100%|███████████████████████████████████████████████████████████████████████| 74/74 [00:56<00:00,  1.32it/s]\n",
      "epoch 10 loss: 0.0681: 100%|███████████████████████████████████████████████████████████████████████| 19/19 [00:10<00:00,  1.73it/s]\n",
      "/home/hojun/miniconda3/envs/torch/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/hojun/miniconda3/envs/torch/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet152_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet152_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10], Train Loss : [0.01076] Val Loss : [0.07100] Val F1 Score : [0.98004]\n",
      " present score: 0.980042022723816\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Best F1 score from now: 0.9838637472402323\n",
      "stop called\n",
      "time : 0:12:22\n",
      "fold: 2, Best Epoch : 5/ 11\n",
      "Best Train Marco F1 : 0.99344\n",
      "[[2372   15]\n",
      " [  16 2322]]\n",
      "Best Valid Marco F1 : 0.98386\n",
      "[[776   8]\n",
      " [  9 388]]\n",
      "-----------------------------------------------------------------------\n",
      "Training start with fold: 3 epoch: 200 \n",
      "\n",
      "cls_cnts: 2\n",
      "num_samples:4725\n",
      "Fold: 3\n",
      "Epoch 0/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 0 loss: 0.4088: 100%|████████████████████████████████████████████████████████████████████████| 74/74 [00:56<00:00,  1.31it/s]\n",
      "epoch 0 loss: 0.0683: 100%|████████████████████████████████████████████████████████████████████████| 19/19 [00:12<00:00,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], Train Loss : [0.12659] Val Loss : [0.06660] Val F1 Score : [0.97083]\n",
      " present score: 0.9708252150595473\n",
      "Epoch 1/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 1 loss: 0.0555: 100%|████████████████████████████████████████████████████████████████████████| 74/74 [00:55<00:00,  1.32it/s]\n",
      "epoch 1 loss: 0.0465: 100%|████████████████████████████████████████████████████████████████████████| 19/19 [00:11<00:00,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1], Train Loss : [0.05881] Val Loss : [0.04653] Val F1 Score : [0.98194]\n",
      " present score: 0.981942782464405\n",
      "Epoch 2/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 2 loss: 0.0909: 100%|████████████████████████████████████████████████████████████████████████| 74/74 [00:55<00:00,  1.33it/s]\n",
      "epoch 2 loss: 0.0802: 100%|████████████████████████████████████████████████████████████████████████| 19/19 [00:11<00:00,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2], Train Loss : [0.04911] Val Loss : [0.08505] Val F1 Score : [0.96917]\n",
      " present score: 0.9691705279644978\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Best F1 score from now: 0.981942782464405\n",
      "Epoch 3/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 3 loss: 0.0327: 100%|████████████████████████████████████████████████████████████████████████| 74/74 [00:55<00:00,  1.33it/s]\n",
      "epoch 3 loss: 0.0676: 100%|████████████████████████████████████████████████████████████████████████| 19/19 [00:11<00:00,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3], Train Loss : [0.04435] Val Loss : [0.06665] Val F1 Score : [0.97894]\n",
      " present score: 0.9789442121300529\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Best F1 score from now: 0.981942782464405\n",
      "Epoch 4/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 4 loss: 0.0193: 100%|████████████████████████████████████████████████████████████████████████| 74/74 [00:56<00:00,  1.31it/s]\n",
      "epoch 4 loss: 0.0750: 100%|████████████████████████████████████████████████████████████████████████| 19/19 [00:11<00:00,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4], Train Loss : [0.03107] Val Loss : [0.07299] Val F1 Score : [0.97729]\n",
      " present score: 0.9772897717439378\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Best F1 score from now: 0.981942782464405\n",
      "Epoch 5/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 5 loss: 0.0140: 100%|████████████████████████████████████████████████████████████████████████| 74/74 [00:57<00:00,  1.29it/s]\n",
      "epoch 5 loss: 0.0762: 100%|████████████████████████████████████████████████████████████████████████| 19/19 [00:11<00:00,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5], Train Loss : [0.01996] Val Loss : [0.07404] Val F1 Score : [0.98384]\n",
      " present score: 0.9838435422049939\n",
      "Epoch 6/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 6 loss: 0.0122: 100%|████████████████████████████████████████████████████████████████████████| 74/74 [00:55<00:00,  1.34it/s]\n",
      "epoch 6 loss: 0.0622: 100%|████████████████████████████████████████████████████████████████████████| 19/19 [00:11<00:00,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6], Train Loss : [0.01310] Val Loss : [0.06072] Val F1 Score : [0.98576]\n",
      " present score: 0.985762129917852\n",
      "Epoch 7/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 7 loss: 0.0089: 100%|████████████████████████████████████████████████████████████████████████| 74/74 [00:55<00:00,  1.32it/s]\n",
      "epoch 7 loss: 0.0704: 100%|████████████████████████████████████████████████████████████████████████| 19/19 [00:11<00:00,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7], Train Loss : [0.01275] Val Loss : [0.06849] Val F1 Score : [0.98388]\n",
      " present score: 0.9838837983086697\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Best F1 score from now: 0.985762129917852\n",
      "Epoch 8/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 8 loss: 0.0209: 100%|████████████████████████████████████████████████████████████████████████| 74/74 [00:55<00:00,  1.34it/s]\n",
      "epoch 8 loss: 0.0690: 100%|████████████████████████████████████████████████████████████████████████| 19/19 [00:11<00:00,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8], Train Loss : [0.01245] Val Loss : [0.06706] Val F1 Score : [0.98484]\n",
      " present score: 0.9848411919110238\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Best F1 score from now: 0.985762129917852\n",
      "Epoch 9/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 9 loss: 0.0060: 100%|████████████████████████████████████████████████████████████████████████| 74/74 [00:56<00:00,  1.31it/s]\n",
      "epoch 9 loss: 0.0650: 100%|████████████████████████████████████████████████████████████████████████| 19/19 [00:11<00:00,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9], Train Loss : [0.00830] Val Loss : [0.06323] Val F1 Score : [0.98670]\n",
      " present score: 0.9867030174355014\n",
      "Epoch 10/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 10 loss: 0.0051: 100%|███████████████████████████████████████████████████████████████████████| 74/74 [00:55<00:00,  1.33it/s]\n",
      "epoch 10 loss: 0.0647: 100%|███████████████████████████████████████████████████████████████████████| 19/19 [00:11<00:00,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10], Train Loss : [0.00797] Val Loss : [0.06367] Val F1 Score : [0.98571]\n",
      " present score: 0.9857082350093787\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Best F1 score from now: 0.9867030174355014\n",
      "Epoch 11/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 11 loss: 0.0030: 100%|███████████████████████████████████████████████████████████████████████| 74/74 [00:55<00:00,  1.33it/s]\n",
      "epoch 11 loss: 0.0585: 100%|███████████████████████████████████████████████████████████████████████| 19/19 [00:12<00:00,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11], Train Loss : [0.00495] Val Loss : [0.05699] Val F1 Score : [0.98670]\n",
      " present score: 0.9867030174355014\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Best F1 score from now: 0.9867030174355014\n",
      "Epoch 12/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 12 loss: 0.0014: 100%|███████████████████████████████████████████████████████████████████████| 74/74 [00:54<00:00,  1.37it/s]\n",
      "epoch 12 loss: 0.0638: 100%|███████████████████████████████████████████████████████████████████████| 19/19 [00:11<00:00,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12], Train Loss : [0.00261] Val Loss : [0.06271] Val F1 Score : [0.98571]\n",
      " present score: 0.9857082350093787\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Best F1 score from now: 0.9867030174355014\n",
      "Epoch 13/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 13 loss: 0.0028: 100%|███████████████████████████████████████████████████████████████████████| 74/74 [00:54<00:00,  1.35it/s]\n",
      "epoch 13 loss: 0.0612: 100%|███████████████████████████████████████████████████████████████████████| 19/19 [00:11<00:00,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13], Train Loss : [0.00366] Val Loss : [0.05982] Val F1 Score : [0.98573]\n",
      " present score: 0.9857263372645328\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Best F1 score from now: 0.9867030174355014\n",
      "Epoch 14/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 14 loss: 0.0025: 100%|███████████████████████████████████████████████████████████████████████| 74/74 [00:55<00:00,  1.34it/s]\n",
      "epoch 14 loss: 0.0664: 100%|███████████████████████████████████████████████████████████████████████| 19/19 [00:11<00:00,  1.62it/s]\n",
      "/home/hojun/miniconda3/envs/torch/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/hojun/miniconda3/envs/torch/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet152_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet152_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14], Train Loss : [0.00397] Val Loss : [0.06483] Val F1 Score : [0.98480]\n",
      " present score: 0.9848034484977161\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Best F1 score from now: 0.9867030174355014\n",
      "stop called\n",
      "time : 0:17:04\n",
      "fold: 3, Best Epoch : 9/ 15\n",
      "Best Train Marco F1 : 0.99788\n",
      "[[2377    6]\n",
      " [   4 2338]]\n",
      "Best Valid Marco F1 : 0.98670\n",
      "[[778   6]\n",
      " [  8 389]]\n",
      "-----------------------------------------------------------------------\n",
      "Training start with fold: 4 epoch: 200 \n",
      "\n",
      "cls_cnts: 2\n",
      "num_samples:4725\n",
      "Fold: 4\n",
      "Epoch 0/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 0 loss: 0.4130: 100%|████████████████████████████████████████████████████████████████████████| 74/74 [00:55<00:00,  1.34it/s]\n",
      "epoch 0 loss: 0.0903: 100%|████████████████████████████████████████████████████████████████████████| 19/19 [00:11<00:00,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], Train Loss : [0.12559] Val Loss : [0.08878] Val F1 Score : [0.97204]\n",
      " present score: 0.9720420206413463\n",
      "Epoch 1/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 1 loss: 0.1462: 100%|████████████████████████████████████████████████████████████████████████| 74/74 [00:55<00:00,  1.34it/s]\n",
      "epoch 1 loss: 0.0796: 100%|████████████████████████████████████████████████████████████████████████| 19/19 [00:11<00:00,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1], Train Loss : [0.06049] Val Loss : [0.07757] Val F1 Score : [0.97437]\n",
      " present score: 0.9743718338521334\n",
      "Epoch 2/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 2 loss: 0.0564: 100%|████████████████████████████████████████████████████████████████████████| 74/74 [00:55<00:00,  1.32it/s]\n",
      "epoch 2 loss: 0.0720: 100%|████████████████████████████████████████████████████████████████████████| 19/19 [00:11<00:00,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2], Train Loss : [0.05260] Val Loss : [0.07336] Val F1 Score : [0.97306]\n",
      " present score: 0.9730602535275523\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Best F1 score from now: 0.9743718338521334\n",
      "Epoch 3/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 3 loss: 0.0253: 100%|████████████████████████████████████████████████████████████████████████| 74/74 [00:56<00:00,  1.31it/s]\n",
      "epoch 3 loss: 0.0764: 100%|████████████████████████████████████████████████████████████████████████| 19/19 [00:11<00:00,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3], Train Loss : [0.03797] Val Loss : [0.07429] Val F1 Score : [0.98390]\n",
      " present score: 0.9839036963693724\n",
      "Epoch 4/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 4 loss: 0.0375: 100%|████████████████████████████████████████████████████████████████████████| 74/74 [00:54<00:00,  1.35it/s]\n",
      "epoch 4 loss: 0.1288: 100%|████████████████████████████████████████████████████████████████████████| 19/19 [00:11<00:00,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4], Train Loss : [0.03870] Val Loss : [0.12508] Val F1 Score : [0.95547]\n",
      " present score: 0.9554675716440424\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Best F1 score from now: 0.9839036963693724\n",
      "Epoch 5/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 5 loss: 0.0295: 100%|████████████████████████████████████████████████████████████████████████| 74/74 [00:56<00:00,  1.32it/s]\n",
      "epoch 5 loss: 0.0605: 100%|████████████████████████████████████████████████████████████████████████| 19/19 [00:11<00:00,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5], Train Loss : [0.02431] Val Loss : [0.05877] Val F1 Score : [0.98480]\n",
      " present score: 0.984803448497716\n",
      "Epoch 6/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 6 loss: 0.0447: 100%|████████████████████████████████████████████████████████████████████████| 74/74 [00:56<00:00,  1.30it/s]\n",
      "epoch 6 loss: 0.0636: 100%|████████████████████████████████████████████████████████████████████████| 19/19 [00:11<00:00,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6], Train Loss : [0.01456] Val Loss : [0.06175] Val F1 Score : [0.98859]\n",
      " present score: 0.9885882693980095\n",
      "Epoch 7/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 7 loss: 0.0058: 100%|████████████████████████████████████████████████████████████████████████| 74/74 [00:55<00:00,  1.33it/s]\n",
      "epoch 7 loss: 0.0540: 100%|████████████████████████████████████████████████████████████████████████| 19/19 [00:10<00:00,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7], Train Loss : [0.01097] Val Loss : [0.05246] Val F1 Score : [0.98857]\n",
      " present score: 0.9885738427105437\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Best F1 score from now: 0.9885882693980095\n",
      "Epoch 8/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 8 loss: 0.0127: 100%|████████████████████████████████████████████████████████████████████████| 74/74 [00:54<00:00,  1.36it/s]\n",
      "epoch 8 loss: 0.0611: 100%|████████████████████████████████████████████████████████████████████████| 19/19 [00:10<00:00,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8], Train Loss : [0.00950] Val Loss : [0.05935] Val F1 Score : [0.98386]\n",
      " present score: 0.9838637472402323\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Best F1 score from now: 0.9885882693980095\n",
      "Epoch 9/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 9 loss: 0.0031: 100%|████████████████████████████████████████████████████████████████████████| 74/74 [00:55<00:00,  1.34it/s]\n",
      "epoch 9 loss: 0.0563: 100%|████████████████████████████████████████████████████████████████████████| 19/19 [00:11<00:00,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9], Train Loss : [0.00492] Val Loss : [0.05469] Val F1 Score : [0.98761]\n",
      " present score: 0.9876138036747948\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Best F1 score from now: 0.9885882693980095\n",
      "Epoch 10/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 10 loss: 0.0040: 100%|███████████████████████████████████████████████████████████████████████| 74/74 [00:56<00:00,  1.31it/s]\n",
      "epoch 10 loss: 0.0541: 100%|███████████████████████████████████████████████████████████████████████| 19/19 [00:11<00:00,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10], Train Loss : [0.00553] Val Loss : [0.05254] Val F1 Score : [0.98672]\n",
      " present score: 0.9867195933789135\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Best F1 score from now: 0.9885882693980095\n",
      "Epoch 11/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 11 loss: 0.0021: 100%|███████████████████████████████████████████████████████████████████████| 74/74 [00:56<00:00,  1.31it/s]\n",
      "epoch 11 loss: 0.0525: 100%|███████████████████████████████████████████████████████████████████████| 19/19 [00:10<00:00,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11], Train Loss : [0.00337] Val Loss : [0.05099] Val F1 Score : [0.98765]\n",
      " present score: 0.9876450616861718\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Best F1 score from now: 0.9885882693980095\n",
      "stop called\n",
      "time : 0:13:32\n",
      "fold: 4, Best Epoch : 6/ 12\n",
      "Best Train Marco F1 : 0.99640\n",
      "[[2368    7]\n",
      " [  10 2340]]\n",
      "Best Valid Marco F1 : 0.98859\n",
      "[[780   3]\n",
      " [  9 389]]\n",
      "-----------------------------------------------------------------------\n",
      "Best Fold F1 score: 0.9914358023587198 Top fold : 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    seed_everything(CFG['seed'])\n",
    "    \n",
    "    # WANDB TRACKER INIT\n",
    "    wandb.init(project=project_name, entity=user)\n",
    "    wandb.config.update(CFG)\n",
    "    wandb.run.name = run_name\n",
    "    wandb.define_metric(\"Train Accuracy\", step_metric=\"epoch\")\n",
    "    wandb.define_metric(\"Valid Accuracy\", step_metric=\"epoch\")\n",
    "    wandb.define_metric(\"Train Loss\", step_metric=\"epoch\")\n",
    "    wandb.define_metric(\"Valid Loss\", step_metric=\"epoch\")\n",
    "    wandb.define_metric(\"Train Macro F1 Score\", step_metric=\"epoch\")\n",
    "    wandb.define_metric(\"Valid Macro F1 Score\", step_metric=\"epoch\")\n",
    "    wandb.define_metric(\"Train-Valid Accuracy\", step_metric=\"epoch\")\n",
    "    \n",
    "    model_dir = CFG['model_path'] + '/{}'.format(run_name)\n",
    "    train_dir = train.dir.values\n",
    "    best_fold = 0\n",
    "    best_f1 =0.0\n",
    "    print('Model: {}'.format(CFG['model']))\n",
    "    # MAKE MODEL DIR\n",
    "    if not os.path.isdir(model_dir):\n",
    "        os.makedirs(model_dir)\n",
    "    \n",
    "    # STRATIFIED K-FOLD DEFINITION\n",
    "    folds = StratifiedKFold(n_splits=CFG['fold_num'], shuffle=True, random_state=CFG['seed']).split(np.arange(train.shape[0]), train.label.values)\n",
    "    \n",
    "    # TEST PROCESS FOLD BREAK\n",
    "    for fold, (trn_idx, val_idx) in enumerate(folds):\n",
    "        print(f'Training start with fold: {fold} epoch: {CFG[\"epochs\"]} \\n')\n",
    "\n",
    "        # EARLY STOPPING DEFINITION\n",
    "        early_stopping = EarlyStopping(patience=CFG[\"patience\"], verbose=True)\n",
    "\n",
    "        # DATALOADER DEFINITION\n",
    "        train_loader, val_loader = prepare_dataloader(train, trn_idx, val_idx, data_root=train_dir)\n",
    "\n",
    "        # MODEL & DEVICE DEFINITION \n",
    "        device = torch.device(CFG['device'])\n",
    "        model =Teacher(CFG['model'], train.label.nunique(), pretrained=True)\n",
    "        \n",
    "        # MODEL FREEZING\n",
    "        #model.freezing(freeze = CFG['freezing'], trainable_layer = CFG['trainable_layer'])\n",
    "        if CFG['freezing'] ==True:\n",
    "            for name, param in model.named_parameters():\n",
    "                if param.requires_grad == True:\n",
    "                    print(f\"{name}: {param.requires_grad}\")\n",
    "\n",
    "        model.to(device)\n",
    "        # MODEL DATA PARALLEL\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            model = nn.DataParallel(model)\n",
    "\n",
    "        scaler = torch.cuda.amp.GradScaler()   \n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=CFG['lr'])\n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, gamma=0.5, step_size=5)\n",
    "\n",
    "        # CRITERION (LOSS FUNCTION)\n",
    "        loss_tr = nn.CrossEntropyLoss().to(device) #MyCrossEntropyLoss().to(device)\n",
    "        loss_fn = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "        wandb.watch(model, loss_tr, log='all')\n",
    "        train_acc_list = []\n",
    "        train_matrix_list = []\n",
    "        train_f1_list = []\n",
    "        valid_acc_list = []\n",
    "        valid_matrix_list = []\n",
    "        valid_f1_list = []\n",
    "        \n",
    "\n",
    "        start = time.time()\n",
    "        print(f'Fold: {fold}')\n",
    "        for epoch in range(CFG['epochs']):\n",
    "            print('Epoch {}/{}'.format(epoch, CFG['epochs'] - 1))\n",
    "\n",
    "            # TRAINIG\n",
    "            train_preds_all, train_acc, train_loss, train_matrix, train_f1 = train_one_epoch(epoch, model, loss_tr,\n",
    "                                                                        optimizer, train_loader, device, scheduler=scheduler)\n",
    "            wandb.log({'Train Accuracy':train_acc, 'Train Loss' : train_loss, 'Train F1': train_f1, 'epoch' : epoch})\n",
    "\n",
    "            # VALIDATION\n",
    "            with torch.no_grad():\n",
    "                valid_preds_all, valid_acc, valid_loss, valid_matrix, valid_f1= valid_one_epoch(epoch, model, loss_fn,\n",
    "                                                                        val_loader, device, scheduler=None)\n",
    "                wandb.log({'Valid Accuracy':valid_acc, 'Valid Loss' : valid_loss, 'Valid F1': valid_f1 ,'epoch' : epoch})\n",
    "            print(f'Epoch [{epoch}], Train Loss : [{train_loss :.5f}] Val Loss : [{valid_loss :.5f}] Val F1 Score : [{valid_f1:.5f}]')\n",
    "            \n",
    "            # SAVE ALL RESULTS\n",
    "            train_acc_list.append(train_acc)\n",
    "            train_matrix_list.append(train_matrix)\n",
    "            train_f1_list.append(train_f1)\n",
    "\n",
    "            valid_acc_list.append(valid_acc)\n",
    "            valid_matrix_list.append(valid_matrix)\n",
    "            valid_f1_list.append(valid_f1)\n",
    "\n",
    "            # MODEL SAVE (THE BEST MODEL OF ALL OF FOLD PROCESS)\n",
    "            if valid_f1 > best_f1:\n",
    "                best_f1 = valid_f1\n",
    "                best_epoch = epoch\n",
    "                # SAVE WITH DATAPARARELLEL WRAPPER\n",
    "                #torch.save(model.state_dict(), (model_dir+'/{}.pth').format(CFG['model']))\n",
    "                # SAVE WITHOUT DATAPARARELLEL WRAPPER\n",
    "                torch.save(model.module.state_dict(), (model_dir+'/{}.pth').format(CFG['model']))\n",
    "\n",
    "            # EARLY STOPPING\n",
    "            stop = early_stopping(valid_f1)\n",
    "            if stop:\n",
    "                print(\"stop called\")   \n",
    "                break\n",
    "\n",
    "        end = time.time() - start\n",
    "        time_ = str(datetime.timedelta(seconds=end)).split(\".\")[0]\n",
    "        print(\"time :\", time_)\n",
    "\n",
    "        # PRINT BEST F1 SCORE MODEL OF FOLD\n",
    "        best_index = valid_f1_list.index(max(valid_f1_list))\n",
    "        print(f'fold: {fold}, Best Epoch : {best_index}/ {len(valid_f1_list)}')\n",
    "        print(f'Best Train Marco F1 : {train_f1_list[best_index]:.5f}')\n",
    "        print(train_matrix_list[best_index])\n",
    "        print(f'Best Valid Marco F1 : {valid_f1_list[best_index]:.5f}')\n",
    "        print(valid_matrix_list[best_index])\n",
    "        print('-----------------------------------------------------------------------')\n",
    "\n",
    "        # K-FOLD END\n",
    "        if valid_f1_list[best_index] > best_fold:\n",
    "            best_fold = valid_f1_list[best_index]\n",
    "            top_fold = fold\n",
    "    print(f'Best Fold F1 score: {best_fold} Top fold : {top_fold}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "93dba2e1-92a8-4e81-89e8-17005fb81bbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>dir</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0282.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/test/10Kwalk</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0466.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/test/10Kwalk</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0190.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/test/10Kwalk</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0234.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/test/10Kwalk</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0392.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/test/10Kwalk</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13688</th>\n",
       "      <td>0381.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/test/wrap</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13689</th>\n",
       "      <td>0236.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/test/wrap</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13690</th>\n",
       "      <td>0384.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/test/wrap</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13691</th>\n",
       "      <td>0074.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/test/wrap</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13692</th>\n",
       "      <td>0011.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/test/wrap</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13693 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       image_id                                         dir  label\n",
       "0      0282.jpg  ../Data/carbon_reduction_data/test/10Kwalk      0\n",
       "1      0466.jpg  ../Data/carbon_reduction_data/test/10Kwalk      0\n",
       "2      0190.jpg  ../Data/carbon_reduction_data/test/10Kwalk      0\n",
       "3      0234.jpg  ../Data/carbon_reduction_data/test/10Kwalk      0\n",
       "4      0392.jpg  ../Data/carbon_reduction_data/test/10Kwalk      0\n",
       "...         ...                                         ...    ...\n",
       "13688  0381.jpg     ../Data/carbon_reduction_data/test/wrap     18\n",
       "13689  0236.jpg     ../Data/carbon_reduction_data/test/wrap     18\n",
       "13690  0384.jpg     ../Data/carbon_reduction_data/test/wrap     18\n",
       "13691  0074.jpg     ../Data/carbon_reduction_data/test/wrap     18\n",
       "13692  0011.jpg     ../Data/carbon_reduction_data/test/wrap     18\n",
       "\n",
       "[13693 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "681ed966-953b-4533-a9b5-1438c1bb27de",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################## inference #############################\n",
    "def inference(model, data_loader, device):\n",
    "    model.eval()\n",
    "    image_preds_all = []\n",
    "    \n",
    "    pbar = tqdm(enumerate(data_loader), total=len(data_loader))\n",
    "    for step, (imgs) in pbar:\n",
    "        imgs = imgs.to(device).float()\n",
    "\n",
    "        image_preds = model(imgs)   #output = model(input)\n",
    "        image_preds_all += [torch.softmax(image_preds, 1).detach().cpu().numpy()]\n",
    "    \n",
    "    image_preds_all = np.concatenate(image_preds_all, axis=0)\n",
    "    return image_preds_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1f910c08-4857-43b4-b499-b5a7d799e5b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hojun/miniconda3/envs/torch/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/hojun/miniconda3/envs/torch/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet152_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet152_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████| 31/31 [00:18<00:00,  1.68it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>dir</th>\n",
       "      <th>label</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0720.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/bin/test/box</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0282.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/bin/test/box</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1028.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/bin/test/box</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0540.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/bin/test/box</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0466.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/bin/test/box</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1965</th>\n",
       "      <td>0384.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/bin/test/untapedBox</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1966</th>\n",
       "      <td>0074.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/bin/test/untapedBox</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1967</th>\n",
       "      <td>0515.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/bin/test/untapedBox</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1968</th>\n",
       "      <td>0011.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/bin/test/untapedBox</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1969</th>\n",
       "      <td>0611.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/bin/test/untapedBox</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1970 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      image_id                                                dir  label  pred\n",
       "0     0720.jpg         ../Data/carbon_reduction_data/bin/test/box      0     0\n",
       "1     0282.jpg         ../Data/carbon_reduction_data/bin/test/box      0     0\n",
       "2     1028.jpg         ../Data/carbon_reduction_data/bin/test/box      0     0\n",
       "3     0540.jpg         ../Data/carbon_reduction_data/bin/test/box      0     0\n",
       "4     0466.jpg         ../Data/carbon_reduction_data/bin/test/box      0     0\n",
       "...        ...                                                ...    ...   ...\n",
       "1965  0384.jpg  ../Data/carbon_reduction_data/bin/test/untapedBox      1     1\n",
       "1966  0074.jpg  ../Data/carbon_reduction_data/bin/test/untapedBox      1     1\n",
       "1967  0515.jpg  ../Data/carbon_reduction_data/bin/test/untapedBox      1     1\n",
       "1968  0011.jpg  ../Data/carbon_reduction_data/bin/test/untapedBox      1     1\n",
       "1969  0611.jpg  ../Data/carbon_reduction_data/bin/test/untapedBox      1     1\n",
       "\n",
       "[1970 rows x 4 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RUN INFERENCE\n",
    "model = Teacher(CFG['model'], test.label.nunique(), pretrained=True)\n",
    "load_model = CFG['model_path'] + '/KD_resnet152_box_202305191256/' + CFG['model'] + '.pth'\n",
    "test_dir = test.dir.values\n",
    "\n",
    "tst_ds = CustomDataset(test, test_dir, transform=transform_test, output_label=False)\n",
    "tst_loader = torch.utils.data.DataLoader(\n",
    "    tst_ds, \n",
    "    batch_size=CFG['train_bs'],\n",
    "    num_workers=CFG['num_workers'],\n",
    "    shuffle=False,\n",
    "    pin_memory=True\n",
    ")\n",
    "device = torch.device(CFG['device'])\n",
    "\n",
    "# INFERENCE VIA MULTI-GPU\n",
    "# if torch.cuda.device_count() > 1:\n",
    "#         model = nn.DataParallel(model)\n",
    "model.to(device)\n",
    "\n",
    "# RUN INFERENCE\n",
    "predictions = []\n",
    "model.load_state_dict(torch.load(load_model))\n",
    "with torch.no_grad():\n",
    "    predictions += [inference(model, tst_loader, device)]\n",
    "\n",
    "\n",
    "predictions = np.mean(predictions, axis=0) \n",
    "test['pred'] = np.argmax(predictions, axis=1)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6dc9d547-6d2c-4d13-95c6-f9baf6e0f5da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>dir</th>\n",
       "      <th>label</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0720.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/bin/test/box</td>\n",
       "      <td>box</td>\n",
       "      <td>box</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0282.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/bin/test/box</td>\n",
       "      <td>box</td>\n",
       "      <td>box</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1028.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/bin/test/box</td>\n",
       "      <td>box</td>\n",
       "      <td>box</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0540.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/bin/test/box</td>\n",
       "      <td>box</td>\n",
       "      <td>box</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0466.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/bin/test/box</td>\n",
       "      <td>box</td>\n",
       "      <td>box</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1965</th>\n",
       "      <td>0384.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/bin/test/untapedBox</td>\n",
       "      <td>untapedBox</td>\n",
       "      <td>untapedBox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1966</th>\n",
       "      <td>0074.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/bin/test/untapedBox</td>\n",
       "      <td>untapedBox</td>\n",
       "      <td>untapedBox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1967</th>\n",
       "      <td>0515.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/bin/test/untapedBox</td>\n",
       "      <td>untapedBox</td>\n",
       "      <td>untapedBox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1968</th>\n",
       "      <td>0011.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/bin/test/untapedBox</td>\n",
       "      <td>untapedBox</td>\n",
       "      <td>untapedBox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1969</th>\n",
       "      <td>0611.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/bin/test/untapedBox</td>\n",
       "      <td>untapedBox</td>\n",
       "      <td>untapedBox</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1970 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      image_id                                                dir       label  \\\n",
       "0     0720.jpg         ../Data/carbon_reduction_data/bin/test/box         box   \n",
       "1     0282.jpg         ../Data/carbon_reduction_data/bin/test/box         box   \n",
       "2     1028.jpg         ../Data/carbon_reduction_data/bin/test/box         box   \n",
       "3     0540.jpg         ../Data/carbon_reduction_data/bin/test/box         box   \n",
       "4     0466.jpg         ../Data/carbon_reduction_data/bin/test/box         box   \n",
       "...        ...                                                ...         ...   \n",
       "1965  0384.jpg  ../Data/carbon_reduction_data/bin/test/untapedBox  untapedBox   \n",
       "1966  0074.jpg  ../Data/carbon_reduction_data/bin/test/untapedBox  untapedBox   \n",
       "1967  0515.jpg  ../Data/carbon_reduction_data/bin/test/untapedBox  untapedBox   \n",
       "1968  0011.jpg  ../Data/carbon_reduction_data/bin/test/untapedBox  untapedBox   \n",
       "1969  0611.jpg  ../Data/carbon_reduction_data/bin/test/untapedBox  untapedBox   \n",
       "\n",
       "            pred  \n",
       "0            box  \n",
       "1            box  \n",
       "2            box  \n",
       "3            box  \n",
       "4            box  \n",
       "...          ...  \n",
       "1965  untapedBox  \n",
       "1966  untapedBox  \n",
       "1967  untapedBox  \n",
       "1968  untapedBox  \n",
       "1969  untapedBox  \n",
       "\n",
       "[1970 rows x 4 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['label'] = le.inverse_transform(test['label'].values)\n",
    "test['pred'] = le.inverse_transform(test['pred'].values)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "da647547-7a7b-4690-94df-bb42ca426f3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9863\n",
      "f1_score: 0.9846\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1500x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "test_acc = np.sum(test.label == test.pred) / len(test)\n",
    "test_matrix = confusion_matrix(test['label'], test['pred'])\n",
    "epoch_f1 = f1_score(test['label'], test['pred'], average='macro')\n",
    "print(f'accuracy: {test_acc:.4f}')\n",
    "print(f'f1_score: {epoch_f1:.4f}')\n",
    "\n",
    "test_matrix = confusion_matrix(test['label'], test['pred'], normalize='true')\n",
    "#test_matrix = confusion_matrix(test['label'], test['pred'])\n",
    "\n",
    "plt.figure(figsize = (15,10))\n",
    "sns.heatmap(test_matrix, \n",
    "            annot=True, \n",
    "            xticklabels = sorted(set(test['label'])), \n",
    "            yticklabels = sorted(set(test['label'])),\n",
    "            )\n",
    "plt.title('Normalized Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "#print(f'confusion_matrix \\n-------------------------\\n {test_matrix}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ab89fde5-9498-4a99-8bb8-4af301e4a6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv('test_result/incep_res_0403.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d8cbfb49-98dd-4d2f-a778-21764270d9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import jsonlines\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3d9a4c94-8eb0-49f1-9e94-d412533a498b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bottle            1229\n",
       "dishes            1163\n",
       "stairs             806\n",
       "else               597\n",
       "plug               593\n",
       "battery            501\n",
       "transportation     458\n",
       "handkerchief       443\n",
       "10Kwalk            411\n",
       "pet                410\n",
       "shopping bag       409\n",
       "box                382\n",
       "paper              374\n",
       "milk               371\n",
       "trash picking      325\n",
       "receipt            288\n",
       "Name: pred, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['pred'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fe7bc385-c882-4830-81f9-e6494fab928d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1475945/30508609.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  label.sort_values(by=['image_id'],ascending=True, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>dir</th>\n",
       "      <th>label</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10Kwalk_1047.jpg</td>\n",
       "      <td>../Data/carbon_data/10Kwalk</td>\n",
       "      <td>10Kwalk</td>\n",
       "      <td>else</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10Kwalk_1174.jpg</td>\n",
       "      <td>../Data/carbon_data/10Kwalk</td>\n",
       "      <td>10Kwalk</td>\n",
       "      <td>else</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16583193231991658319380893.jpg</td>\n",
       "      <td>../Data/carbon_data/else/instance_spoon</td>\n",
       "      <td>else</td>\n",
       "      <td>else</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16583311864571658331260534.jpg</td>\n",
       "      <td>../Data/carbon_data/else/instance_spoon</td>\n",
       "      <td>else</td>\n",
       "      <td>else</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20220722_125118_HDR1658461897787.jpg</td>\n",
       "      <td>../Data/carbon_data/else/instance_spoon</td>\n",
       "      <td>else</td>\n",
       "      <td>else</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>wrap_990.jpg</td>\n",
       "      <td>../Data/carbon_data/dishes/wrap</td>\n",
       "      <td>dishes</td>\n",
       "      <td>else</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>wrap_995.jpg</td>\n",
       "      <td>../Data/carbon_data/dishes/wrap</td>\n",
       "      <td>dishes</td>\n",
       "      <td>else</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>양치컵 사용_063.jpg</td>\n",
       "      <td>../Data/carbon_data/bottle/toothcup/toothcup_852</td>\n",
       "      <td>bottle</td>\n",
       "      <td>else</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>양치컵 사용_140.jpg</td>\n",
       "      <td>../Data/carbon_data/bottle/toothcup/toothcup_852</td>\n",
       "      <td>bottle</td>\n",
       "      <td>else</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>양치컵 사용_175.jpg</td>\n",
       "      <td>../Data/carbon_data/bottle/toothcup/toothcup_852</td>\n",
       "      <td>bottle</td>\n",
       "      <td>else</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>597 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 image_id  \\\n",
       "0                        10Kwalk_1047.jpg   \n",
       "1                        10Kwalk_1174.jpg   \n",
       "2          16583193231991658319380893.jpg   \n",
       "3          16583311864571658331260534.jpg   \n",
       "4    20220722_125118_HDR1658461897787.jpg   \n",
       "..                                    ...   \n",
       "592                          wrap_990.jpg   \n",
       "593                          wrap_995.jpg   \n",
       "594                        양치컵 사용_063.jpg   \n",
       "595                        양치컵 사용_140.jpg   \n",
       "596                        양치컵 사용_175.jpg   \n",
       "\n",
       "                                                  dir    label  pred  \n",
       "0                         ../Data/carbon_data/10Kwalk  10Kwalk  else  \n",
       "1                         ../Data/carbon_data/10Kwalk  10Kwalk  else  \n",
       "2             ../Data/carbon_data/else/instance_spoon     else  else  \n",
       "3             ../Data/carbon_data/else/instance_spoon     else  else  \n",
       "4             ../Data/carbon_data/else/instance_spoon     else  else  \n",
       "..                                                ...      ...   ...  \n",
       "592                   ../Data/carbon_data/dishes/wrap   dishes  else  \n",
       "593                   ../Data/carbon_data/dishes/wrap   dishes  else  \n",
       "594  ../Data/carbon_data/bottle/toothcup/toothcup_852   bottle  else  \n",
       "595  ../Data/carbon_data/bottle/toothcup/toothcup_852   bottle  else  \n",
       "596  ../Data/carbon_data/bottle/toothcup/toothcup_852   bottle  else  \n",
       "\n",
       "[597 rows x 4 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_list = []\n",
    "label = test[test.pred == 'else']\n",
    "\n",
    "label.sort_values(by=['image_id'],ascending=True, inplace=True)\n",
    "label.reset_index(inplace=True, drop=True)\n",
    "tmp = label['image_id'].value_counts().index.sort_values()\n",
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ab3b8b-043d-4d3b-b14f-13564a985766",
   "metadata": {},
   "outputs": [],
   "source": [
    "## show img status\n",
    "\n",
    "back = 0\n",
    "plt.figure(figsize=(16,500))\n",
    "for i in range(len(label[200:400])):\n",
    "    plt.subplot(100,4,i+1)\n",
    "    if i % 4 == 0:\n",
    "        plt.title(f\"{(i+1+back)/4}\")\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "        \n",
    "    path = label['dir'][i] + '/' + label['image_id'][i]\n",
    "    try:\n",
    "    # im_bgr = cv2.imread(path)\n",
    "    # im_rgb = im_bgr[:, :, ::-1]\n",
    "        temp = Image.open(path).convert(\"RGB\")\n",
    "        image = np.array(temp).copy()\n",
    "        temp.close()\n",
    "\n",
    "        plt.imshow(image, cmap=plt.cm.binary)\n",
    "        plt.xlabel(label['image_id'][i], loc='left', fontsize=10)\n",
    "    except:\n",
    "        plt.xlabel(path, loc='left', fontsize=10)\n",
    "        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4949b731-608b-43b9-93fa-c4ef70c28a09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-gpu",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
