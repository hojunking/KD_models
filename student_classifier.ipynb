{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32c4ea0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, magic, shutil\n",
    "from glob import glob\n",
    "import time, datetime\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import joblib\n",
    "import datetime as dt\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torch, gc\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torch.utils.data.sampler import SequentialSampler, RandomSampler\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "\n",
    "#from skimage import io\n",
    "import sklearn\n",
    "from sklearn.model_selection import GroupKFold, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, log_loss, f1_score, confusion_matrix, classification_report\n",
    "from sklearn import metrics, preprocessing\n",
    "from scipy.ndimage import zoom\n",
    "\n",
    "import timm\n",
    "import albumentations as A\n",
    "import albumentations.pytorch\n",
    "import wandb\n",
    "from catalyst.data.sampler import BalanceClassSampler\n",
    "from torch.utils.data.distributed import DistributedSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29d0796-1f1d-40df-ad4a-21f57ed7fe35",
   "metadata": {},
   "source": [
    "#### Hyper Param Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57c0283c",
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'fold_num': 5,\n",
    "    'seed': 42,\n",
    "    't_model': 'resnet152',\n",
    "    'load_model': 'resnet152_pet_20230430175553', # LOAD TEACHER MODEL\n",
    "    's_model': 'mobilenet_v3_large',\n",
    "    'img_size': 260,\n",
    "    'alpha': 0.5,\n",
    "    'epochs': 200,\n",
    "    'train_bs':64,\n",
    "    'valid_bs':64,\n",
    "    'lr': 1e-4, ## learning rate\n",
    "    'num_workers': 8,\n",
    "    'verbose_step': 1,\n",
    "    'patience' : 5,\n",
    "    'label_encoder':True,\n",
    "    'device': 'cuda:0',\n",
    "    'freezing': False,\n",
    "    'trainable_layer': 6,\n",
    "    'model_path': './models'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9dd7e7d-b42f-44de-9376-cbad0bc027bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7066a8a1-7060-4b6d-bf0c-d4164820a414",
   "metadata": {},
   "source": [
    "#### wandb init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "127461e4-c16d-47fd-b983-556c12ad0daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "category = 'pet'\n",
    "time_now = dt.datetime.now()\n",
    "run_id = time_now.strftime(\"%Y%m%d%H%M\")\n",
    "project_name = 'KD_'+ CFG['t_model'] +'_' + CFG['s_model'] + '_' + category\n",
    "user = 'hojunking'\n",
    "run_name = project_name + '_' + run_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5c538155-d55f-4321-bf7c-171d356ebceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: pet 2404\n",
      "label: labeled 4529\n",
      "Train_Images:  5546\n",
      "Train_Images_labels: 5546\n",
      "Test_Images:  1387\n",
      "Test_Images_labels: 1387\n",
      "All data 6933\n"
     ]
    }
   ],
   "source": [
    "# Data split\n",
    "main_path = '../Data/carbon_data/'\n",
    "label_list = [\"pet\",\"labeled\"]\n",
    "\n",
    "total_train_img_paths = []\n",
    "total_train_img_labels = []\n",
    "total_test_img_paths = []\n",
    "total_test_img_labels = []\n",
    "\n",
    "for label in label_list: ## 각 레이블 돌기\n",
    "    print(f'label: {label}',end=' ')\n",
    "    img_paths = [] \n",
    "    img_labels = []\n",
    "\n",
    "    # default ratio\n",
    "    train_ratio = 1500\n",
    "    test_ratio = 500\n",
    "\n",
    "    dir_path = main_path + label ## 레이블 폴더 경로\n",
    "    count = 0\n",
    "    for folder, subfolders, filenames in os.walk(dir_path): ## 폴더 내 모든 파일 탐색\n",
    "    \n",
    "        for img in filenames: ## 각 파일 경로, 레이블 저장\n",
    "            count +=1\n",
    "            if count > train_ratio + test_ratio + 10000:\n",
    "                break\n",
    "            \n",
    "            img_paths.append(folder+'/'+img)\n",
    "            img_labels.append(label)\n",
    "        \n",
    "    print(len(img_paths))\n",
    "\n",
    "    if label == 'labeled': ##  데이터 비율 설정하기 \n",
    "        train_ratio = 3623\n",
    "        test_ratio = 906\n",
    "    elif label == 'pet': ##  데이터 비율 설정하기 \n",
    "        train_ratio = 1923\n",
    "        test_ratio = 481\n",
    "        \n",
    "    total_train_img_paths.extend(img_paths[:train_ratio])\n",
    "    total_train_img_labels.extend(img_labels[:train_ratio])\n",
    "\n",
    "    total_test_img_paths.extend(img_paths[-test_ratio:])\n",
    "    total_test_img_labels.extend(img_labels[-test_ratio:])\n",
    "\n",
    "print('Train_Images: ',len(total_train_img_paths))\n",
    "print(\"Train_Images_labels:\", len(total_train_img_labels))\n",
    "print('Test_Images: ',len(total_test_img_paths))\n",
    "print(\"Test_Images_labels:\", len(total_test_img_labels))\n",
    "print(\"All data\",len(total_train_img_paths) + len(total_test_img_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2716dd8b-84db-4707-80e2-19b29eae9c23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>dir</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pet_1214.jpg</td>\n",
       "      <td>../Data/carbon_data/pet</td>\n",
       "      <td>pet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pet_663.jpg</td>\n",
       "      <td>../Data/carbon_data/pet</td>\n",
       "      <td>pet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pet_2262.jpg</td>\n",
       "      <td>../Data/carbon_data/pet</td>\n",
       "      <td>pet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pet_780.jpg</td>\n",
       "      <td>../Data/carbon_data/pet</td>\n",
       "      <td>pet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pet_176.jpg</td>\n",
       "      <td>../Data/carbon_data/pet</td>\n",
       "      <td>pet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5541</th>\n",
       "      <td>pte (872).jpg</td>\n",
       "      <td>../Data/carbon_data/labeled</td>\n",
       "      <td>labeled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5542</th>\n",
       "      <td>pet36594.jpg</td>\n",
       "      <td>../Data/carbon_data/labeled</td>\n",
       "      <td>labeled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5543</th>\n",
       "      <td>2634_jpg.rf.c07e985b8263d33898e6a2dcdec88b08.jpg</td>\n",
       "      <td>../Data/carbon_data/labeled</td>\n",
       "      <td>labeled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5544</th>\n",
       "      <td>2969_jpg.rf.5f6f9269090b49fdab83153569e91038.jpg</td>\n",
       "      <td>../Data/carbon_data/labeled</td>\n",
       "      <td>labeled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5545</th>\n",
       "      <td>pet8979.jpg</td>\n",
       "      <td>../Data/carbon_data/labeled</td>\n",
       "      <td>labeled</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5546 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              image_id  \\\n",
       "0                                         pet_1214.jpg   \n",
       "1                                          pet_663.jpg   \n",
       "2                                         pet_2262.jpg   \n",
       "3                                          pet_780.jpg   \n",
       "4                                          pet_176.jpg   \n",
       "...                                                ...   \n",
       "5541                                     pte (872).jpg   \n",
       "5542                                      pet36594.jpg   \n",
       "5543  2634_jpg.rf.c07e985b8263d33898e6a2dcdec88b08.jpg   \n",
       "5544  2969_jpg.rf.5f6f9269090b49fdab83153569e91038.jpg   \n",
       "5545                                       pet8979.jpg   \n",
       "\n",
       "                              dir    label  \n",
       "0         ../Data/carbon_data/pet      pet  \n",
       "1         ../Data/carbon_data/pet      pet  \n",
       "2         ../Data/carbon_data/pet      pet  \n",
       "3         ../Data/carbon_data/pet      pet  \n",
       "4         ../Data/carbon_data/pet      pet  \n",
       "...                           ...      ...  \n",
       "5541  ../Data/carbon_data/labeled  labeled  \n",
       "5542  ../Data/carbon_data/labeled  labeled  \n",
       "5543  ../Data/carbon_data/labeled  labeled  \n",
       "5544  ../Data/carbon_data/labeled  labeled  \n",
       "5545  ../Data/carbon_data/labeled  labeled  \n",
       "\n",
       "[5546 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Pandas 데이터프레임 만들기\n",
    "trn_df = pd.DataFrame(total_train_img_paths, columns=['image_id'])\n",
    "trn_df['dir'] = trn_df['image_id'].apply(lambda x: os.path.dirname(x))\n",
    "trn_df['image_id'] = trn_df['image_id'].apply(lambda x: os.path.basename(x))\n",
    "trn_df['label'] = total_train_img_labels\n",
    "train = trn_df\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "03c67d39-7933-4f98-b998-54a6036ff4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Encoding\n",
    "le = preprocessing.LabelEncoder()\n",
    "train['label'] = le.fit_transform(train['label'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a3a8ac38-0b0f-4db4-80d2-6504916b7723",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3623\n",
       "1    1923\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8d3fa5ff-2c3f-4b28-af67-e7ee2533d021",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_encoding_classes():\n",
    "    # define certain classes to transform differently\n",
    "    capture_image_classes = ['10Kwalk', 'battery','receipt']\n",
    "    return le.transform(capture_image_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6c454bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d97a3c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img(path, sub_path=None):\n",
    "    try:\n",
    "        im_bgr = cv2.imread(path)\n",
    "        im_rgb = im_bgr[:, :, ::-1]\n",
    "        past_path = path\n",
    "    except: ## 이미지 에러 발생 시 백지로 대체\n",
    "        im_bgr = cv2.imread('../Data/carbon_reduction/temp_img.jpg')\n",
    "        im_rgb = im_bgr[:, :, ::-1]\n",
    "    return im_rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "884eb987-4341-4fe7-8094-6e61cb051af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = A.Compose([\n",
    "    A.OneOf([\n",
    "        A.Compose([\n",
    "            A.RandomResizedCrop(p=1, height=CFG['img_size'] ,width=CFG['img_size'], scale=(0.65, 0.75),ratio=(0.90, 1.10)),\n",
    "        ], p=0.7),\n",
    "        A.Compose([\n",
    "            A.Resize(p=1, height = CFG['img_size'], width = CFG['img_size']),\n",
    "        ], p=0.3),\n",
    "    ], p=1.0),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.SafeRotate(p=0.5, limit=(-20, 20), interpolation=2, border_mode=0, value=(0, 0, 0), mask_value=None),\n",
    "    A.ColorJitter(always_apply=True, p=0.5, contrast=0.2, saturation=0.3, hue=0.2),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, always_apply=True, p=1.0),\n",
    "    A.pytorch.transforms.ToTensorV2()\n",
    "        ])\n",
    "\n",
    "transform_train_cap = A.Compose([\n",
    "    A.OneOf([\n",
    "        A.Compose([\n",
    "            A.RandomResizedCrop(p=1, height=CFG['img_size'] ,width=CFG['img_size'], scale=(0.65, 0.85),ratio=(0.90, 1.10)),\n",
    "        ], p=0.6),\n",
    "        A.Compose([\n",
    "            A.Resize(p=1, height = CFG['img_size'], width = CFG['img_size']),\n",
    "        ], p=0.4),\n",
    "    ], p=1.0),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, always_apply=True, p=1.0),\n",
    "    A.pytorch.transforms.ToTensorV2()\n",
    "])\n",
    "\n",
    "transform_test = A.Compose([\n",
    "    A.Resize(height = CFG['img_size'], width = CFG['img_size']),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, p=1.0),\n",
    "    A.pytorch.transforms.ToTensorV2()\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5f1561be",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColonDataset(Dataset):\n",
    "    def __init__(self, df, data_root, transform=None, transform2=None, output_label=True):\n",
    "        super().__init__()\n",
    "        self.df = df.reset_index(drop=True).copy()\n",
    "        self.transform = transform\n",
    "        self.transform2 = transform2\n",
    "        self.data_root = data_root\n",
    "        self.output_label = output_label\n",
    "        \n",
    "        if output_label == True:\n",
    "            self.labels = self.df['label'].values\n",
    "        \n",
    "        # EXEPTION TRANSFORM FOR CAPTURE IMAGES\n",
    "        if transform2 != None:\n",
    "            self.cap_image = le.fit_transform(['10Kwalk', 'battery','receipt'])\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index: int):\n",
    "        # GET labels\n",
    "        if self.output_label:\n",
    "            target = self.labels[index]\n",
    "        # GET IMAGES\n",
    "        path = \"{}/{}\".format(self.data_root[index], self.df.iloc[index]['image_id'])\n",
    "        img  = get_img(path)\n",
    "        \n",
    "        # TRANSFORM1, TRANSFORM2 PROCESS\n",
    "        if self.transform2 :\n",
    "            if target in self.cap_image and self.transform2:\n",
    "                transformed = self.transform2(image=img)\n",
    "            else:\n",
    "                transformed = self.transform(image=img)\n",
    "        elif self.transform:\n",
    "            transformed = self.transform(image=img)\n",
    "        img = transformed['image']\n",
    "                \n",
    "        if self.output_label == True:\n",
    "            return img, target\n",
    "        else:\n",
    "            return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "73a5b82b-cb1e-4e91-8c70-3a1890bc707c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD PRE-TRAINED MODEL\n",
    "class Student(nn.Module):\n",
    "    def __init__(self, model_arch, num_classes= 2,pretrained=True):\n",
    "        super(Student, self).__init__()\n",
    "        self.backbone = models.mobilenet_v3_large(pretrained=pretrained) ## 모델 선언 여기 models.##(pretrained =pretrained)\n",
    "        self.backbone.classifier[-1] = nn.Linear(self.backbone.classifier[-1].in_features, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "572bd9cd-7650-4d6d-8574-7a4942eef620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD PRE-TRAINED MODEL\n",
    "class Teacher(nn.Module):\n",
    "    def __init__(self, model_arch, num_classes= 2,pretrained=True):\n",
    "        super(Teacher, self).__init__()\n",
    "        self.backbone = models.resnet152(pretrained=pretrained) ## 모델 선언 여기 models.##(pretrained =pretrained)\n",
    "        self.backbone.fc = nn.Linear(self.backbone.fc.in_features, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "240e5531",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataloader(df, trn_idx, val_idx, data_root=train.dir.values):\n",
    "    \n",
    "    train_ = df.loc[trn_idx,:].reset_index(drop=True)\n",
    "    valid_ = df.loc[val_idx,:].reset_index(drop=True)\n",
    "    train_data_root = data_root[trn_idx]\n",
    "    valid_data_root = data_root[val_idx]\n",
    "    \n",
    "        \n",
    "    train_ds = ColonDataset(train_,\n",
    "                            train_data_root,\n",
    "                            transform=transform_train,\n",
    "                            transform2=transform_train_cap,\n",
    "                            output_label=True)\n",
    "    valid_ds = ColonDataset(valid_,\n",
    "                            valid_data_root,\n",
    "                            transform=transform_test,\n",
    "                            output_label=True)\n",
    "    # WEIGHTEDRANDOMSAMPLER\n",
    "    class_counts = train_.label.value_counts(sort=False).to_dict()\n",
    "    num_samples = sum(class_counts.values())\n",
    "    print(f'cls_cnts: {len(class_counts)}\\nnum_samples:{num_samples}')\n",
    "    \n",
    "    # weight 제작, 전체 학습 데이터 수를 해당 클래스의 데이터 수로 나누어 줌\n",
    "    class_weights = {l:round(num_samples/class_counts[l], 2) for l in class_counts.keys()}\n",
    "    t_labels = train_.label.to_list()\n",
    "    \n",
    "    # class 별 weight를 전체 trainset에 대응시켜 sampler에 넣어줌\n",
    "    weights = [class_weights[t_labels[i]] for i in range(int(num_samples))]\n",
    "\n",
    "\n",
    "    # weight 제작, 전체 학습 데이터 수를 해당 클래스의 데이터 수로 나누어 줌\n",
    "    class_weights = {l:round(num_samples/class_counts[l], 2) for l in class_counts.keys()}\n",
    "\n",
    "    # class 별 weight를 전체 trainset에 대응시켜 sampler에 넣어줌\n",
    "    weights = [class_weights[t_labels[i]] for i in range(int(num_samples))] \n",
    "    sampler = torch.utils.data.WeightedRandomSampler(torch.DoubleTensor(weights), int(num_samples))\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_ds,\n",
    "        batch_size=CFG['train_bs'],\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "        shuffle=False, ## IN CASE OF USING SAMPLER, SHUFFLE=FALSE\n",
    "        sampler=sampler, \n",
    "        num_workers=CFG['num_workers']\n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        valid_ds, \n",
    "        batch_size=CFG['valid_bs'],\n",
    "        num_workers=CFG['num_workers'],\n",
    "        shuffle=False,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67bc652d-dfff-45d6-8412-38db1fe187e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def distill_loss(student_logits, labels, teacher_logits, criterion, alpha=0.1):\n",
    "#     # TEACHER & STUDENT LOSS\n",
    "#     distillation_loss = criterion(student_logits, teacher_logits)\n",
    "    \n",
    "#     # STUDENT & LABEL LOSS\n",
    "#     student_loss = criterion(student_logits, labels)\n",
    "#     loss_b = alpha * student_loss + (1-alpha) * distillation_loss\n",
    "\n",
    "#     return loss_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0a7d551-5565-4c29-8398-371af4ece4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distill_loss(student_logits, labels, teacher_logits, criterion, alpha=0.1, temperature=2):\n",
    "    # STUDENT & LABEL LOSS\n",
    "    student_loss = criterion(student_logits, labels)\n",
    "\n",
    "    # TEACHER & STUDENT LOSS\n",
    "    teacher_probs = F.softmax(teacher_logits / temperature, dim=1)\n",
    "    student_probs = F.softmax(student_logits / temperature, dim=1)\n",
    "    distillation_loss = F.kl_div(torch.log(student_probs), teacher_probs, reduction=\"batchmean\") * (temperature ** 2)\n",
    "\n",
    "    # FINAL LOSS\n",
    "    loss_b = alpha * student_loss + (1 - alpha) * distillation_loss\n",
    "    return loss_b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08ffa2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(epoch, s_model, t_model, loss_tr, optimizer, train_loader, device, scheduler=None, alpha =0.1):\n",
    "    t = time.time()\n",
    "\n",
    "    # SET MODEL TRAINING MODE\n",
    "    s_model.train()\n",
    "    t_model.eval()\n",
    "    \n",
    "    running_loss = None\n",
    "    loss_sum = 0\n",
    "    student_preds_all = []\n",
    "    image_targets_all = []\n",
    "    acc_list = []\n",
    "    \n",
    "    pbar = tqdm(enumerate(train_loader), total=len(train_loader))\n",
    "    for step, (imgs, image_labels) in pbar:\n",
    "        imgs = imgs.to(device).float()\n",
    "        image_labels = image_labels.to(device).long()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # STUDENT MODEL PREDICTION\n",
    "        with torch.cuda.amp.autocast():\n",
    "            student_preds = s_model(imgs)\n",
    "            \n",
    "            # TEACHER MODEL DISTILLATION (NO UPDATE)\n",
    "            with torch.no_grad():\n",
    "                teacher_preds = t_model(imgs)\n",
    "            \n",
    "            # DISTILLATION LOSS\n",
    "            loss = distill_loss(student_preds, image_labels, teacher_preds, loss_tr, alpha)\n",
    "            loss_sum+=loss.detach()\n",
    "            \n",
    "            # BACKPROPAGATION\n",
    "            optimizer.zero_grad()\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        \n",
    "            if running_loss is None:\n",
    "                running_loss = loss.item()\n",
    "            else:\n",
    "                running_loss = running_loss * .99 + loss.item() * .01    \n",
    "            \n",
    "            # TQDM VERBOSE_STEP TRACKING\n",
    "            if ((step + 1) % CFG['verbose_step'] == 0) or ((step + 1) == len(train_loader)):\n",
    "                description = f'epoch {epoch} loss: {running_loss:.4f}'\n",
    "                pbar.set_description(description)\n",
    "        \n",
    "        student_preds_all += [torch.argmax(student_preds, 1).detach().cpu().numpy()]\n",
    "        image_targets_all += [image_labels.detach().cpu().numpy()]\n",
    "        \n",
    "    if scheduler is not None:\n",
    "        scheduler.step()\n",
    "    \n",
    "    student_preds_all = np.concatenate(student_preds_all)\n",
    "    image_targets_all = np.concatenate(image_targets_all)\n",
    "    \n",
    "    matrix = confusion_matrix(image_targets_all,student_preds_all)\n",
    "    epoch_f1 = f1_score(image_targets_all, student_preds_all, average='macro')\n",
    "    accuracy = (student_preds_all==image_targets_all).mean()\n",
    "    trn_loss = loss_sum/len(train_loader)\n",
    "    \n",
    "    return student_preds_all, accuracy, trn_loss, matrix, epoch_f1\n",
    "\n",
    "def valid_one_epoch(epoch,s_model, t_model, loss_fn, val_loader, device, scheduler=None, schd_loss_update=False, alpha =0.1):\n",
    "    t = time.time()\n",
    "    \n",
    "    # SET MODEL VALID MODE\n",
    "    s_model.eval()\n",
    "    t_model.eval()\n",
    "\n",
    "    loss_sum = 0\n",
    "    sample_num = 0\n",
    "    avg_loss = 0\n",
    "    student_preds_all = []\n",
    "    image_targets_all = []\n",
    "    acc_list = []\n",
    "    \n",
    "    pbar = tqdm(enumerate(val_loader), total=len(val_loader))\n",
    "    for step, (imgs, image_labels) in pbar:\n",
    "        imgs = imgs.to(device).float()\n",
    "        image_labels = image_labels.to(device).long()\n",
    "        \n",
    "        # STUDENT MODEL PREDICTION\n",
    "        student_preds = s_model(imgs)\n",
    "        # TEACHER MODEL PREDICTION\n",
    "        teacher_preds = t_model(imgs)\n",
    "        \n",
    "        # DISTILLATION LOSS\n",
    "        loss = distill_loss(student_preds, image_labels, teacher_preds, loss_fn, alpha)\n",
    "        \n",
    "        student_preds_all += [torch.argmax(student_preds, 1).detach().cpu().numpy()]\n",
    "        image_targets_all += [image_labels.detach().cpu().numpy()]\n",
    "        \n",
    "        avg_loss += loss.item()\n",
    "        loss_sum += loss.item()*image_labels.shape[0]\n",
    "        sample_num += image_labels.shape[0]\n",
    "        \n",
    "        # TQDM\n",
    "        description = f'epoch {epoch} loss: {loss_sum/sample_num:.4f}'\n",
    "        pbar.set_description(description)\n",
    "    \n",
    "    student_preds_all = np.concatenate(student_preds_all)\n",
    "    image_targets_all = np.concatenate(image_targets_all)\n",
    "    matrix = confusion_matrix(image_targets_all,student_preds_all)\n",
    "    \n",
    "    epoch_f1 = f1_score(image_targets_all, student_preds_all, average='macro')\n",
    "    acc = (student_preds_all==image_targets_all).mean()\n",
    "    val_loss = avg_loss/len(val_loader)\n",
    "    \n",
    "    return student_preds_all, acc, val_loss, matrix, epoch_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862e4b92-23e3-4444-9369-1dc9dc504b13",
   "metadata": {},
   "source": [
    "#### Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77e9950b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10, verbose=False, delta=0):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "\n",
    "    def __call__(self, score):\n",
    "        print(f' present score: {score}')\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "        elif score <= self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            print(f'Best F1 score from now: {self.best_score}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.counter = 0\n",
    "        \n",
    "        return self.early_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37102a34",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'seed_everything' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mseed_everything\u001b[49m(CFG[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseed\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m# WANDB TRACKER INIT\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     wandb\u001b[38;5;241m.\u001b[39minit(project\u001b[38;5;241m=\u001b[39mproject_name, entity\u001b[38;5;241m=\u001b[39muser)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'seed_everything' is not defined"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    seed_everything(CFG['seed'])\n",
    "    \n",
    "    # WANDB TRACKER INIT\n",
    "    wandb.init(project=project_name, entity=user)\n",
    "    wandb.config.update(CFG)\n",
    "    wandb.run.name = run_name\n",
    "    wandb.define_metric(\"Train Accuracy\", step_metric=\"epoch\")\n",
    "    wandb.define_metric(\"Valid Accuracy\", step_metric=\"epoch\")\n",
    "    wandb.define_metric(\"Train Loss\", step_metric=\"epoch\")\n",
    "    wandb.define_metric(\"Valid Loss\", step_metric=\"epoch\")\n",
    "    wandb.define_metric(\"Train Macro F1 Score\", step_metric=\"epoch\")\n",
    "    wandb.define_metric(\"Valid Macro F1 Score\", step_metric=\"epoch\")\n",
    "    wandb.define_metric(\"Train-Valid Accuracy\", step_metric=\"epoch\")\n",
    "    \n",
    "    model_dir = CFG['model_path'] + '/{}'.format(run_name)\n",
    "    train_dir = train.dir.values\n",
    "    best_fold = 0\n",
    "    best_f1 =0.0\n",
    "    \n",
    "    print('Model: {}'.format(CFG['s_model']))\n",
    "    # MAKE MODEL DIR\n",
    "    if not os.path.isdir(model_dir):\n",
    "        os.makedirs(model_dir)\n",
    "    \n",
    "    \n",
    "    # STRATIFIED K-FOLD DEFINITION\n",
    "    folds = StratifiedKFold(n_splits=CFG['fold_num'], shuffle=True, random_state=CFG['seed']).split(np.arange(train.shape[0]), train.label.values)\n",
    "    for fold, (trn_idx, val_idx) in enumerate(folds):\n",
    "        print(f'Training start with fold: {fold} epoch: {CFG[\"epochs\"]} \\n')\n",
    "\n",
    "        # EARLY STOPPING DEFINITION\n",
    "        early_stopping = EarlyStopping(patience=CFG[\"patience\"], verbose=True)\n",
    "\n",
    "        # DATALOADER DEFINITION\n",
    "        train_loader, val_loader = prepare_dataloader(train, trn_idx, val_idx, data_root=train_dir)\n",
    "\n",
    "        # MODEL & DEVICE DEFINITION \n",
    "        device = torch.device(CFG['device'])\n",
    "        student_model = Student(CFG['s_model'], train.label.nunique(), pretrained=True)\n",
    "        teacher_model = Teacher(CFG['t_model'], train.label.nunique(), pretrained=True)\n",
    "        \n",
    "        # T_MODEL DATA PARALLEL\n",
    "        teacher_model.to(device)\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            teacher_model = nn.DataParallel(teacher_model)\n",
    "\n",
    "        # LOAD TEACHER_MODE WEIGHT\n",
    "        load_model = CFG['model_path'] +'/' + CFG['load_model'] + '/' + CFG['t_model']\n",
    "        teacher_model.load_state_dict(torch.load(load_model))\n",
    "\n",
    "        # MODEL FREEZING\n",
    "        # student_model.freezing(freeze = CFG['freezing'], trainable_layer = CFG['trainable_layer'])\n",
    "        # if CFG['freezing'] ==True:\n",
    "        #     for name, param in student_model.named_parameters():\n",
    "        #         if param.requires_grad == True:\n",
    "        #             print(f\"{name}: {param.requires_grad}\")\n",
    "\n",
    "        # S_MODEL DATA PARALLEL\n",
    "        student_model.to(device)\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            student_model = nn.DataParallel(student_model)\n",
    "\n",
    "        scaler = torch.cuda.amp.GradScaler()   \n",
    "        optimizer = torch.optim.Adam(student_model.parameters(), lr=CFG['lr'])\n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, gamma=0.5, step_size=5)\n",
    "\n",
    "        # DISTILLATION RATE\n",
    "        alpha = CFG['alpha']\n",
    "\n",
    "        # CRITERION (LOSS FUNCTION)\n",
    "        loss_tr = nn.CrossEntropyLoss().to(device) #MyCrossEntropyLoss().to(device)\n",
    "        loss_fn = nn.CrossEntropyLoss().to(device)\n",
    "        \n",
    "        wandb.watch(student_model, loss_tr, log='all')\n",
    "        train_acc_list = []\n",
    "        train_matrix_list = []\n",
    "        train_f1_list = []\n",
    "        valid_acc_list = []\n",
    "        valid_matrix_list = []\n",
    "        valid_f1_list = []\n",
    "\n",
    "        start = time.time()\n",
    "        print(f'Fold: {fold}\\n')\n",
    "        for epoch in range(CFG['epochs']):\n",
    "            print('Epoch {}/{}'.format(epoch, CFG['epochs'] - 1))\n",
    "\n",
    "            # TRAINIG\n",
    "            train_preds_all, train_acc, train_loss, train_matrix, train_f1 = train_one_epoch(epoch, student_model, teacher_model,loss_tr, optimizer, train_loader, device, scheduler=scheduler, alpha = alpha)\n",
    "            wandb.log({'Train Accuracy':train_acc, 'Train Loss' : train_loss, 'Train F1': train_f1, 'epoch' : epoch})\n",
    "\n",
    "            # VALIDATION\n",
    "            with torch.no_grad():\n",
    "                valid_preds_all, valid_acc, valid_loss, valid_matrix, valid_f1= valid_one_epoch(epoch, student_model, teacher_model, loss_fn, val_loader, device, scheduler=None, alpha = alpha)\n",
    "                wandb.log({'Valid Accuracy':valid_acc, 'Valid Loss' : valid_loss, 'Valid F1': valid_f1 ,'epoch' : epoch})\n",
    "            print(f'Epoch [{epoch}], Train Loss : [{train_loss :.5f}] Val Loss : [{valid_loss :.5f}] Val F1 Score : [{valid_f1:.5f}]')\n",
    "\n",
    "            # SAVE ALL RESULTS\n",
    "            train_acc_list.append(train_acc)\n",
    "            train_matrix_list.append(train_matrix)\n",
    "            train_f1_list.append(train_f1)\n",
    "\n",
    "            valid_acc_list.append(valid_acc)\n",
    "            valid_matrix_list.append(valid_matrix)\n",
    "            valid_f1_list.append(valid_f1)\n",
    "\n",
    "            # MODEL SAVE (THE BEST MODEL OF ALL OF FOLD PROCESS)\n",
    "            if valid_f1 > best_f1:\n",
    "                best_f1 = valid_f1\n",
    "                torch.save(student_model.state_dict(), (model_dir+'/{}.pth').format(CFG['s_model']))\n",
    "\n",
    "            # EARLY STOPPING\n",
    "            stop = early_stopping(valid_f1)\n",
    "            if stop:\n",
    "                print(\"stop called\")   \n",
    "                break\n",
    "\n",
    "        end = time.time() - start\n",
    "        time_ = str(datetime.timedelta(seconds=end)).split(\".\")[0]\n",
    "        print(\"time :\", time_)\n",
    "\n",
    "        # PRINT BEST F1 SCORE MODEL OF FOLD\n",
    "        best_index = valid_f1_list.index(max(valid_f1_list))\n",
    "        print(f'fold: {fold}, Best Epoch : {best_index}/ {len(valid_f1_list)}')\n",
    "        print(f'Best Train Marco F1 : {train_f1_list[best_index]:.5f}')\n",
    "        print(train_matrix_list[best_index])\n",
    "        print(f'Best Valid Marco F1 : {valid_f1_list[best_index]:.5f}')\n",
    "        print(valid_matrix_list[best_index])\n",
    "        print('-----------------------------------------------------------------------')\n",
    "\n",
    "        ## K-FOLD END\n",
    "        if valid_f1_list[best_index] > best_fold:\n",
    "            best_fold = valid_f1_list[best_index]\n",
    "            top_fold = fold\n",
    "    print(f'Best Fold F1 score: {best_fold} Top fold : {top_fold}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "084cd221-5c4f-4255-8f42-7e898c240898",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>dir</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pet_2366.jpg</td>\n",
       "      <td>../Data/carbon_data/pet</td>\n",
       "      <td>pet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pet_2065.jpg</td>\n",
       "      <td>../Data/carbon_data/pet</td>\n",
       "      <td>pet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pet_1199.jpg</td>\n",
       "      <td>../Data/carbon_data/pet</td>\n",
       "      <td>pet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pet_932.jpg</td>\n",
       "      <td>../Data/carbon_data/pet</td>\n",
       "      <td>pet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pet_201.jpg</td>\n",
       "      <td>../Data/carbon_data/pet</td>\n",
       "      <td>pet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1382</th>\n",
       "      <td>2294_jpg.rf.ce95ad8540f9b9d5f686614f49224dba.jpg</td>\n",
       "      <td>../Data/carbon_data/labeled</td>\n",
       "      <td>labeled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1383</th>\n",
       "      <td>4460_jpg.rf.a92554d8db8ed19fc370562601f2c33e.jpg</td>\n",
       "      <td>../Data/carbon_data/labeled</td>\n",
       "      <td>labeled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384</th>\n",
       "      <td>pet27463.jpg</td>\n",
       "      <td>../Data/carbon_data/labeled</td>\n",
       "      <td>labeled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1385</th>\n",
       "      <td>pet19028.jpg</td>\n",
       "      <td>../Data/carbon_data/labeled</td>\n",
       "      <td>labeled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1386</th>\n",
       "      <td>pte (1079).jpg</td>\n",
       "      <td>../Data/carbon_data/labeled</td>\n",
       "      <td>labeled</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1387 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              image_id  \\\n",
       "0                                         pet_2366.jpg   \n",
       "1                                         pet_2065.jpg   \n",
       "2                                         pet_1199.jpg   \n",
       "3                                          pet_932.jpg   \n",
       "4                                          pet_201.jpg   \n",
       "...                                                ...   \n",
       "1382  2294_jpg.rf.ce95ad8540f9b9d5f686614f49224dba.jpg   \n",
       "1383  4460_jpg.rf.a92554d8db8ed19fc370562601f2c33e.jpg   \n",
       "1384                                      pet27463.jpg   \n",
       "1385                                      pet19028.jpg   \n",
       "1386                                    pte (1079).jpg   \n",
       "\n",
       "                              dir    label  \n",
       "0         ../Data/carbon_data/pet      pet  \n",
       "1         ../Data/carbon_data/pet      pet  \n",
       "2         ../Data/carbon_data/pet      pet  \n",
       "3         ../Data/carbon_data/pet      pet  \n",
       "4         ../Data/carbon_data/pet      pet  \n",
       "...                           ...      ...  \n",
       "1382  ../Data/carbon_data/labeled  labeled  \n",
       "1383  ../Data/carbon_data/labeled  labeled  \n",
       "1384  ../Data/carbon_data/labeled  labeled  \n",
       "1385  ../Data/carbon_data/labeled  labeled  \n",
       "1386  ../Data/carbon_data/labeled  labeled  \n",
       "\n",
       "[1387 rows x 3 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Pandas Test 데이터프레임 만들기\n",
    "tst_df = pd.DataFrame(total_test_img_paths, columns=['image_id'])\n",
    "tst_df['dir'] = tst_df['image_id'].apply(lambda x: os.path.dirname(x))\n",
    "tst_df['image_id'] = tst_df['image_id'].apply(lambda x: os.path.basename(x))\n",
    "tst_df['label'] = total_test_img_labels\n",
    "test = tst_df\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8a437e36-9c91-4f37-8a6c-f3eadce8fecb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>dir</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pet_2366.jpg</td>\n",
       "      <td>../Data/carbon_data/pet</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pet_2065.jpg</td>\n",
       "      <td>../Data/carbon_data/pet</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pet_1199.jpg</td>\n",
       "      <td>../Data/carbon_data/pet</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pet_932.jpg</td>\n",
       "      <td>../Data/carbon_data/pet</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pet_201.jpg</td>\n",
       "      <td>../Data/carbon_data/pet</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1382</th>\n",
       "      <td>2294_jpg.rf.ce95ad8540f9b9d5f686614f49224dba.jpg</td>\n",
       "      <td>../Data/carbon_data/labeled</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1383</th>\n",
       "      <td>4460_jpg.rf.a92554d8db8ed19fc370562601f2c33e.jpg</td>\n",
       "      <td>../Data/carbon_data/labeled</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384</th>\n",
       "      <td>pet27463.jpg</td>\n",
       "      <td>../Data/carbon_data/labeled</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1385</th>\n",
       "      <td>pet19028.jpg</td>\n",
       "      <td>../Data/carbon_data/labeled</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1386</th>\n",
       "      <td>pte (1079).jpg</td>\n",
       "      <td>../Data/carbon_data/labeled</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1387 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              image_id  \\\n",
       "0                                         pet_2366.jpg   \n",
       "1                                         pet_2065.jpg   \n",
       "2                                         pet_1199.jpg   \n",
       "3                                          pet_932.jpg   \n",
       "4                                          pet_201.jpg   \n",
       "...                                                ...   \n",
       "1382  2294_jpg.rf.ce95ad8540f9b9d5f686614f49224dba.jpg   \n",
       "1383  4460_jpg.rf.a92554d8db8ed19fc370562601f2c33e.jpg   \n",
       "1384                                      pet27463.jpg   \n",
       "1385                                      pet19028.jpg   \n",
       "1386                                    pte (1079).jpg   \n",
       "\n",
       "                              dir  label  \n",
       "0         ../Data/carbon_data/pet      1  \n",
       "1         ../Data/carbon_data/pet      1  \n",
       "2         ../Data/carbon_data/pet      1  \n",
       "3         ../Data/carbon_data/pet      1  \n",
       "4         ../Data/carbon_data/pet      1  \n",
       "...                           ...    ...  \n",
       "1382  ../Data/carbon_data/labeled      0  \n",
       "1383  ../Data/carbon_data/labeled      0  \n",
       "1384  ../Data/carbon_data/labeled      0  \n",
       "1385  ../Data/carbon_data/labeled      0  \n",
       "1386  ../Data/carbon_data/labeled      0  \n",
       "\n",
       "[1387 rows x 3 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test2['label'].value_counts()\n",
    "test['label'] = le.fit_transform(test['label'].values)\n",
    "#test2['label'] = le.inverse_transform(test2['label'].values)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5e9b29-a540-44a3-9ffb-c9e4b06104dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1ef05a94-6c5d-4171-8286-8efa23ba7a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################## inference #############################\n",
    "def inference(model, data_loader, device):\n",
    "    model.eval()\n",
    "    image_preds_all = []\n",
    "    \n",
    "    pbar = tqdm(enumerate(data_loader), total=len(data_loader))\n",
    "    for step, (imgs) in pbar:\n",
    "        imgs = imgs.to(device).float()\n",
    "\n",
    "        image_preds = model(imgs)   #output = model(input)\n",
    "        image_preds_all += [torch.softmax(image_preds, 1).detach().cpu().numpy()]\n",
    "    \n",
    "    image_preds_all = np.concatenate(image_preds_all, axis=0)\n",
    "    return image_preds_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bf8dd532-5acf-4d36-93df-55a97860eb0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hojun/miniconda3/envs/torch/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/hojun/miniconda3/envs/torch/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V3_Large_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V3_Large_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "100%|███████████████████████████████████████████| 22/22 [00:18<00:00,  1.21it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = Student(CFG['s_model'], test.label.nunique(), pretrained=True)\n",
    "load_model = CFG['model_path'] + '/mobilenet_pet_20230430181138/' + CFG['s_model'] + '.pth'\n",
    "test_dir = test.dir.values\n",
    "\n",
    "tst_ds = ColonDataset(test, test_dir, transform=transform_test, output_label=False)\n",
    "tst_loader = torch.utils.data.DataLoader(\n",
    "    tst_ds, \n",
    "    batch_size=CFG['train_bs'],\n",
    "    num_workers=CFG['num_workers'],\n",
    "    shuffle=False,\n",
    "    pin_memory=True\n",
    ")\n",
    "device = torch.device(CFG['device'])\n",
    "\n",
    "# INFERENCE VIA MULTI-GPU\n",
    "# if torch.cuda.device_count() > 1:\n",
    "#         model = nn.DataParallel(model)\n",
    "model.to(device)\n",
    "\n",
    "# RUN INFERENCE\n",
    "predictions = []\n",
    "model.load_state_dict(torch.load(load_model))\n",
    "with torch.no_grad():\n",
    "    predictions += [inference(model, tst_loader, device)]\n",
    "\n",
    "\n",
    "predictions = np.mean(predictions, axis=0) \n",
    "test['pred'] = np.argmax(predictions, axis=1)\n",
    "#test['confidence score'] =np.max(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "63e86c0e-080e-4a45-ba54-20db2560660d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>dir</th>\n",
       "      <th>label</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pet_2366.jpg</td>\n",
       "      <td>../Data/carbon_data/pet</td>\n",
       "      <td>pet</td>\n",
       "      <td>pet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pet_2065.jpg</td>\n",
       "      <td>../Data/carbon_data/pet</td>\n",
       "      <td>pet</td>\n",
       "      <td>pet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pet_1199.jpg</td>\n",
       "      <td>../Data/carbon_data/pet</td>\n",
       "      <td>pet</td>\n",
       "      <td>pet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pet_932.jpg</td>\n",
       "      <td>../Data/carbon_data/pet</td>\n",
       "      <td>pet</td>\n",
       "      <td>pet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pet_201.jpg</td>\n",
       "      <td>../Data/carbon_data/pet</td>\n",
       "      <td>pet</td>\n",
       "      <td>pet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1382</th>\n",
       "      <td>2294_jpg.rf.ce95ad8540f9b9d5f686614f49224dba.jpg</td>\n",
       "      <td>../Data/carbon_data/labeled</td>\n",
       "      <td>labeled</td>\n",
       "      <td>labeled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1383</th>\n",
       "      <td>4460_jpg.rf.a92554d8db8ed19fc370562601f2c33e.jpg</td>\n",
       "      <td>../Data/carbon_data/labeled</td>\n",
       "      <td>labeled</td>\n",
       "      <td>labeled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384</th>\n",
       "      <td>pet27463.jpg</td>\n",
       "      <td>../Data/carbon_data/labeled</td>\n",
       "      <td>labeled</td>\n",
       "      <td>labeled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1385</th>\n",
       "      <td>pet19028.jpg</td>\n",
       "      <td>../Data/carbon_data/labeled</td>\n",
       "      <td>labeled</td>\n",
       "      <td>labeled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1386</th>\n",
       "      <td>pte (1079).jpg</td>\n",
       "      <td>../Data/carbon_data/labeled</td>\n",
       "      <td>labeled</td>\n",
       "      <td>labeled</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1387 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              image_id  \\\n",
       "0                                         pet_2366.jpg   \n",
       "1                                         pet_2065.jpg   \n",
       "2                                         pet_1199.jpg   \n",
       "3                                          pet_932.jpg   \n",
       "4                                          pet_201.jpg   \n",
       "...                                                ...   \n",
       "1382  2294_jpg.rf.ce95ad8540f9b9d5f686614f49224dba.jpg   \n",
       "1383  4460_jpg.rf.a92554d8db8ed19fc370562601f2c33e.jpg   \n",
       "1384                                      pet27463.jpg   \n",
       "1385                                      pet19028.jpg   \n",
       "1386                                    pte (1079).jpg   \n",
       "\n",
       "                              dir    label     pred  \n",
       "0         ../Data/carbon_data/pet      pet      pet  \n",
       "1         ../Data/carbon_data/pet      pet      pet  \n",
       "2         ../Data/carbon_data/pet      pet      pet  \n",
       "3         ../Data/carbon_data/pet      pet      pet  \n",
       "4         ../Data/carbon_data/pet      pet      pet  \n",
       "...                           ...      ...      ...  \n",
       "1382  ../Data/carbon_data/labeled  labeled  labeled  \n",
       "1383  ../Data/carbon_data/labeled  labeled  labeled  \n",
       "1384  ../Data/carbon_data/labeled  labeled  labeled  \n",
       "1385  ../Data/carbon_data/labeled  labeled  labeled  \n",
       "1386  ../Data/carbon_data/labeled  labeled  labeled  \n",
       "\n",
       "[1387 rows x 4 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['label'] = le.inverse_transform(test['label'].values)\n",
    "test['pred'] = le.inverse_transform(test['pred'].values)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8c6af9cf-1048-40ed-a983-d831cc5ac39d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9971\n",
      "f1_score: 0.9968\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1500x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "test_acc = np.sum(test.label == test.pred) / len(test)\n",
    "test_matrix = confusion_matrix(test['label'], test['pred'])\n",
    "epoch_f1 = f1_score(test['label'], test['pred'], average='macro')\n",
    "print(f'accuracy: {test_acc:.4f}')\n",
    "print(f'f1_score: {epoch_f1:.4f}')\n",
    "\n",
    "test_matrix = confusion_matrix(test['label'], test['pred'], normalize='true')\n",
    "#test_matrix = confusion_matrix(test['label'], test['pred'])\n",
    "\n",
    "plt.figure(figsize = (15,10))\n",
    "sns.heatmap(test_matrix, \n",
    "            annot=True, \n",
    "            xticklabels = sorted(set(test['label'])), \n",
    "            yticklabels = sorted(set(test['label'])),\n",
    "            )\n",
    "plt.title('Normalized Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "#print(f'confusion_matrix \\n-------------------------\\n {test_matrix}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7162577b-8bd7-4cfb-b7e4-7332c1959181",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-gpu",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
