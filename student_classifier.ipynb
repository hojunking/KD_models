{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32c4ea0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, magic, shutil\n",
    "from glob import glob\n",
    "import time, datetime\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import joblib\n",
    "import datetime as dt\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torch, gc\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "\n",
    "#from skimage import io\n",
    "import sklearn\n",
    "from sklearn.model_selection import GroupKFold, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, log_loss, f1_score, confusion_matrix, classification_report\n",
    "from sklearn import metrics, preprocessing\n",
    "from scipy.ndimage import zoom\n",
    "import timm\n",
    "from timm.data import resolve_data_config\n",
    "from timm.data.transforms_factory import create_transform\n",
    "import albumentations as A\n",
    "import albumentations.pytorch\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29d0796-1f1d-40df-ad4a-21f57ed7fe35",
   "metadata": {},
   "source": [
    "#### Hyper Param Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57c0283c",
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'fold_num': 5,\n",
    "    'seed': 42,\n",
    "    't_model': 'resnet152',\n",
    "    'load_model': 'KD_resnet152_dishes_202305200035', # LOAD TEACHER MODEL\n",
    "    's_model': 'mobilenet_v3_large',\n",
    "    'img_size': 260,\n",
    "    'alpha': 0.5, # HARD LABEL : SOFT LABEL RATIO\n",
    "    'epochs': 200, \n",
    "    'train_bs':64,\n",
    "    'valid_bs':64,\n",
    "    'lr': 1e-4, ## learning rate\n",
    "    'num_workers': 8,\n",
    "    'verbose_step': 1,\n",
    "    'patience' : 5,\n",
    "    'label_encoder':False,\n",
    "    'device': 'cuda:0',\n",
    "    'freezing': False,\n",
    "    'trainable_layer': 6,\n",
    "    'model_path': './models'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7066a8a1-7060-4b6d-bf0c-d4164820a414",
   "metadata": {},
   "source": [
    "#### wandb init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "127461e4-c16d-47fd-b983-556c12ad0daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "category = 'dishes'\n",
    "time_now = dt.datetime.now()\n",
    "run_id = time_now.strftime(\"%Y%m%d%H%M\")\n",
    "project_name = 'KD_'+ category + '_'+ CFG['t_model'] + '_' + CFG['s_model']\n",
    "user = 'hojunking'\n",
    "run_name = project_name + '_' + run_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c538155-d55f-4321-bf7c-171d356ebceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: wrap 1266\n",
      "label: leftover 1483\n",
      "label: green dish 1261\n",
      "Train_Images:  4010\n",
      "Train_Images_labels: 4010\n"
     ]
    }
   ],
   "source": [
    "# TRAIN DATASET DATAFRAME\n",
    "train_path = '../Data/carbon_reduction_data/train/'\n",
    "label_list = ['wrap','leftover','green dish']\n",
    "\n",
    "train_img_paths = []\n",
    "train_img_labels = []\n",
    "\n",
    "for label in label_list: ## 각 레이블 돌기\n",
    "    print(f'label: {label}',end=' ')\n",
    "    img_paths = [] \n",
    "    img_labels = []\n",
    "\n",
    "    dir_path = train_path + label ## 레이블 폴더 경로\n",
    "    \n",
    "    for folder, subfolders, filenames in os.walk(dir_path): ## 폴더 내 모든 파일 탐색\n",
    "        for img in filenames: ## 각 파일 경로, 레이블 저장\n",
    "            img_paths.append(folder+'/'+img)\n",
    "            img_labels.append(label)\n",
    "        \n",
    "    print(len(img_paths))\n",
    "\n",
    "    train_img_paths.extend(img_paths)\n",
    "    train_img_labels.extend(img_labels)\n",
    "\n",
    "print('Train_Images: ',len(train_img_paths))\n",
    "print(\"Train_Images_labels:\", len(train_img_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f420162-da43-4ac0-9187-d4aedf9533e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: wrap 423\n",
      "label: leftover 495\n",
      "label: green dish 421\n",
      "Test_Images:  1339\n",
      "Test_Images_labels: 1339\n"
     ]
    }
   ],
   "source": [
    "# TEST DATASET DATAFRAME\n",
    "test_path =  '../Data/carbon_reduction_data/test/'\n",
    "test_img_paths = []\n",
    "test_img_labels = []\n",
    "\n",
    "for label in label_list: ## 각 레이블 돌기\n",
    "    print(f'label: {label}',end=' ')\n",
    "    img_paths = [] \n",
    "    img_labels = []\n",
    "    dir_path = test_path + label ## 레이블 폴더 경로\n",
    "    \n",
    "    for folder, subfolders, filenames in os.walk(dir_path): ## 폴더 내 모든 파일 탐색\n",
    "        for img in filenames: ## 각 파일 경로, 레이블 저장\n",
    "            img_paths.append(folder+'/'+img)\n",
    "            img_labels.append(label)\n",
    "        \n",
    "    print(len(img_paths))\n",
    "\n",
    "    test_img_paths.extend(img_paths)\n",
    "    test_img_labels.extend(img_labels)\n",
    "\n",
    "print('Test_Images: ',len(test_img_paths))\n",
    "print(\"Test_Images_labels:\", len(test_img_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2716dd8b-84db-4707-80e2-19b29eae9c23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>dir</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0720.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/train/wrap</td>\n",
       "      <td>wrap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0282.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/train/wrap</td>\n",
       "      <td>wrap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1028.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/train/wrap</td>\n",
       "      <td>wrap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0540.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/train/wrap</td>\n",
       "      <td>wrap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0466.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/train/wrap</td>\n",
       "      <td>wrap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4005</th>\n",
       "      <td>0011.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/train/green dish</td>\n",
       "      <td>green dish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4006</th>\n",
       "      <td>0868.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/train/green dish</td>\n",
       "      <td>green dish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4007</th>\n",
       "      <td>0611.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/train/green dish</td>\n",
       "      <td>green dish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4008</th>\n",
       "      <td>0692.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/train/green dish</td>\n",
       "      <td>green dish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4009</th>\n",
       "      <td>1059.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/train/green dish</td>\n",
       "      <td>green dish</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4010 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      image_id                                             dir       label\n",
       "0     0720.jpg        ../Data/carbon_reduction_data/train/wrap        wrap\n",
       "1     0282.jpg        ../Data/carbon_reduction_data/train/wrap        wrap\n",
       "2     1028.jpg        ../Data/carbon_reduction_data/train/wrap        wrap\n",
       "3     0540.jpg        ../Data/carbon_reduction_data/train/wrap        wrap\n",
       "4     0466.jpg        ../Data/carbon_reduction_data/train/wrap        wrap\n",
       "...        ...                                             ...         ...\n",
       "4005  0011.jpg  ../Data/carbon_reduction_data/train/green dish  green dish\n",
       "4006  0868.jpg  ../Data/carbon_reduction_data/train/green dish  green dish\n",
       "4007  0611.jpg  ../Data/carbon_reduction_data/train/green dish  green dish\n",
       "4008  0692.jpg  ../Data/carbon_reduction_data/train/green dish  green dish\n",
       "4009  1059.jpg  ../Data/carbon_reduction_data/train/green dish  green dish\n",
       "\n",
       "[4010 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Pandas 데이터프레임 만들기\n",
    "trn_df = pd.DataFrame(train_img_paths, columns=['image_id'])\n",
    "trn_df['dir'] = trn_df['image_id'].apply(lambda x: os.path.dirname(x))\n",
    "trn_df['image_id'] = trn_df['image_id'].apply(lambda x: os.path.basename(x))\n",
    "trn_df['label'] = train_img_labels\n",
    "train = trn_df\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b84a8c2-bdde-4fae-b68a-964bb3702c18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>dir</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0282.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/test/wrap</td>\n",
       "      <td>wrap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0190.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/test/wrap</td>\n",
       "      <td>wrap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0234.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/test/wrap</td>\n",
       "      <td>wrap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0392.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/test/wrap</td>\n",
       "      <td>wrap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0375.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/test/wrap</td>\n",
       "      <td>wrap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1334</th>\n",
       "      <td>0381.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/test/green dish</td>\n",
       "      <td>green dish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1335</th>\n",
       "      <td>0236.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/test/green dish</td>\n",
       "      <td>green dish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336</th>\n",
       "      <td>0384.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/test/green dish</td>\n",
       "      <td>green dish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1337</th>\n",
       "      <td>0074.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/test/green dish</td>\n",
       "      <td>green dish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1338</th>\n",
       "      <td>0011.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/test/green dish</td>\n",
       "      <td>green dish</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1339 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      image_id                                            dir       label\n",
       "0     0282.jpg        ../Data/carbon_reduction_data/test/wrap        wrap\n",
       "1     0190.jpg        ../Data/carbon_reduction_data/test/wrap        wrap\n",
       "2     0234.jpg        ../Data/carbon_reduction_data/test/wrap        wrap\n",
       "3     0392.jpg        ../Data/carbon_reduction_data/test/wrap        wrap\n",
       "4     0375.jpg        ../Data/carbon_reduction_data/test/wrap        wrap\n",
       "...        ...                                            ...         ...\n",
       "1334  0381.jpg  ../Data/carbon_reduction_data/test/green dish  green dish\n",
       "1335  0236.jpg  ../Data/carbon_reduction_data/test/green dish  green dish\n",
       "1336  0384.jpg  ../Data/carbon_reduction_data/test/green dish  green dish\n",
       "1337  0074.jpg  ../Data/carbon_reduction_data/test/green dish  green dish\n",
       "1338  0011.jpg  ../Data/carbon_reduction_data/test/green dish  green dish\n",
       "\n",
       "[1339 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Pandas 데이터프레임 만들기\n",
    "tst_df = pd.DataFrame(test_img_paths, columns=['image_id'])\n",
    "tst_df['dir'] = tst_df['image_id'].apply(lambda x: os.path.dirname(x))\n",
    "tst_df['image_id'] = tst_df['image_id'].apply(lambda x: os.path.basename(x))\n",
    "tst_df['label'] = test_img_labels\n",
    "test = tst_df\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03c67d39-7933-4f98-b998-54a6036ff4a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>dir</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0720.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/train/wrap</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0282.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/train/wrap</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1028.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/train/wrap</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0540.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/train/wrap</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0466.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/train/wrap</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4005</th>\n",
       "      <td>0011.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/train/green dish</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4006</th>\n",
       "      <td>0868.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/train/green dish</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4007</th>\n",
       "      <td>0611.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/train/green dish</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4008</th>\n",
       "      <td>0692.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/train/green dish</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4009</th>\n",
       "      <td>1059.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/train/green dish</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4010 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      image_id                                             dir  label\n",
       "0     0720.jpg        ../Data/carbon_reduction_data/train/wrap      2\n",
       "1     0282.jpg        ../Data/carbon_reduction_data/train/wrap      2\n",
       "2     1028.jpg        ../Data/carbon_reduction_data/train/wrap      2\n",
       "3     0540.jpg        ../Data/carbon_reduction_data/train/wrap      2\n",
       "4     0466.jpg        ../Data/carbon_reduction_data/train/wrap      2\n",
       "...        ...                                             ...    ...\n",
       "4005  0011.jpg  ../Data/carbon_reduction_data/train/green dish      0\n",
       "4006  0868.jpg  ../Data/carbon_reduction_data/train/green dish      0\n",
       "4007  0611.jpg  ../Data/carbon_reduction_data/train/green dish      0\n",
       "4008  0692.jpg  ../Data/carbon_reduction_data/train/green dish      0\n",
       "4009  1059.jpg  ../Data/carbon_reduction_data/train/green dish      0\n",
       "\n",
       "[4010 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "train['label'] = le.fit_transform(train['label'].values)\n",
    "test['label'] = le.transform(test['label'].values)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d3fa5ff-2c3f-4b28-af67-e7ee2533d021",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_encoding_classes():\n",
    "    # define certain classes to transform differently\n",
    "    capture_image_classes = ['10Kwalk', 'battery','receipt']\n",
    "    return le.transform(capture_image_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c454bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d97a3c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img(path, sub_path=None):\n",
    "    try:\n",
    "        im_bgr = cv2.imread(path)\n",
    "        im_rgb = im_bgr[:, :, ::-1]\n",
    "        past_path = path\n",
    "    except: ## 이미지 에러 발생 시 백지로 대체\n",
    "        im_bgr = cv2.imread('../Data/carbon_reduction/temp_img.jpg')\n",
    "        im_rgb = im_bgr[:, :, ::-1]\n",
    "    return im_rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "884eb987-4341-4fe7-8094-6e61cb051af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = A.Compose([\n",
    "    A.OneOf([\n",
    "        A.Compose([\n",
    "            A.RandomResizedCrop(p=1, height=CFG['img_size'] ,width=CFG['img_size'], scale=(0.65, 0.75),ratio=(0.90, 1.10)),\n",
    "        ], p=0.8),\n",
    "        A.Compose([\n",
    "            A.Resize(p=1, height = CFG['img_size'], width = CFG['img_size']),\n",
    "        ], p=0.2),\n",
    "    ], p=1.0),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.SafeRotate(p=0.5, limit=(-20, 20), interpolation=2, border_mode=0, value=(0, 0, 0), mask_value=None),\n",
    "    A.ColorJitter(always_apply=True, p=0.5, contrast=0.2, saturation=0.3, hue=0.2),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, always_apply=True, p=1.0),\n",
    "    A.pytorch.transforms.ToTensorV2()\n",
    "        ])\n",
    "\n",
    "transform_train_cap = A.Compose([\n",
    "    A.OneOf([\n",
    "        A.Compose([\n",
    "            A.RandomResizedCrop(p=1, height=CFG['img_size'] ,width=CFG['img_size'], scale=(0.65, 0.85),ratio=(0.90, 1.10)),\n",
    "        ], p=0.6),\n",
    "        A.Compose([\n",
    "            A.Resize(p=1, height = CFG['img_size'], width = CFG['img_size']),\n",
    "        ], p=0.4),\n",
    "    ], p=1.0),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, always_apply=True, p=1.0),\n",
    "    A.pytorch.transforms.ToTensorV2()\n",
    "])\n",
    "\n",
    "transform_test = A.Compose([\n",
    "    A.Resize(height = CFG['img_size'], width = CFG['img_size']),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, p=1.0),\n",
    "    A.pytorch.transforms.ToTensorV2()\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f1561be",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, df, data_root, transform=None, transform2=None, output_label=True, encoded_class=False):\n",
    "        super(CustomDataset,self).__init__()\n",
    "        self.df = df.reset_index(drop=True).copy()\n",
    "        self.transform = transform\n",
    "        self.transform2 = transform2\n",
    "        self.data_root = data_root\n",
    "        self.output_label = output_label\n",
    "         \n",
    "        if encoded_class == True:\n",
    "            self.encoded_class = label_encoding_classes()\n",
    "        else:\n",
    "            self.encoded_class = encoded_class\n",
    "            \n",
    "        if output_label == True:\n",
    "            self.labels = self.df['label'].values\n",
    "        \n",
    "    # AUGMENTATION DIFFERENTLY DEPENDING ON THE TARGET\n",
    "    def custom_augmentation(self, img, target):\n",
    "        if self.encoded_class is not False and target in self.encoded_class:\n",
    "            return self.transform2(image=img)\n",
    "        else:\n",
    "            return self.transform(image=img)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index: int):\n",
    "        \n",
    "        # GET IMAGES\n",
    "        path = \"{}/{}\".format(self.data_root[index], self.df.iloc[index]['image_id'])\n",
    "        img  = get_img(path)\n",
    "        \n",
    "        # GET LABELS\n",
    "        if self.output_label:\n",
    "            target = self.labels[index]\n",
    "            \n",
    "            # CUSTOM AUGMENTATION\n",
    "            transformed = self.custom_augmentation(img, target) \n",
    "            img = transformed['image']\n",
    "            return img, target\n",
    "        else:\n",
    "            transformed =self.transform(image=img)\n",
    "            img = transformed['image']\n",
    "            return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "73a5b82b-cb1e-4e91-8c70-3a1890bc707c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD PRE-TRAINED MODEL\n",
    "class Student(nn.Module):\n",
    "    def __init__(self, model_arch, num_classes= 2,pretrained=True):\n",
    "        super(Student, self).__init__()\n",
    "        self.backbone = models.mobilenet_v3_large(pretrained=pretrained) ## 모델 선언 여기 models.##(pretrained =pretrained)\n",
    "        self.backbone.classifier[-1] = nn.Linear(self.backbone.classifier[-1].in_features, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "572bd9cd-7650-4d6d-8574-7a4942eef620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD PRE-TRAINED MODEL\n",
    "class Teacher(nn.Module):\n",
    "    def __init__(self, model_arch, num_classes= 2,pretrained=True):\n",
    "        super(Teacher, self).__init__()\n",
    "        self.backbone = models.resnet152(pretrained=pretrained) ## 모델 선언 여기 models.##(pretrained =pretrained)\n",
    "        self.backbone.fc = nn.Linear(self.backbone.fc.in_features, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "240e5531",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataloader(df, trn_idx, val_idx, data_root=train.dir.values):\n",
    "    \n",
    "    train_ = df.loc[trn_idx,:].reset_index(drop=True)\n",
    "    valid_ = df.loc[val_idx,:].reset_index(drop=True)\n",
    "    train_data_root = data_root[trn_idx]\n",
    "    valid_data_root = data_root[val_idx]\n",
    "    \n",
    "        \n",
    "    train_ds = CustomDataset(train_, train_data_root, transform=transform_train,\n",
    "                            transform2=transform_train_cap, output_label=True, encoded_class=CFG['label_encoder'])\n",
    "    valid_ds = CustomDataset(valid_, valid_data_root, transform=transform_test,\n",
    "                            output_label=True)\n",
    "    # WEIGHTEDRANDOMSAMPLER\n",
    "    class_counts = train_.label.value_counts(sort=False).to_dict()\n",
    "    num_samples = sum(class_counts.values())\n",
    "    print(f'cls_cnts: {len(class_counts)}\\nnum_samples:{num_samples}')\n",
    "    \n",
    "    # weight 제작, 전체 학습 데이터 수를 해당 클래스의 데이터 수로 나누어 줌\n",
    "    class_weights = {l:round(num_samples/class_counts[l], 2) for l in class_counts.keys()}\n",
    "    t_labels = train_.label.to_list()\n",
    "    \n",
    "    # class 별 weight를 전체 trainset에 대응시켜 sampler에 넣어줌\n",
    "    weights = [class_weights[t_labels[i]] for i in range(int(num_samples))]\n",
    "\n",
    "\n",
    "    # weight 제작, 전체 학습 데이터 수를 해당 클래스의 데이터 수로 나누어 줌\n",
    "    class_weights = {l:round(num_samples/class_counts[l], 2) for l in class_counts.keys()}\n",
    "\n",
    "    # class 별 weight를 전체 trainset에 대응시켜 sampler에 넣어줌\n",
    "    weights = [class_weights[t_labels[i]] for i in range(int(num_samples))] \n",
    "    sampler = torch.utils.data.WeightedRandomSampler(torch.DoubleTensor(weights), int(num_samples))\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_ds,\n",
    "        batch_size=CFG['train_bs'],\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "        shuffle=False,\n",
    "        sampler=sampler, \n",
    "        num_workers=CFG['num_workers']\n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        valid_ds, \n",
    "        batch_size=CFG['valid_bs'],\n",
    "        num_workers=CFG['num_workers'],\n",
    "        shuffle=False,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "67bc652d-dfff-45d6-8412-38db1fe187e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def distill_loss(student_logits, labels, teacher_logits, criterion, alpha=0.1):\n",
    "#     # TEACHER & STUDENT LOSS\n",
    "#     distillation_loss = criterion(student_logits, teacher_logits)\n",
    "    \n",
    "#     # STUDENT & LABEL LOSS\n",
    "#     student_loss = criterion(student_logits, labels)\n",
    "#     loss_b = alpha * student_loss + (1-alpha) * distillation_loss\n",
    "\n",
    "#     return loss_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a0a7d551-5565-4c29-8398-371af4ece4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distill_loss(student_logits, labels, teacher_logits, criterion, alpha=0.1, temperature=2):\n",
    "    # STUDENT & LABEL LOSS\n",
    "    student_loss = criterion(student_logits, labels)\n",
    "\n",
    "    # TEACHER & STUDENT LOSS\n",
    "    teacher_probs = F.softmax(teacher_logits / temperature, dim=1)\n",
    "    student_probs = F.softmax(student_logits / temperature, dim=1)\n",
    "    distillation_loss = F.kl_div(torch.log(student_probs), teacher_probs, reduction=\"batchmean\") * (temperature ** 2)\n",
    "\n",
    "    # FINAL LOSS\n",
    "    loss_b = alpha * student_loss + (1 - alpha) * distillation_loss\n",
    "    return loss_b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "08ffa2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(epoch, s_model, t_model, loss_tr, optimizer, train_loader, device, scheduler=None, alpha =0.1):\n",
    "    t = time.time()\n",
    "\n",
    "    # SET MODEL TRAINING MODE\n",
    "    s_model.train()\n",
    "    t_model.eval()\n",
    "    \n",
    "    running_loss = None\n",
    "    loss_sum = 0\n",
    "    student_preds_all = []\n",
    "    image_targets_all = []\n",
    "    acc_list = []\n",
    "    \n",
    "    pbar = tqdm(enumerate(train_loader), total=len(train_loader))\n",
    "    for step, (imgs, image_labels) in pbar:\n",
    "        imgs = imgs.to(device).float()\n",
    "        image_labels = image_labels.to(device).long()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # STUDENT MODEL PREDICTION\n",
    "        with torch.cuda.amp.autocast():\n",
    "            student_preds = s_model(imgs)\n",
    "            \n",
    "            # TEACHER MODEL DISTILLATION (NO UPDATE)\n",
    "            with torch.no_grad():\n",
    "                teacher_preds = t_model(imgs)\n",
    "            \n",
    "            # DISTILLATION LOSS\n",
    "            loss = distill_loss(student_preds, image_labels, teacher_preds, loss_tr, alpha)\n",
    "            loss_sum+=loss.detach()\n",
    "            \n",
    "            # BACKPROPAGATION\n",
    "            optimizer.zero_grad()\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        \n",
    "            if running_loss is None:\n",
    "                running_loss = loss.item()\n",
    "            else:\n",
    "                running_loss = running_loss * .99 + loss.item() * .01    \n",
    "            \n",
    "            # TQDM VERBOSE_STEP TRACKING\n",
    "            if ((step + 1) % CFG['verbose_step'] == 0) or ((step + 1) == len(train_loader)):\n",
    "                description = f'epoch {epoch} loss: {running_loss:.4f}'\n",
    "                pbar.set_description(description)\n",
    "        \n",
    "        student_preds_all += [torch.argmax(student_preds, 1).detach().cpu().numpy()]\n",
    "        image_targets_all += [image_labels.detach().cpu().numpy()]\n",
    "        \n",
    "    if scheduler is not None:\n",
    "        scheduler.step()\n",
    "    \n",
    "    student_preds_all = np.concatenate(student_preds_all)\n",
    "    image_targets_all = np.concatenate(image_targets_all)\n",
    "    \n",
    "    matrix = confusion_matrix(image_targets_all,student_preds_all)\n",
    "    epoch_f1 = f1_score(image_targets_all, student_preds_all, average='macro')\n",
    "    accuracy = (student_preds_all==image_targets_all).mean()\n",
    "    trn_loss = loss_sum/len(train_loader)\n",
    "    \n",
    "    return student_preds_all, accuracy, trn_loss, matrix, epoch_f1\n",
    "\n",
    "def valid_one_epoch(epoch,s_model, t_model, loss_fn, val_loader, device, scheduler=None, schd_loss_update=False, alpha =0.1):\n",
    "    t = time.time()\n",
    "    \n",
    "    # SET MODEL VALID MODE\n",
    "    s_model.eval()\n",
    "    t_model.eval()\n",
    "\n",
    "    loss_sum = 0\n",
    "    sample_num = 0\n",
    "    avg_loss = 0\n",
    "    student_preds_all = []\n",
    "    image_targets_all = []\n",
    "    acc_list = []\n",
    "    \n",
    "    pbar = tqdm(enumerate(val_loader), total=len(val_loader))\n",
    "    for step, (imgs, image_labels) in pbar:\n",
    "        imgs = imgs.to(device).float()\n",
    "        image_labels = image_labels.to(device).long()\n",
    "        \n",
    "        # STUDENT MODEL PREDICTION\n",
    "        student_preds = s_model(imgs)\n",
    "        # TEACHER MODEL PREDICTION\n",
    "        teacher_preds = t_model(imgs)\n",
    "        \n",
    "        # DISTILLATION LOSS\n",
    "        loss = distill_loss(student_preds, image_labels, teacher_preds, loss_fn, alpha)\n",
    "        \n",
    "        student_preds_all += [torch.argmax(student_preds, 1).detach().cpu().numpy()]\n",
    "        image_targets_all += [image_labels.detach().cpu().numpy()]\n",
    "        \n",
    "        avg_loss += loss.item()\n",
    "        loss_sum += loss.item()*image_labels.shape[0]\n",
    "        sample_num += image_labels.shape[0]\n",
    "        \n",
    "        # TQDM\n",
    "        description = f'epoch {epoch} loss: {loss_sum/sample_num:.4f}'\n",
    "        pbar.set_description(description)\n",
    "    \n",
    "    student_preds_all = np.concatenate(student_preds_all)\n",
    "    image_targets_all = np.concatenate(image_targets_all)\n",
    "    matrix = confusion_matrix(image_targets_all,student_preds_all)\n",
    "    \n",
    "    epoch_f1 = f1_score(image_targets_all, student_preds_all, average='macro')\n",
    "    acc = (student_preds_all==image_targets_all).mean()\n",
    "    val_loss = avg_loss/len(val_loader)\n",
    "    \n",
    "    return student_preds_all, acc, val_loss, matrix, epoch_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862e4b92-23e3-4444-9369-1dc9dc504b13",
   "metadata": {},
   "source": [
    "#### Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "77e9950b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10, verbose=False, delta=0):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "\n",
    "    def __call__(self, score):\n",
    "        print(f' present score: {score}')\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "        elif score <= self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            print(f'Best F1 score from now: {self.best_score}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.counter = 0\n",
    "        \n",
    "        return self.early_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37102a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhojunking\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/hojun/git/KD_models/wandb/run-20230520_132314-j32d56et</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/hojunking/KD_dishes_resnet152_mobilenet_v3_large/runs/j32d56et' target=\"_blank\">serene-bee-2</a></strong> to <a href='https://wandb.ai/hojunking/KD_dishes_resnet152_mobilenet_v3_large' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/hojunking/KD_dishes_resnet152_mobilenet_v3_large' target=\"_blank\">https://wandb.ai/hojunking/KD_dishes_resnet152_mobilenet_v3_large</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/hojunking/KD_dishes_resnet152_mobilenet_v3_large/runs/j32d56et' target=\"_blank\">https://wandb.ai/hojunking/KD_dishes_resnet152_mobilenet_v3_large/runs/j32d56et</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: mobilenet_v3_large\n",
      "Training start with fold: 0 epoch: 200 \n",
      "\n",
      "cls_cnts: 3\n",
      "num_samples:3208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hojun/miniconda3/envs/torch/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/hojun/miniconda3/envs/torch/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V3_Large_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V3_Large_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/home/hojun/miniconda3/envs/torch/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet152_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet152_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 0\n",
      "\n",
      "Epoch 0/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 0 loss: 1.8950: 100%|████████████████████████████████████████████████████████████████████████| 51/51 [01:31<00:00,  1.79s/it]\n",
      "epoch 0 loss: 0.2866: 100%|████████████████████████████████████████████████████████████████████████| 13/13 [00:30<00:00,  2.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], Train Loss : [1.16957] Val Loss : [0.29324] Val F1 Score : [0.93519]\n",
      " present score: 0.9351913665151388\n",
      "Epoch 1/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 loss: 0.4254: 100%|████████████████████████████████████████████████████████████████████████| 51/51 [01:29<00:00,  1.76s/it]\n",
      "epoch 1 loss: 0.2029: 100%|████████████████████████████████████████████████████████████████████████| 13/13 [00:28<00:00,  2.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1], Train Loss : [0.34426] Val Loss : [0.20722] Val F1 Score : [0.95126]\n",
      " present score: 0.95126450530817\n",
      "Epoch 2/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 2 loss: 0.1944: 100%|████████████████████████████████████████████████████████████████████████| 51/51 [01:27<00:00,  1.71s/it]\n",
      "epoch 2 loss: 0.1563: 100%|████████████████████████████████████████████████████████████████████████| 13/13 [00:28<00:00,  2.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2], Train Loss : [0.25822] Val Loss : [0.16230] Val F1 Score : [0.95868]\n",
      " present score: 0.9586770895004677\n",
      "Epoch 3/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 3 loss: 0.1944: 100%|████████████████████████████████████████████████████████████████████████| 51/51 [01:28<00:00,  1.73s/it]\n",
      "epoch 3 loss: 0.1470: 100%|████████████████████████████████████████████████████████████████████████| 13/13 [00:27<00:00,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3], Train Loss : [0.21431] Val Loss : [0.15592] Val F1 Score : [0.96216]\n",
      " present score: 0.9621616666997571\n",
      "Epoch 4/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 4 loss: 0.1427: 100%|████████████████████████████████████████████████████████████████████████| 51/51 [01:25<00:00,  1.67s/it]\n",
      "epoch 4 loss: 0.1719: 100%|████████████████████████████████████████████████████████████████████████| 13/13 [00:27<00:00,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4], Train Loss : [0.19214] Val Loss : [0.18074] Val F1 Score : [0.95900]\n",
      " present score: 0.9590045141363744\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Best F1 score from now: 0.9621616666997571\n",
      "Epoch 5/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 5 loss: 0.1364: 100%|████████████████████████████████████████████████████████████████████████| 51/51 [01:29<00:00,  1.75s/it]\n",
      "epoch 5 loss: 0.1355: 100%|████████████████████████████████████████████████████████████████████████| 13/13 [00:27<00:00,  2.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5], Train Loss : [0.16268] Val Loss : [0.14339] Val F1 Score : [0.96640]\n",
      " present score: 0.9663964645190223\n",
      "Epoch 6/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 6 loss: 0.1936: 100%|████████████████████████████████████████████████████████████████████████| 51/51 [01:24<00:00,  1.65s/it]\n",
      "epoch 6 loss: 0.1337: 100%|████████████████████████████████████████████████████████████████████████| 13/13 [00:28<00:00,  2.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6], Train Loss : [0.15834] Val Loss : [0.14268] Val F1 Score : [0.96385]\n",
      " present score: 0.963850701288651\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Best F1 score from now: 0.9663964645190223\n",
      "Epoch 7/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 7 loss: 0.0948: 100%|████████████████████████████████████████████████████████████████████████| 51/51 [01:22<00:00,  1.62s/it]\n",
      "epoch 7 loss: 0.1181: 100%|████████████████████████████████████████████████████████████████████████| 13/13 [00:27<00:00,  2.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7], Train Loss : [0.15267] Val Loss : [0.12486] Val F1 Score : [0.97101]\n",
      " present score: 0.9710090313613825\n",
      "Epoch 8/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 8 loss: 0.2054: 100%|████████████████████████████████████████████████████████████████████████| 51/51 [01:27<00:00,  1.72s/it]\n",
      "epoch 8 loss: 0.1222: 100%|████████████████████████████████████████████████████████████████████████| 13/13 [00:27<00:00,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8], Train Loss : [0.17184] Val Loss : [0.12904] Val F1 Score : [0.96987]\n",
      " present score: 0.9698714419524014\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Best F1 score from now: 0.9710090313613825\n",
      "Epoch 9/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 9 loss: 0.1001: 100%|████████████████████████████████████████████████████████████████████████| 51/51 [01:28<00:00,  1.73s/it]\n",
      "epoch 9 loss: 0.1268: 100%|████████████████████████████████████████████████████████████████████████| 13/13 [00:27<00:00,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9], Train Loss : [0.12269] Val Loss : [0.13652] Val F1 Score : [0.96744]\n",
      " present score: 0.9674424945075307\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Best F1 score from now: 0.9710090313613825\n",
      "Epoch 10/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 10 loss: 0.1229: 100%|███████████████████████████████████████████████████████████████████████| 51/51 [01:24<00:00,  1.66s/it]\n",
      "epoch 10 loss: 0.1154: 100%|███████████████████████████████████████████████████████████████████████| 13/13 [00:27<00:00,  2.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10], Train Loss : [0.12495] Val Loss : [0.12335] Val F1 Score : [0.97000]\n",
      " present score: 0.9700037276254788\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Best F1 score from now: 0.9710090313613825\n",
      "Epoch 11/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 11 loss: 0.2176: 100%|███████████████████████████████████████████████████████████████████████| 51/51 [01:25<00:00,  1.68s/it]\n",
      "epoch 11 loss: 0.1214: 100%|███████████████████████████████████████████████████████████████████████| 13/13 [00:26<00:00,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11], Train Loss : [0.11449] Val Loss : [0.13107] Val F1 Score : [0.97003]\n",
      " present score: 0.9700304250901034\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Best F1 score from now: 0.9710090313613825\n",
      "Epoch 12/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 12 loss: 0.0818: 100%|███████████████████████████████████████████████████████████████████████| 51/51 [01:25<00:00,  1.67s/it]\n",
      "epoch 12 loss: 0.1181: 100%|███████████████████████████████████████████████████████████████████████| 13/13 [00:27<00:00,  2.15s/it]\n",
      "/home/hojun/miniconda3/envs/torch/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/hojun/miniconda3/envs/torch/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V3_Large_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V3_Large_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/home/hojun/miniconda3/envs/torch/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet152_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet152_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12], Train Loss : [0.11722] Val Loss : [0.12736] Val F1 Score : [0.97002]\n",
      " present score: 0.9700152685253629\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Best F1 score from now: 0.9710090313613825\n",
      "stop called\n",
      "time : 0:25:06\n",
      "fold: 0, Best Epoch : 7/ 13\n",
      "Best Train Marco F1 : 0.98250\n",
      "[[1089    8   10]\n",
      " [   8 1014   12]\n",
      " [   7   11 1049]]\n",
      "Best Valid Marco F1 : 0.97101\n",
      "[[241   4   7]\n",
      " [  0 289   7]\n",
      " [  3   2 249]]\n",
      "-----------------------------------------------------------------------\n",
      "Training start with fold: 1 epoch: 200 \n",
      "\n",
      "cls_cnts: 3\n",
      "num_samples:3208\n",
      "Fold: 1\n",
      "\n",
      "Epoch 0/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 0 loss: 1.7733: 100%|████████████████████████████████████████████████████████████████████████| 51/51 [01:21<00:00,  1.60s/it]\n",
      "epoch 0 loss: 0.3151: 100%|████████████████████████████████████████████████████████████████████████| 13/13 [00:27<00:00,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], Train Loss : [1.07218] Val Loss : [0.31652] Val F1 Score : [0.94189]\n",
      " present score: 0.9418884816253126\n",
      "Epoch 1/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 1 loss: 0.2811: 100%|████████████████████████████████████████████████████████████████████████| 51/51 [01:22<00:00,  1.63s/it]\n",
      "epoch 1 loss: 0.2728: 100%|████████████████████████████████████████████████████████████████████████| 13/13 [00:28<00:00,  2.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1], Train Loss : [0.29452] Val Loss : [0.27604] Val F1 Score : [0.95099]\n",
      " present score: 0.9509923676407918\n",
      "Epoch 2/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 2 loss: 0.3939: 100%|████████████████████████████████████████████████████████████████████████| 51/51 [01:25<00:00,  1.67s/it]\n",
      "epoch 2 loss: 0.2011: 100%|████████████████████████████████████████████████████████████████████████| 13/13 [00:27<00:00,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2], Train Loss : [0.23221] Val Loss : [0.20096] Val F1 Score : [0.97034]\n",
      " present score: 0.9703445754934696\n",
      "Epoch 3/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 3 loss: 0.2172: 100%|████████████████████████████████████████████████████████████████████████| 51/51 [01:23<00:00,  1.65s/it]\n",
      "epoch 3 loss: 0.2231: 100%|████████████████████████████████████████████████████████████████████████| 13/13 [00:26<00:00,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3], Train Loss : [0.19773] Val Loss : [0.22439] Val F1 Score : [0.96052]\n",
      " present score: 0.960524879131284\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Best F1 score from now: 0.9703445754934696\n",
      "Epoch 4/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 4 loss: 0.2548: 100%|████████████████████████████████████████████████████████████████████████| 51/51 [01:27<00:00,  1.71s/it]\n",
      "epoch 4 loss: 0.1853: 100%|████████████████████████████████████████████████████████████████████████| 13/13 [00:26<00:00,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4], Train Loss : [0.22389] Val Loss : [0.18502] Val F1 Score : [0.96930]\n",
      " present score: 0.9692959724853956\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Best F1 score from now: 0.9703445754934696\n",
      "Epoch 5/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 5 loss: 0.1293: 100%|████████████████████████████████████████████████████████████████████████| 51/51 [01:21<00:00,  1.60s/it]\n",
      "epoch 5 loss: 0.1902: 100%|████████████████████████████████████████████████████████████████████████| 13/13 [00:26<00:00,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5], Train Loss : [0.16936] Val Loss : [0.18889] Val F1 Score : [0.96549]\n",
      " present score: 0.9654911604637798\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Best F1 score from now: 0.9703445754934696\n",
      "Epoch 6/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 6 loss: 0.1958: 100%|████████████████████████████████████████████████████████████████████████| 51/51 [01:20<00:00,  1.58s/it]\n",
      "epoch 6 loss: 0.1732: 100%|████████████████████████████████████████████████████████████████████████| 13/13 [00:27<00:00,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6], Train Loss : [0.17276] Val Loss : [0.17135] Val F1 Score : [0.96930]\n",
      " present score: 0.9693035794584848\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Best F1 score from now: 0.9703445754934696\n",
      "Epoch 7/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 7 loss: 0.1014: 100%|████████████████████████████████████████████████████████████████████████| 51/51 [01:23<00:00,  1.64s/it]\n",
      "epoch 7 loss: 0.1778: 100%|████████████████████████████████████████████████████████████████████████| 13/13 [00:27<00:00,  2.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7], Train Loss : [0.13850] Val Loss : [0.17647] Val F1 Score : [0.97154]\n",
      " present score: 0.9715391236416836\n",
      "Epoch 8/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 8 loss: 0.1583: 100%|████████████████████████████████████████████████████████████████████████| 51/51 [01:22<00:00,  1.61s/it]\n",
      "epoch 8 loss: 0.1718: 100%|████████████████████████████████████████████████████████████████████████| 13/13 [00:26<00:00,  2.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8], Train Loss : [0.13094] Val Loss : [0.17038] Val F1 Score : [0.97653]\n",
      " present score: 0.9765260050742341\n",
      "Epoch 9/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 9 loss: 0.1155: 100%|████████████████████████████████████████████████████████████████████████| 51/51 [01:22<00:00,  1.62s/it]\n",
      "epoch 9 loss: 0.1626: 100%|████████████████████████████████████████████████████████████████████████| 13/13 [00:27<00:00,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9], Train Loss : [0.12452] Val Loss : [0.16080] Val F1 Score : [0.97400]\n",
      " present score: 0.9739982923624074\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Best F1 score from now: 0.9765260050742341\n",
      "Epoch 10/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 10 loss: 0.0877: 100%|███████████████████████████████████████████████████████████████████████| 51/51 [01:23<00:00,  1.64s/it]\n",
      "epoch 10 loss: 0.1706: 100%|███████████████████████████████████████████████████████████████████████| 13/13 [00:27<00:00,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10], Train Loss : [0.14429] Val Loss : [0.16913] Val F1 Score : [0.97159]\n",
      " present score: 0.9715861361248882\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Best F1 score from now: 0.9765260050742341\n",
      "Epoch 11/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 11 loss: 0.1024: 100%|███████████████████████████████████████████████████████████████████████| 51/51 [01:23<00:00,  1.63s/it]\n",
      "epoch 11 loss: 0.1658: 100%|███████████████████████████████████████████████████████████████████████| 13/13 [00:26<00:00,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11], Train Loss : [0.12200] Val Loss : [0.16457] Val F1 Score : [0.97410]\n",
      " present score: 0.9741022300387606\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Best F1 score from now: 0.9765260050742341\n",
      "Epoch 12/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 12 loss: 0.1118: 100%|███████████████████████████████████████████████████████████████████████| 51/51 [01:22<00:00,  1.62s/it]\n",
      "epoch 12 loss: 0.1659: 100%|███████████████████████████████████████████████████████████████████████| 13/13 [00:26<00:00,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12], Train Loss : [0.11055] Val Loss : [0.16406] Val F1 Score : [0.97172]\n",
      " present score: 0.971717905652303\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Best F1 score from now: 0.9765260050742341\n",
      "Epoch 13/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 13 loss: 0.1053: 100%|███████████████████████████████████████████████████████████████████████| 51/51 [01:22<00:00,  1.62s/it]\n",
      "epoch 13 loss: 0.1635: 100%|███████████████████████████████████████████████████████████████████████| 13/13 [00:27<00:00,  2.10s/it]\n",
      "/home/hojun/miniconda3/envs/torch/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/hojun/miniconda3/envs/torch/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V3_Large_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V3_Large_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/home/hojun/miniconda3/envs/torch/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet152_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet152_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13], Train Loss : [0.11032] Val Loss : [0.16168] Val F1 Score : [0.97423]\n",
      " present score: 0.9742271572374653\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Best F1 score from now: 0.9765260050742341\n",
      "stop called\n",
      "time : 0:25:57\n",
      "fold: 1, Best Epoch : 8/ 14\n",
      "Best Train Marco F1 : 0.98157\n",
      "[[1073    8    7]\n",
      " [   7 1055   14]\n",
      " [  12   11 1021]]\n",
      "Best Valid Marco F1 : 0.97653\n",
      "[[245   5   2]\n",
      " [  1 290   6]\n",
      " [  1   4 248]]\n",
      "-----------------------------------------------------------------------\n",
      "Training start with fold: 2 epoch: 200 \n",
      "\n",
      "cls_cnts: 3\n",
      "num_samples:3208\n",
      "Fold: 2\n",
      "\n",
      "Epoch 0/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 0 loss: 1.7707: 100%|████████████████████████████████████████████████████████████████████████| 51/51 [01:25<00:00,  1.68s/it]\n",
      "epoch 0 loss: 0.3623: 100%|████████████████████████████████████████████████████████████████████████| 13/13 [00:26<00:00,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], Train Loss : [1.08467] Val Loss : [0.36466] Val F1 Score : [0.92397]\n",
      " present score: 0.9239667037124947\n",
      "Epoch 1/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 1 loss: 0.4556: 100%|████████████████████████████████████████████████████████████████████████| 51/51 [01:21<00:00,  1.60s/it]\n",
      "epoch 1 loss: 0.2580: 100%|████████████████████████████████████████████████████████████████████████| 13/13 [00:28<00:00,  2.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1], Train Loss : [0.35359] Val Loss : [0.25160] Val F1 Score : [0.94869]\n",
      " present score: 0.9486861475756584\n",
      "Epoch 2/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 2 loss: 0.2223: 100%|████████████████████████████████████████████████████████████████████████| 51/51 [01:21<00:00,  1.60s/it]\n",
      "epoch 2 loss: 0.2152: 100%|████████████████████████████████████████████████████████████████████████| 13/13 [00:27<00:00,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2], Train Loss : [0.24266] Val Loss : [0.21748] Val F1 Score : [0.95652]\n",
      " present score: 0.9565218358862663\n",
      "Epoch 3/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 3 loss: 0.1558: 100%|████████████████████████████████████████████████████████████████████████| 51/51 [01:25<00:00,  1.67s/it]\n",
      "epoch 3 loss: 0.1868: 100%|████████████████████████████████████████████████████████████████████████| 13/13 [00:26<00:00,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3], Train Loss : [0.24397] Val Loss : [0.18500] Val F1 Score : [0.96494]\n",
      " present score: 0.9649366198345742\n",
      "Epoch 4/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 4 loss: 0.1854: 100%|████████████████████████████████████████████████████████████████████████| 51/51 [01:22<00:00,  1.63s/it]\n",
      "epoch 4 loss: 0.1506: 100%|████████████████████████████████████████████████████████████████████████| 13/13 [00:26<00:00,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4], Train Loss : [0.16149] Val Loss : [0.15041] Val F1 Score : [0.97626]\n",
      " present score: 0.9762574854702534\n",
      "Epoch 5/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 5 loss: 0.2040: 100%|████████████████████████████████████████████████████████████████████████| 51/51 [01:25<00:00,  1.67s/it]\n",
      "epoch 5 loss: 0.1419: 100%|████████████████████████████████████████████████████████████████████████| 13/13 [00:27<00:00,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5], Train Loss : [0.16815] Val Loss : [0.14094] Val F1 Score : [0.97378]\n",
      " present score: 0.9737802638344473\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Best F1 score from now: 0.9762574854702534\n",
      "Epoch 6/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 6 loss: 0.2056: 100%|████████████████████████████████████████████████████████████████████████| 51/51 [01:25<00:00,  1.67s/it]\n",
      "epoch 6 loss: 0.1392: 100%|████████████████████████████████████████████████████████████████████████| 13/13 [00:27<00:00,  2.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6], Train Loss : [0.16843] Val Loss : [0.13842] Val F1 Score : [0.97622]\n",
      " present score: 0.9762182464761281\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Best F1 score from now: 0.9762574854702534\n",
      "Epoch 7/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 7 loss: 0.1232: 100%|████████████████████████████████████████████████████████████████████████| 51/51 [01:24<00:00,  1.65s/it]\n",
      "epoch 7 loss: 0.1424: 100%|████████████████████████████████████████████████████████████████████████| 13/13 [00:26<00:00,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7], Train Loss : [0.13169] Val Loss : [0.14234] Val F1 Score : [0.97489]\n",
      " present score: 0.9748873066227253\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Best F1 score from now: 0.9762574854702534\n",
      "Epoch 8/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 8 loss: 0.1240: 100%|████████████████████████████████████████████████████████████████████████| 51/51 [01:24<00:00,  1.65s/it]\n",
      "epoch 8 loss: 0.1371: 100%|████████████████████████████████████████████████████████████████████████| 13/13 [00:26<00:00,  2.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8], Train Loss : [0.14039] Val Loss : [0.13497] Val F1 Score : [0.97752]\n",
      " present score: 0.9775224721351687\n",
      "Epoch 9/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 9 loss: 0.0980: 100%|████████████████████████████████████████████████████████████████████████| 51/51 [01:23<00:00,  1.64s/it]\n",
      "epoch 9 loss: 0.1323: 100%|████████████████████████████████████████████████████████████████████████| 13/13 [00:26<00:00,  2.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9], Train Loss : [0.12709] Val Loss : [0.13132] Val F1 Score : [0.97986]\n",
      " present score: 0.9798620860391507\n",
      "Epoch 10/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 10 loss: 0.1177: 100%|███████████████████████████████████████████████████████████████████████| 51/51 [01:22<00:00,  1.62s/it]\n",
      "epoch 10 loss: 0.1284: 100%|███████████████████████████████████████████████████████████████████████| 13/13 [00:26<00:00,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10], Train Loss : [0.16104] Val Loss : [0.12748] Val F1 Score : [0.97726]\n",
      " present score: 0.9772562653918585\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Best F1 score from now: 0.9798620860391507\n",
      "Epoch 11/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 11 loss: 0.1155: 100%|███████████████████████████████████████████████████████████████████████| 51/51 [01:23<00:00,  1.65s/it]\n",
      "epoch 11 loss: 0.1273: 100%|███████████████████████████████████████████████████████████████████████| 13/13 [00:27<00:00,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11], Train Loss : [0.12803] Val Loss : [0.12702] Val F1 Score : [0.97596]\n",
      " present score: 0.9759608745014302\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Best F1 score from now: 0.9798620860391507\n",
      "Epoch 12/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 12 loss: 0.1324: 100%|███████████████████████████████████████████████████████████████████████| 51/51 [01:22<00:00,  1.62s/it]\n",
      "epoch 12 loss: 0.1296: 100%|███████████████████████████████████████████████████████████████████████| 13/13 [00:28<00:00,  2.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12], Train Loss : [0.11411] Val Loss : [0.13001] Val F1 Score : [0.97616]\n",
      " present score: 0.9761610944588268\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Best F1 score from now: 0.9798620860391507\n",
      "Epoch 13/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 13 loss: 0.1124: 100%|███████████████████████████████████████████████████████████████████████| 51/51 [01:22<00:00,  1.62s/it]\n",
      "epoch 13 loss: 0.1328: 100%|███████████████████████████████████████████████████████████████████████| 13/13 [00:27<00:00,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13], Train Loss : [0.11486] Val Loss : [0.13218] Val F1 Score : [0.97890]\n",
      " present score: 0.9788988183664795\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Best F1 score from now: 0.9798620860391507\n",
      "Epoch 14/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 14 loss: 0.0933: 100%|███████████████████████████████████████████████████████████████████████| 51/51 [01:21<00:00,  1.61s/it]\n",
      "epoch 14 loss: 0.1262: 100%|███████████████████████████████████████████████████████████████████████| 13/13 [00:27<00:00,  2.08s/it]\n",
      "/home/hojun/miniconda3/envs/torch/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/hojun/miniconda3/envs/torch/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V3_Large_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V3_Large_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/home/hojun/miniconda3/envs/torch/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet152_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet152_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14], Train Loss : [0.12694] Val Loss : [0.12434] Val F1 Score : [0.97488]\n",
      " present score: 0.9748784291526541\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Best F1 score from now: 0.9798620860391507\n",
      "stop called\n",
      "time : 0:27:56\n",
      "fold: 2, Best Epoch : 9/ 15\n",
      "Best Train Marco F1 : 0.98342\n",
      "[[1015    7    8]\n",
      " [   8 1110   10]\n",
      " [  13    7 1030]]\n",
      "Best Valid Marco F1 : 0.97986\n",
      "[[247   2   3]\n",
      " [  1 293   3]\n",
      " [  3   4 246]]\n",
      "-----------------------------------------------------------------------\n",
      "Training start with fold: 3 epoch: 200 \n",
      "\n",
      "cls_cnts: 3\n",
      "num_samples:3208\n",
      "Fold: 3\n",
      "\n",
      "Epoch 0/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 0 loss: 1.8771: 100%|████████████████████████████████████████████████████████████████████████| 51/51 [01:20<00:00,  1.58s/it]\n",
      "epoch 0 loss: 0.4165: 100%|████████████████████████████████████████████████████████████████████████| 13/13 [00:25<00:00,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], Train Loss : [1.12150] Val Loss : [0.41225] Val F1 Score : [0.92030]\n",
      " present score: 0.9202994301694769\n",
      "Epoch 1/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 1 loss: 0.3158:  88%|███████████████████████████████████████████████████████████████▌        | 45/51 [01:16<00:06,  1.14s/it]"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    seed_everything(CFG['seed'])\n",
    "    \n",
    "    # WANDB TRACKER INIT\n",
    "    wandb.init(project=project_name, entity=user)\n",
    "    wandb.config.update(CFG)\n",
    "    wandb.run.name = run_name\n",
    "    wandb.define_metric(\"Train Accuracy\", step_metric=\"epoch\")\n",
    "    wandb.define_metric(\"Valid Accuracy\", step_metric=\"epoch\")\n",
    "    wandb.define_metric(\"Train Loss\", step_metric=\"epoch\")\n",
    "    wandb.define_metric(\"Valid Loss\", step_metric=\"epoch\")\n",
    "    wandb.define_metric(\"Train Macro F1 Score\", step_metric=\"epoch\")\n",
    "    wandb.define_metric(\"Valid Macro F1 Score\", step_metric=\"epoch\")\n",
    "    wandb.define_metric(\"Train-Valid Accuracy\", step_metric=\"epoch\")\n",
    "    \n",
    "    model_dir = CFG['model_path'] + '/{}'.format(run_name)\n",
    "    train_dir = train.dir.values\n",
    "    best_fold = 0\n",
    "    best_f1 =0.0\n",
    "    \n",
    "    print('Model: {}'.format(CFG['s_model']))\n",
    "    # MAKE MODEL DIR\n",
    "    if not os.path.isdir(model_dir):\n",
    "        os.makedirs(model_dir)\n",
    "    \n",
    "    \n",
    "    # STRATIFIED K-FOLD DEFINITION\n",
    "    folds = StratifiedKFold(n_splits=CFG['fold_num'], shuffle=True, random_state=CFG['seed']).split(np.arange(train.shape[0]), train.label.values)\n",
    "    for fold, (trn_idx, val_idx) in enumerate(folds):\n",
    "        print(f'Training start with fold: {fold} epoch: {CFG[\"epochs\"]} \\n')\n",
    "\n",
    "        # EARLY STOPPING DEFINITION\n",
    "        early_stopping = EarlyStopping(patience=CFG[\"patience\"], verbose=True)\n",
    "\n",
    "        # DATALOADER DEFINITION\n",
    "        train_loader, val_loader = prepare_dataloader(train, trn_idx, val_idx, data_root=train_dir)\n",
    "\n",
    "        # MODEL & DEVICE DEFINITION \n",
    "        device = torch.device(CFG['device'])\n",
    "        student_model = Student(CFG['s_model'], train.label.nunique(), pretrained=True)\n",
    "        teacher_model = Teacher(CFG['t_model'], train.label.nunique(), pretrained=True)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # LOAD TEACHER_MODE WEIGHT\n",
    "        load_model = CFG['model_path'] +'/' + CFG['load_model'] + '/' + CFG['t_model'] +'.pth'\n",
    "        teacher_model.load_state_dict(torch.load(load_model))\n",
    "\n",
    "        # MODEL FREEZING\n",
    "        # student_model.freezing(freeze = CFG['freezing'], trainable_layer = CFG['trainable_layer'])\n",
    "        # if CFG['freezing'] ==True:\n",
    "        #     for name, param in student_model.named_parameters():\n",
    "        #         if param.requires_grad == True:\n",
    "        #             print(f\"{name}: {param.requires_grad}\")\n",
    "        \n",
    "        # T_MODEL DATA PARALLEL\n",
    "        # S_MODEL DATA PARALLEL\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            teacher_model = nn.DataParallel(teacher_model)\n",
    "            student_model = nn.DataParallel(student_model)\n",
    "            \n",
    "        teacher_model.to(device)\n",
    "        student_model.to(device)\n",
    "        scaler = torch.cuda.amp.GradScaler()   \n",
    "        optimizer = torch.optim.Adam(student_model.parameters(), lr=CFG['lr'])\n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, gamma=0.5, step_size=5)\n",
    "\n",
    "        # DISTILLATION RATE\n",
    "        alpha = CFG['alpha']\n",
    "\n",
    "        # CRITERION (LOSS FUNCTION)\n",
    "        loss_tr = nn.CrossEntropyLoss().to(device) #MyCrossEntropyLoss().to(device)\n",
    "        loss_fn = nn.CrossEntropyLoss().to(device)\n",
    "        \n",
    "        wandb.watch(student_model, loss_tr, log='all')\n",
    "        train_acc_list = []\n",
    "        train_matrix_list = []\n",
    "        train_f1_list = []\n",
    "        valid_acc_list = []\n",
    "        valid_matrix_list = []\n",
    "        valid_f1_list = []\n",
    "\n",
    "        start = time.time()\n",
    "        print(f'Fold: {fold}\\n')\n",
    "        for epoch in range(CFG['epochs']):\n",
    "            print('Epoch {}/{}'.format(epoch, CFG['epochs'] - 1))\n",
    "\n",
    "            # TRAINIG\n",
    "            train_preds_all, train_acc, train_loss, train_matrix, train_f1 = train_one_epoch(epoch, student_model, teacher_model,loss_tr, optimizer, train_loader, device, scheduler=scheduler, alpha = alpha)\n",
    "            wandb.log({'Train Accuracy':train_acc, 'Train Loss' : train_loss, 'Train F1': train_f1, 'epoch' : epoch})\n",
    "\n",
    "            # VALIDATION\n",
    "            with torch.no_grad():\n",
    "                valid_preds_all, valid_acc, valid_loss, valid_matrix, valid_f1= valid_one_epoch(epoch, student_model, teacher_model, loss_fn, val_loader, device, scheduler=None, alpha = alpha)\n",
    "                wandb.log({'Valid Accuracy':valid_acc, 'Valid Loss' : valid_loss, 'Valid F1': valid_f1 ,'epoch' : epoch})\n",
    "            print(f'Epoch [{epoch}], Train Loss : [{train_loss :.5f}] Val Loss : [{valid_loss :.5f}] Val F1 Score : [{valid_f1:.5f}]')\n",
    "\n",
    "            # SAVE ALL RESULTS\n",
    "            train_acc_list.append(train_acc)\n",
    "            train_matrix_list.append(train_matrix)\n",
    "            train_f1_list.append(train_f1)\n",
    "\n",
    "            valid_acc_list.append(valid_acc)\n",
    "            valid_matrix_list.append(valid_matrix)\n",
    "            valid_f1_list.append(valid_f1)\n",
    "\n",
    "            # MODEL SAVE (THE BEST MODEL OF ALL OF FOLD PROCESS)\n",
    "            if valid_f1 > best_f1:\n",
    "                best_f1 = valid_f1\n",
    "                torch.save(student_model.module.state_dict(), (model_dir+'/{}.pth').format(CFG['s_model']))\n",
    "\n",
    "            # EARLY STOPPING\n",
    "            stop = early_stopping(valid_f1)\n",
    "            if stop:\n",
    "                print(\"stop called\")   \n",
    "                break\n",
    "\n",
    "        end = time.time() - start\n",
    "        time_ = str(datetime.timedelta(seconds=end)).split(\".\")[0]\n",
    "        print(\"time :\", time_)\n",
    "\n",
    "        # PRINT BEST F1 SCORE MODEL OF FOLD\n",
    "        best_index = valid_f1_list.index(max(valid_f1_list))\n",
    "        print(f'fold: {fold}, Best Epoch : {best_index}/ {len(valid_f1_list)}')\n",
    "        print(f'Best Train Marco F1 : {train_f1_list[best_index]:.5f}')\n",
    "        print(train_matrix_list[best_index])\n",
    "        print(f'Best Valid Marco F1 : {valid_f1_list[best_index]:.5f}')\n",
    "        print(valid_matrix_list[best_index])\n",
    "        print('-----------------------------------------------------------------------')\n",
    "\n",
    "        ## K-FOLD END\n",
    "        if valid_f1_list[best_index] > best_fold:\n",
    "            best_fold = valid_f1_list[best_index]\n",
    "            top_fold = fold\n",
    "    print(f'Best Fold F1 score: {best_fold} Top fold : {top_fold}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8a437e36-9c91-4f37-8a6c-f3eadce8fecb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>dir</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0282.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/test/wrap</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0190.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/test/wrap</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0234.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/test/wrap</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0392.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/test/wrap</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0375.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/test/wrap</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1334</th>\n",
       "      <td>0381.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/test/green dish</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1335</th>\n",
       "      <td>0236.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/test/green dish</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336</th>\n",
       "      <td>0384.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/test/green dish</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1337</th>\n",
       "      <td>0074.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/test/green dish</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1338</th>\n",
       "      <td>0011.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/test/green dish</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1339 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      image_id                                            dir  label\n",
       "0     0282.jpg        ../Data/carbon_reduction_data/test/wrap      2\n",
       "1     0190.jpg        ../Data/carbon_reduction_data/test/wrap      2\n",
       "2     0234.jpg        ../Data/carbon_reduction_data/test/wrap      2\n",
       "3     0392.jpg        ../Data/carbon_reduction_data/test/wrap      2\n",
       "4     0375.jpg        ../Data/carbon_reduction_data/test/wrap      2\n",
       "...        ...                                            ...    ...\n",
       "1334  0381.jpg  ../Data/carbon_reduction_data/test/green dish      0\n",
       "1335  0236.jpg  ../Data/carbon_reduction_data/test/green dish      0\n",
       "1336  0384.jpg  ../Data/carbon_reduction_data/test/green dish      0\n",
       "1337  0074.jpg  ../Data/carbon_reduction_data/test/green dish      0\n",
       "1338  0011.jpg  ../Data/carbon_reduction_data/test/green dish      0\n",
       "\n",
       "[1339 rows x 3 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1ef05a94-6c5d-4171-8286-8efa23ba7a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################## inference #############################\n",
    "def inference(model, data_loader, device):\n",
    "    model.eval()\n",
    "    image_preds_all = []\n",
    "    \n",
    "    pbar = tqdm(enumerate(data_loader), total=len(data_loader))\n",
    "    for step, (imgs) in pbar:\n",
    "        imgs = imgs.to(device).float()\n",
    "\n",
    "        image_preds = model(imgs)   #output = model(input)\n",
    "        image_preds_all += [torch.softmax(image_preds, 1).detach().cpu().numpy()]\n",
    "    \n",
    "    image_preds_all = np.concatenate(image_preds_all, axis=0)\n",
    "    return image_preds_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bf8dd532-5acf-4d36-93df-55a97860eb0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hojun/miniconda3/envs/torch/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/hojun/miniconda3/envs/torch/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V3_Large_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V3_Large_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:42<00:00,  2.01s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>dir</th>\n",
       "      <th>label</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0282.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/test/wrap</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0190.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/test/wrap</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0234.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/test/wrap</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0392.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/test/wrap</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0375.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/test/wrap</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1334</th>\n",
       "      <td>0381.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/test/green dish</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1335</th>\n",
       "      <td>0236.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/test/green dish</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336</th>\n",
       "      <td>0384.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/test/green dish</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1337</th>\n",
       "      <td>0074.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/test/green dish</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1338</th>\n",
       "      <td>0011.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/test/green dish</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1339 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      image_id                                            dir  label  pred\n",
       "0     0282.jpg        ../Data/carbon_reduction_data/test/wrap      2     2\n",
       "1     0190.jpg        ../Data/carbon_reduction_data/test/wrap      2     2\n",
       "2     0234.jpg        ../Data/carbon_reduction_data/test/wrap      2     2\n",
       "3     0392.jpg        ../Data/carbon_reduction_data/test/wrap      2     2\n",
       "4     0375.jpg        ../Data/carbon_reduction_data/test/wrap      2     2\n",
       "...        ...                                            ...    ...   ...\n",
       "1334  0381.jpg  ../Data/carbon_reduction_data/test/green dish      0     0\n",
       "1335  0236.jpg  ../Data/carbon_reduction_data/test/green dish      0     0\n",
       "1336  0384.jpg  ../Data/carbon_reduction_data/test/green dish      0     0\n",
       "1337  0074.jpg  ../Data/carbon_reduction_data/test/green dish      0     0\n",
       "1338  0011.jpg  ../Data/carbon_reduction_data/test/green dish      0     0\n",
       "\n",
       "[1339 rows x 4 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RUN INFERENCE\n",
    "model = Student(CFG['s_model'], test.label.nunique(), pretrained=True)\n",
    "load_model = CFG['model_path'] + '/KD_dishes_resnet152_mobilenet_v3_large_202305201323/' + CFG['s_model'] + '.pth'\n",
    "test_dir = test.dir.values\n",
    "\n",
    "tst_ds = CustomDataset(test, test_dir, transform=transform_test, output_label=False)\n",
    "tst_loader = torch.utils.data.DataLoader(\n",
    "    tst_ds, \n",
    "    batch_size=CFG['train_bs'],\n",
    "    num_workers=CFG['num_workers'],\n",
    "    shuffle=False,\n",
    "    pin_memory=True\n",
    ")\n",
    "device = torch.device(CFG['device'])\n",
    "\n",
    "# INFERENCE VIA MULTI-GPU\n",
    "# if torch.cuda.device_count() > 1:\n",
    "#         model = nn.DataParallel(model)\n",
    "model.to(device)\n",
    "\n",
    "# RUN INFERENCE\n",
    "predictions = []\n",
    "model.load_state_dict(torch.load(load_model))\n",
    "with torch.no_grad():\n",
    "    predictions += [inference(model, tst_loader, device)]\n",
    "\n",
    "\n",
    "predictions = np.mean(predictions, axis=0) \n",
    "test['pred'] = np.argmax(predictions, axis=1)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "63e86c0e-080e-4a45-ba54-20db2560660d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>dir</th>\n",
       "      <th>label</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0282.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/test/wrap</td>\n",
       "      <td>wrap</td>\n",
       "      <td>wrap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0190.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/test/wrap</td>\n",
       "      <td>wrap</td>\n",
       "      <td>wrap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0234.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/test/wrap</td>\n",
       "      <td>wrap</td>\n",
       "      <td>wrap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0392.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/test/wrap</td>\n",
       "      <td>wrap</td>\n",
       "      <td>wrap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0375.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/test/wrap</td>\n",
       "      <td>wrap</td>\n",
       "      <td>wrap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1334</th>\n",
       "      <td>0381.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/test/green dish</td>\n",
       "      <td>green dish</td>\n",
       "      <td>green dish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1335</th>\n",
       "      <td>0236.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/test/green dish</td>\n",
       "      <td>green dish</td>\n",
       "      <td>green dish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336</th>\n",
       "      <td>0384.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/test/green dish</td>\n",
       "      <td>green dish</td>\n",
       "      <td>green dish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1337</th>\n",
       "      <td>0074.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/test/green dish</td>\n",
       "      <td>green dish</td>\n",
       "      <td>green dish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1338</th>\n",
       "      <td>0011.jpg</td>\n",
       "      <td>../Data/carbon_reduction_data/test/green dish</td>\n",
       "      <td>green dish</td>\n",
       "      <td>green dish</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1339 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      image_id                                            dir       label  \\\n",
       "0     0282.jpg        ../Data/carbon_reduction_data/test/wrap        wrap   \n",
       "1     0190.jpg        ../Data/carbon_reduction_data/test/wrap        wrap   \n",
       "2     0234.jpg        ../Data/carbon_reduction_data/test/wrap        wrap   \n",
       "3     0392.jpg        ../Data/carbon_reduction_data/test/wrap        wrap   \n",
       "4     0375.jpg        ../Data/carbon_reduction_data/test/wrap        wrap   \n",
       "...        ...                                            ...         ...   \n",
       "1334  0381.jpg  ../Data/carbon_reduction_data/test/green dish  green dish   \n",
       "1335  0236.jpg  ../Data/carbon_reduction_data/test/green dish  green dish   \n",
       "1336  0384.jpg  ../Data/carbon_reduction_data/test/green dish  green dish   \n",
       "1337  0074.jpg  ../Data/carbon_reduction_data/test/green dish  green dish   \n",
       "1338  0011.jpg  ../Data/carbon_reduction_data/test/green dish  green dish   \n",
       "\n",
       "            pred  \n",
       "0           wrap  \n",
       "1           wrap  \n",
       "2           wrap  \n",
       "3           wrap  \n",
       "4           wrap  \n",
       "...          ...  \n",
       "1334  green dish  \n",
       "1335  green dish  \n",
       "1336  green dish  \n",
       "1337  green dish  \n",
       "1338  green dish  \n",
       "\n",
       "[1339 rows x 4 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['label'] = le.inverse_transform(test['label'].values)\n",
    "test['pred'] = le.inverse_transform(test['pred'].values)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8c6af9cf-1048-40ed-a983-d831cc5ac39d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9701\n",
      "f1_score: 0.9702\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1500x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "test_acc = np.sum(test.label == test.pred) / len(test)\n",
    "test_matrix = confusion_matrix(test['label'], test['pred'])\n",
    "epoch_f1 = f1_score(test['label'], test['pred'], average='macro')\n",
    "print(f'accuracy: {test_acc:.4f}')\n",
    "print(f'f1_score: {epoch_f1:.4f}')\n",
    "\n",
    "test_matrix = confusion_matrix(test['label'], test['pred'], normalize='true')\n",
    "#test_matrix = confusion_matrix(test['label'], test['pred'])\n",
    "\n",
    "plt.figure(figsize = (15,10))\n",
    "sns.heatmap(test_matrix, \n",
    "            annot=True, \n",
    "            xticklabels = sorted(set(test['label'])), \n",
    "            yticklabels = sorted(set(test['label'])),\n",
    "            )\n",
    "plt.title('Normalized Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "#print(f'confusion_matrix \\n-------------------------\\n {test_matrix}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7162577b-8bd7-4cfb-b7e4-7332c1959181",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-gpu",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
